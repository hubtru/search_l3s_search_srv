{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, subprocess, json\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "# from search_l3s_search.api.encoder.logic import BertGermanCasedDenseEncoder\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-german-cased\")\n",
    "\n",
    "dataset_path = \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks/json/data.json\"\n",
    "\n",
    "\n",
    "with open(dataset_path) as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "# print(dataset)\n",
    "    \n",
    "        \n",
    "# enc = BertGermanCasedDenseEncoder()\n",
    "\n",
    "# enc.dataset_encoder()\n",
    "contents = []\n",
    "for d in dataset:\n",
    "        contents.append(d[\"contents\"])\n",
    "        \n",
    "type(contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048218488693237305\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t = time.time()\n",
    "tokenizer(contents, add_special_tokens=True, padding='max_length', max_length=512, truncation=True)\n",
    "elapsed = time.time() - t\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1616382598876953\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "for c in contents:\n",
    "    tokens = tokenizer(c, add_special_tokens=True, padding='max_length', max_length=512, truncation=True)\n",
    "    \n",
    "elapsed = time.time() - t\n",
    "print(elapsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07217977941036224, 0.09157858043909073, 0.05999606475234032, -0.020205063745379448, 0.02170461416244507, -0.02944577857851982, 0.03564104810357094, 0.0004519230860751122, 0.06526193022727966, -0.11502823233604431, 0.011782891117036343, 0.06713750213384628, -0.06128199025988579, 0.006231870502233505, 0.004843269940465689, 0.051830656826496124, -0.03202732279896736, -0.01102643646299839, 0.08238693326711655, 0.058150727301836014, 0.028431113809347153, -0.005219425540417433, 0.08151587843894958, 0.04477493464946747, -0.013574089854955673, 0.03810984641313553, -0.05324321985244751, 0.05443398654460907, 0.06877885013818741, 0.013043617829680443, 0.09326209872961044, -0.015830939635634422, 0.04249339923262596, 0.07140932977199554, 0.07173920422792435, 0.017670203000307083, -0.112077496945858, -0.07562334090471268, 0.059521548449993134, 0.07727187126874924, 0.07298506796360016, 0.11304982006549835, 0.025053592398762703, -0.03082236647605896, 0.019926216453313828, -0.07809607684612274, -0.03780963644385338, -0.032319966703653336, -0.003458051709458232, -0.08691567927598953, 0.03114311397075653, 0.01244838535785675, 0.06066260486841202, 0.04374367371201515, -0.10687128454446793, -0.08608587831258774, 0.10647741705179214, 0.02396652288734913, -0.014954113401472569, 0.10234984755516052, -0.06292112171649933, 0.08440732955932617, 0.06378950923681259, 0.01864585466682911, 0.1112263947725296, -0.09706335514783859, -0.08924123644828796, -0.07284083217382431, 0.019687091931700706, -0.028796974569559097, -0.04119914770126343, -0.141618549823761, -0.018335873261094093, 0.03202801197767258, -0.08144234120845795, -0.0553269162774086, -0.057262979447841644, 0.08365405350923538, -0.03397713974118233, 0.07905979454517365, 0.05542796105146408, -0.0026162066496908665, -0.0177549347281456, 0.010862321592867374, -0.016288045793771744, 0.041579943150281906, -0.008277698419988155, 0.08733944594860077, 0.022695381194353104, -0.037821874022483826, 0.03174199163913727, -0.02361334301531315, -0.04268179088830948, -0.038264721632003784, -0.03374132513999939, -0.012953228317201138, 0.008493403904139996, -0.05209215730428696, -0.06259632855653763, -0.04746628552675247, -0.06379155814647675, -0.13149043917655945, 0.0395466573536396, -0.03199750930070877, -0.05167046934366226, -0.1404585838317871, -0.08386363834142685, -0.043144889175891876, 0.040471017360687256, 0.01261887140572071, -0.03527580574154854, 0.028574049472808838, 0.007634025998413563, -0.0033390342723578215, 0.056465279310941696, -0.0647340789437294, 0.031603723764419556, -0.030066171661019325, -0.06557171046733856, 0.06484798341989517, 0.07020017504692078, 0.05587660148739815, -0.13524223864078522, 0.14875857532024384, -0.08065780252218246, -0.03870702162384987, -0.014905081130564213, -0.11362398415803909, 0.026430148631334305, 0.027702314779162407, 0.0769462063908577, 0.030611857771873474, 0.03181581199169159, -0.11043741554021835, -0.025730393826961517, 0.1446973979473114, 0.013399288058280945, 0.14867886900901794, 0.07980140298604965, -0.0658775120973587, 0.01957745850086212, -0.10529480874538422, 0.04611585661768913, 0.014239629730582237, -0.05925234407186508, -0.006889231503009796, -0.03802907094359398, 0.07637656480073929, -0.03730400279164314, 0.10687784850597382, -0.02470715343952179, -0.10359369218349457, -0.4139382243156433, -0.03156024217605591, -0.001616805442608893, 0.016756031662225723, 0.05738787725567818, -0.01561539527028799, 0.031279124319553375, 0.07784814387559891, 0.0014765559462830424, 0.07943745702505112, 0.08337833732366562, -0.01599281094968319, 0.06381641328334808, -0.019637122750282288, 0.053972553461790085, 0.02876831404864788, -0.052523788064718246, 0.007298172451555729, 0.09315893054008484, -0.037286434322595596, -0.020963402464985847, 0.11926402896642685, 0.0680248886346817, 0.021709831431508064, 0.008438309654593468, 0.06257833540439606, 0.012394954450428486, -0.02800765447318554, -0.07086976617574692, -0.08820971101522446, 0.00019984332902822644, 0.12487538158893585, -0.019607828930020332, -0.00686393678188324, 0.026706814765930176, -0.11211711913347244, 0.05583515763282776, -0.09829081594944, -0.006042891647666693, 0.05737804248929024, 0.04778728261590004, -0.025390801951289177, -0.01877204142510891, 0.06043194606900215, -0.06864549964666367, 0.019932923838496208, -0.04134960100054741, -0.06771182268857956, 0.03249567374587059, -0.04051549360156059, 0.10638175904750824, 0.0029933247715234756, 0.0021597999148070812, -0.16657163202762604, 0.0008049861644394696, 0.09905217587947845, 0.09896161407232285, 0.07476895302534103, 0.015744537115097046, 0.012466933578252792, 0.05243516340851784, 0.00714125158265233, 0.06375081837177277, -0.03406604379415512, 0.053776368498802185, 0.04064870998263359, 0.09413112699985504, -0.009069847874343395, -0.004674719180911779, -0.006028424017131329, 0.014769821427762508, -0.020958339795470238, 0.03841320052742958, 0.03982025012373924, -0.05085178092122078, -0.01719462126493454, 0.010405494831502438, -0.040849581360816956, -0.06234819442033768, -0.019010664895176888, 0.059785258024930954, -0.0258787851780653, -0.07856287062168121, -0.0607311837375164, 0.02905231900513172, 0.046296220272779465, -0.046372190117836, 0.04802146926522255, -0.010037219151854515, 0.031446851789951324, -0.022888002917170525, -0.015697747468948364, 0.021306941285729408, -0.06901635229587555, -0.05065780133008957, 0.03836226835846901, -0.02874990925192833, 0.010852635838091373, 0.04305426776409149, -0.05413355305790901, -0.01691618002951145, 0.025296946987509727, 0.004261430352926254, 0.060236331075429916, -0.0009042636957019567, 0.04011911898851395, -0.11522509157657623, -0.15564125776290894, 0.07415896654129028, 0.02865217812359333, 0.06870726495981216, -0.07126495987176895, 0.0007860799669288099, 0.037011221051216125, 0.00187009631190449, 0.03882722929120064, -0.05078078806400299, 0.016305120661854744, -0.14755217730998993, 0.011818119324743748, -0.022487955167889595, 0.03218904510140419, 0.0022844362538307905, -0.06293238699436188, -0.058282315731048584, -0.023906225338578224, 0.04806641861796379, 0.13313615322113037, 0.022141072899103165, -0.0021466182079166174, -0.18747787177562714, 0.02108127623796463, 0.04588036984205246, 0.11132293194532394, -0.08114037662744522, -0.10213742405176163, 0.04355598986148834, -0.030371343716979027, 0.04136289656162262, -0.05255204439163208, 0.03825286403298378, -0.04242638126015663, 0.08432900905609131, -0.05975628271698952, -0.002494477666914463, -0.03483480587601662, -0.008981270715594292, 0.005878185387700796, 0.07652740180492401, 0.01522866077721119, -0.02359769493341446, -0.11165742576122284, -0.013161431066691875, -0.03691820427775383, 0.10810402035713196, 0.09407932311296463, -0.14596910774707794, -0.07568518817424774, 0.11998773366212845, 0.0395655520260334, -0.020471680909395218, 0.017040761187672615, -0.03864702582359314, -0.06098806858062744, 0.0735083743929863, 0.04419674351811409, 0.04197385162115097, 0.07203104346990585, 0.005639326758682728, -0.06569630652666092, -0.04457924887537956, 0.04111413657665253, -0.0038624650333076715, -0.06149357184767723, -0.0802936777472496, -0.022922474890947342, 0.048245593905448914, -0.0017321642953902483, -0.13971258699893951, -0.09676367789506912, 0.04952014982700348, 0.18706274032592773, -0.1383190155029297, -0.04994567111134529, -0.02400934137403965, -0.09772156178951263, 0.06797230988740921, -0.006783011835068464, 0.04344978556036949, 0.059448059648275375, -0.08215052634477615, 0.019326524809002876, -0.0063220662996172905, -0.03481149673461914, -0.03555305302143097, -0.05894417315721512, 0.008726408705115318, 0.0370209738612175, 0.04383842647075653, 0.0015914510004222393, 0.011000390164554119, -0.007586173713207245, -0.09133855998516083, -0.017960241064429283, -0.005470593925565481, 0.05646015703678131, 0.027121536433696747, -0.04559476301074028, -0.046081945300102234, -0.060977138578891754, -0.03469599038362503, 0.1747344732284546, -0.03431238606572151, 0.026186306029558182, 0.004647037945687771, -0.025956423953175545, 0.0165752861648798, 0.0009522181353531778, 0.05349193513393402, 0.018732229247689247, -0.03701324388384819, 0.05874583125114441, 0.11903483420610428, 0.009711705148220062, -0.018031451851129532, 0.013718953356146812, -0.024636194109916687, 0.017658626660704613, 0.08405585587024689, 0.22935566306114197, 0.0445270910859108, 0.07273023575544357, 0.09934331476688385, 0.05696619302034378, -0.0471552349627018, -0.12969465553760529, 0.020479045808315277, 0.02720257267355919, -0.011201808229088783, -0.15089525282382965, 0.03393229842185974, -0.03848544880747795, 0.09088961780071259, -0.05787360295653343, 0.05929088965058327, -0.027653884142637253, -0.02981552854180336, -0.017159003764390945, 0.029317570850253105, -0.04079794883728027, -0.09183920174837112, 0.04443797096610069, 0.08239676058292389, -0.005234256386756897, 0.0034682152327150106, 0.017811203375458717, -0.07038193941116333, 0.02816718816757202, 0.04451397806406021, -0.018225446343421936, -0.048454511910676956, -0.07535231858491898, 0.07551964372396469, -0.05950745567679405, 0.05782071128487587, 0.01430582720786333, 0.04682323336601257, -0.06441566348075867, -0.06802766025066376, 0.05003197118639946, -0.02618178352713585, 0.05939885973930359, 0.005832392256706953, -0.05010480806231499, -0.010403566062450409, 0.0029418575577437878, -0.10014328360557556, -0.04191119596362114, 0.047005318105220795, 0.06049670651555061, -0.018231548368930817, 0.0729234367609024, -0.004965652246028185, 0.0031512349378317595, 0.18027684092521667, 0.060937508940696716, 0.0441029891371727, 0.08137736469507217, 0.024821868166327477, 0.009091155603528023, -0.11182565987110138, 0.029594067484140396, -0.06701400876045227, -0.06695496290922165, 0.017486581578850746, -0.05104776844382286, -0.03370347246527672, 0.026702238246798515, 0.06920892000198364, -0.025511201471090317, 0.09421266615390778, 0.07729265838861465, 0.047868505120277405, -0.037728454917669296, 0.08922233432531357, 0.048591408878564835, -0.0036619589664041996, 0.14548204839229584, 0.07045459747314453, 0.07261732965707779, 0.031684521585702896, 0.024462152272462845, -0.09110432118177414, -0.12536175549030304, -0.029440466314554214, -0.11099090427160263, 0.105542853474617, 0.057546019554138184, -0.02081681787967682, -0.017047077417373657, 0.09009755402803421, -0.04116532951593399, 0.009722073562443256, 0.08750409632921219, -0.0140022998675704, 0.07773608714342117, 0.07081062346696854, -0.006457127630710602, 0.08159588277339935, 0.0023892621975392103, -0.013982105068862438, 0.1261834353208542, 0.03659052029252052, 0.10033003240823746, -0.05281457304954529, -0.004954898729920387, 0.1257479339838028, -0.026086611673235893, -0.009515098296105862, 0.05939316749572754, -0.007837322540581226, -0.1479477882385254, 0.016612417995929718, 0.006620196159929037, 0.04435395449399948, -0.06698277592658997, 0.024178776890039444, 0.0374426506459713, -0.027690226212143898, 0.04153275489807129, 0.08977867662906647, -0.06431743502616882, -0.05474352464079857, 0.06568732112646103, 0.08242570608854294, -0.010887129232287407, 0.01852988265454769, -0.08068842440843582, 0.14599506556987762, -0.027479471638798714, -0.08816250413656235, -0.09868234395980835, 0.01405759621411562, 0.011440127156674862, -0.057948339730501175, -0.06175613775849342, 0.024795355275273323, -0.11445093154907227, 0.013647542335093021, -0.04504646360874176, -0.08904647082090378, 0.01833576336503029, -0.004791127052158117, 0.02439987286925316, 0.0021852205973118544, -0.1223888099193573, 0.028902219608426094, -0.022478651255369186, 0.06885887682437897, 0.005429770797491074, 0.011928297579288483, -0.20552872121334076, 0.03740290552377701, 0.06833569705486298, -0.04436023533344269, 0.03258507326245308, 0.0014892719918861985, 0.04729243740439415, 0.10115007311105728, -0.000295432546408847, 0.07011423259973526, 0.08278696984052658, -0.0520700067281723, 0.06344971805810928, -0.02571973390877247, 0.08673211932182312, 0.06339197605848312, 0.08426114916801453, -0.01032283902168274, -0.04122136905789375, 0.006692804861813784, -0.03156983479857445, -0.04988590255379677, 0.04138132557272911, 0.023749105632305145, -0.02722736820578575, 0.08611682057380676, 0.030304159969091415, 0.024305693805217743, -0.0328376367688179, 0.05511205270886421, 0.07093323767185211, -0.016538197174668312, 0.08726464211940765, -0.03245586156845093, -0.027805790305137634, -0.04045988246798515, 0.08781979978084564, -0.061066120862960815, -0.041885118931531906, -0.06602668762207031, 0.003769936738535762, 0.05389191210269928, -0.0160076767206192, -0.014020858332514763, -0.0622028112411499, -0.04506570100784302, -0.03593747690320015, -0.003660567570477724, -0.030565308406949043, -0.022045180201530457, -0.01178345549851656, 0.03152718394994736, -0.0252088513225317, 0.060314010828733444, 0.04907607659697533, 1.1895909309387207, 0.03281673416495323, -0.02565036155283451, -0.04388634115457535, -0.049698978662490845, 0.03259219974279404, -0.0009453032398596406, -0.07019492238759995, -0.0761152133345604, 0.027592625468969345, -0.008910372853279114, 0.042739320546388626, -0.04403841122984886, 0.026196228340268135, -0.019422322511672974, -0.006804562173783779, -0.05019931122660637, 0.012751240283250809, 0.04934714734554291, 0.06463629007339478, -0.015814239159226418, 0.10221157222986221, 0.04771501198410988, 0.05714238062500954, -0.18368951976299286, -0.13771939277648926, 0.013752506114542484, -0.025812853127717972, -0.009033935144543648, 0.03506069630384445, 0.006388361565768719, 0.018412038683891296, 0.011328662745654583, 0.013283503241837025, -0.048123687505722046, 0.029530471190810204, -0.02520117349922657, 0.04174065589904785, -0.08431077003479004, -0.016338355839252472, 0.0032806789968162775, -0.03592800348997116, -0.1197565495967865, -0.07798422873020172, 0.0033032798673957586, 0.009607422165572643, 0.036609552800655365, 0.057598818093538284, 0.05838471278548241, 0.010944980196654797, 0.059312377125024796, -0.03359165042638779, -0.07645457237958908, 0.08749861270189285, -0.056318752467632294, 0.054241571575403214, 0.08437687158584595, 0.014259982854127884, 0.008681000210344791, 0.023881694301962852, 0.013052486814558506, -0.01165121141821146, -0.10317013412714005, -0.025873936712741852, -0.07728128135204315, 0.04999078810214996, 0.057736270129680634, 0.06816829741001129, -0.11120464652776718, 0.10394694656133652, -0.025775402784347534, 0.04131754860281944, -0.0140165314078331, 0.016076933592557907, -0.0009772455086931586, 0.035829368978738785, -0.05451960861682892, -0.11522045731544495, -0.02413547970354557, 0.06737188249826431, 0.016852926462888718, -0.038616981357336044, -0.021678606048226357, -0.02990025468170643, 0.05431568622589111, 0.027310417965054512, 0.010016901418566704, -0.13624358177185059, 0.06885787844657898, -0.1089296042919159, -0.1283181607723236, -0.0373230054974556, 0.01244816929101944, -0.005976976361125708, 0.0549926683306694, -0.03861117362976074, -0.07301965355873108, 0.030319787561893463, -0.055443376302719116, -0.16535332798957825, -0.01497392076998949, 0.015667948871850967, -0.08824630826711655, 0.06923984736204147, -0.01051812432706356, 0.011949574574828148, -0.0309958066791296, 0.15761056542396545, 0.021023541688919067, 0.052057571709156036, 0.009870738722383976, 0.05426447466015816, -0.07105446606874466, -0.008162041194736958, 0.04266027733683586, 0.05236533656716347, 0.15452110767364502, -0.010937385261058807, -0.07008304446935654, 0.026658758521080017, 0.026419484987854958, 0.06955815106630325, -0.03805325925350189, -0.016198672354221344, 0.0414390005171299, 0.049349840730428696, 0.0010191798210144043, 0.06590606272220612, 0.009478529915213585, 0.043368443846702576, -0.08700107783079147, -0.002613449702039361, 0.04056709259748459, 0.02566874958574772, -0.03825598210096359, -0.10620914399623871, -0.05436190590262413, -0.030971050262451172, 0.05768227204680443, -0.014199694618582726, 0.005867937114089727, 0.03477535769343376, 0.008478845469653606, -0.07861461490392685, 0.02689487114548683, 0.11036602407693863, -0.08802405744791031, -0.03418447822332382, 0.027606569230556488, 0.053050730377435684, -0.039728470146656036, -0.023490598425269127, -0.03570091724395752, 18.576993942260742, -0.048000019043684006, 0.046926263719797134, 0.006908027455210686, 0.09569171071052551, 0.011724910698831081, 0.007552358787506819, -0.01956249214708805, -0.08653874695301056, 0.014636289328336716, 0.09866639971733093, 0.09304570406675339, -0.12597209215164185, -0.01037309318780899, 0.02489655464887619, 0.01629222370684147, 0.09570398181676865, 0.03501059114933014, -0.01370587944984436, 0.09007340669631958, 0.007850260473787785, 0.08684130758047104, -0.0297644454985857, 0.1062239333987236, -0.09542987495660782, 0.06093659996986389, 0.03976920619606972]\n"
     ]
    }
   ],
   "source": [
    "# from .logic import DenseEncoder\n",
    "\n",
    "dense_enc = DenseEncoder()\n",
    "\n",
    "dense_vec = dense_enc.xlm_roberta_base_encoder(\"Was is Elektrotechnik\")\n",
    "\n",
    "print(dense_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dense_enc.document_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326, 768)\n",
      "hnsw_add_vertices: adding 326 elements on top of 0 (preset_levels=0)\n",
      "  max_level = 0\n",
      "Adding 326 elements at level 0\n",
      "Done in 21.725 ms\n",
      "326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "cmd2 = \"\"\"\n",
    "    python -m pyserini.index.faiss \\\n",
    "        --input /home/peng_luh/__github/search_l3s/search_l3s_search_srv/encodes/dense_encoder \\\n",
    "        --output /home/peng_luh/__github/search_l3s/search_l3s_search_srv/indexes/dense/hnsw \\\n",
    "        --hnsw\n",
    "\"\"\"\n",
    "\n",
    "subprocess.call(cmd2, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder size: 9592 bytes (9.37 KB, 0.01 MB, 0.00 GB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "folder_path = \"/home/peng_luh/__github/search_l3s/search_l3s_search_srv/indexes/bm25/mls-tasks-1\"\n",
    "\n",
    "# Get the size of the folder in bytes\n",
    "folder_size = get_folder_size(folder_path)\n",
    "\n",
    "# Convert to appropriate units (KB, MB, GB, etc.)\n",
    "folder_size_kb = folder_size / 1024\n",
    "folder_size_mb = folder_size_kb / 1024\n",
    "folder_size_gb = folder_size_mb / 1024\n",
    "\n",
    "# Print the folder size\n",
    "print(f\"Folder size: {folder_size} bytes ({folder_size_kb:.2f} KB, {folder_size_mb:.2f} MB, {folder_size_gb:.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(\"/home/peng_luh/__github/search_l3s/search_l3s_search_srv/encodes/dense/xlm_roberta_base/mls-tasks-0/data_encoded.jsonl\"):\n",
    "    print(\"True\")\n",
    "else:\n",
    "    print(\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '/mls-api/tasks/418', 'contents': 'Kick-off Grundlagen der Sensorik - Schwingungssensor; Cover; Sicherheitshinweise; Einfhrung; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/417', 'contents': 'Grundlagen der Sensorik: Schwingungssensor - Betrieblicher Auftrag; Erluterung; Aufgabenstellung; Vereinfachungen/Simulationen; Aufbau und Messanordnung; Nachweis der Funktion\\n'}, {'id': '/mls-api/tasks/416', 'contents': 'Grundlagen der Sensorik: Schwingungssensor - Arbeitsplanung; Arbeitsvorbereitung; Eingesetzter Sensor; Datenblatt; Tastenprogrammierung und Grenzwerte festlegen\\n'}, {'id': '/mls-api/tasks/415', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 2.2: Operationsverstrker als Impedanzwandler und summierender Verstrker; Impedanzwandler; Impedanzwandler (Spannungsfolger); Summierender Verstrker; Summierer in der praktischen bung; Summierer mit Gleich- und Wechselspannung\\n'}, {'id': '/mls-api/tasks/414', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 2.1: Operationsverstrker als Verstrker; Operationsverstrker; Operationsverstrker als invertierender Verstrker; Invertierender Verstrker in der praktischen bung; Dreieckspannung am Eingang; Operationsverstrker als nicht invertierender Verstrker; Nicht invertierender Verstrker in der praktischen bung; Wechselspannung am Eingang\\n'}, {'id': '/mls-api/tasks/413', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.7: Mitkopplung; Mitkopplung; Zweistufiger Verstrker mit Mitkopplung\\n'}, {'id': '/mls-api/tasks/412', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.6: Rckkopplung; Rckkopplung; Wechselstromgegenkopplung; Spannungsgegenkopplung; Zwei Verstrkerstufen\\n'}, {'id': '/mls-api/tasks/411', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.5: Gleichspannungsverstrker und Gegentaktverstrker; Gleichspannungsverstrrker; Zweistufiger Gleichspannungsverstrker; Gegentaktverstrker; Gegentaktendstufe\\n'}, {'id': '/mls-api/tasks/410', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.4: Differenzverstrker; Differenzverstrker; Differenzverstrker fr Gleichspannungen; Differenzverstrker fr Wechselspannungen\\n'}, {'id': '/mls-api/tasks/409', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.3: Emittergekoppelte Verstrker und Phasenumkehrstufen; Emittergekoppelte Verstrker; Zwischenbasisschaltung; Emittergekoppelte Phasenumkehrstufe\\n'}, {'id': '/mls-api/tasks/408', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.2: Darlington-Verstrker; Darlington-Verstrker; Emitterschaltung; Kollektorschaltung\\n'}, {'id': '/mls-api/tasks/407', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.1: Mehrstufige Verstrker; Mehrstufige Verstrker; Zweistufiger Wechselspannungsverstrker\\n'}, {'id': '/mls-api/tasks/406', 'contents': 'Kick-off Schaltungen der Elektronik; Cover; Sicherheitshinweise; Einfhrung und Ablauf\\n'}, {'id': '/mls-api/tasks/405', 'contents': 'Grundlagen S7-1500 Versuch 1 - Transfersystem mit 2 Positionen; Aufbau; Ablaufbeschreibung; Variablentabelle; Ablaufgraph; SPS-Programm; Bausteinschnittstellen fcEndposition; Programm fcEndposition; Bausteinschnittstelle fbTransfersystem; Ablaufgraph fbTransfersystem; Programm fbTransfersystem\\n'}, {'id': '/mls-api/tasks/404', 'contents': 'Kick-off Grundlagen S7-1500; Cover; Sicherheitshinweise; Allgemeines; S7-1500 Familie\\n'}, {'id': '/mls-api/tasks/403', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 5.3: Zweirichtungsthyristor (Triac); Aufbau und Wirkungsweise; Untersuchung eines Triacs; Anschnittsteuerung mit Triac\\n'}, {'id': '/mls-api/tasks/402', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 5.2: Die Thyristortriode; Aufbau und Wirkungsweise; Untersuchung einer Thyristortriode; Verfahren zur Lschung einer Thyristortriode; Anschnittsteuerung mit Thyristortriode\\n'}, {'id': '/mls-api/tasks/401', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 5.1: Thyristoren (Diac); Aufbau und Wirkungsweise; Schaltvorgang eines Diacs; Diac als Sgezahngenerator und Impulsgenerator\\n'}, {'id': '/mls-api/tasks/400', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 4: Unijunktion-Transistor (UJT); Aufbau und Wirkungsweise; Schaltpunkte des Unijunktion-Transistors; Nichtlinearer Sgezahn; Linearer Sgezahn\\n'}, {'id': '/mls-api/tasks/399', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 3.2: Verstrkerstufen mit unipolaren Transistoren; Verstrkerstufen mit unipolaren Transistoren; Verstrkerstufe mit Sperrschicht-FET; Verstrkerstufe mit Isolierschicht-FET; Verstrkergrundschaltungen mit FET; Source-Schaltung; Gate-Schaltung; Drain-Schaltung; Zusammenfassung\\n'}, {'id': '/mls-api/tasks/398', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 3.1: Grundlagen zu unipolaren Transistoren; Aufbau, Wirkungsweise und Schaltzeichen; Sperrschicht FET; Kennlinien von Sperrschicht-FET; Isolierschicht-FET\\n'}, {'id': '/mls-api/tasks/397', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 2.3: Verstrkerstufen mit bipolaren Transistoren; Verstrkerstufen mit bipolaren Transistoren; Untersuchung einer Verstrkerstufe; Verstrkergrundschaltungen; Emitterschaltung; Basisschaltung; Kollektorschaltung; Zusammenfassung\\n'}, {'id': '/mls-api/tasks/396', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 2.2: Kennlinien bipolarer Transistoren; Kennlinien bipolarer Transistoren; Steuerkennlinie; Eingangs- und Ausgangskennlinien; Rckwirkungskennlinie\\n'}, {'id': '/mls-api/tasks/395', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 2.1: Grundlagen zu bipolaren Transistoren; Aufbau und Funktionsweise; Der Transistor als Diode; Wirkungen des Basisstroms auf den Kollektorstrom\\n'}, {'id': '/mls-api/tasks/394', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.4: Dioden mit besonderen Eigenschaften; Dioden mit besonderen Eigenschaften; Leuchtdioden\\n'}, {'id': '/mls-api/tasks/393', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.3: Zener-Dioden; Kennlinie der Zener-Diode; Gleichspannungsbegrenzung; Schaltung mehrerer Z-Dioden; berspannungsschutz und Wechselspannungsbegrenzung; Spannungsstabilisierung\\n'}, {'id': '/mls-api/tasks/392', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.2: Gleichrichterschaltungen; Gleichrichterschaltungen; Einpuls-Mittelpunkt-Schaltung (M1); Zweipuls-Brckenschaltung (B2)\\n'}, {'id': '/mls-api/tasks/391', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.1: Dioden; Strom in Halbleiterwerkstoffen; PN-bergang; PN-bergang; Dioden aus verschiedenen Halbleitermaterialien\\n'}, {'id': '/mls-api/tasks/390', 'contents': 'Kick-off Halbleiterbauelemente der Elektronik; Cover; Sicherheitshinweise; Einfhrung und Ablauf; Sichereres Experimentieren mit Strom und Spannung\\n'}, {'id': '/mls-api/tasks/389', 'contents': 'Regelungstechnik - Projekt 1: Einfhrung in die Regelungstechnik; Temperatursteuerung; Temperaturregelung; Regelkreise analysieren; Regelstreckenarten und Auswahl des Reglers; Die Einheitssprungfunktion\\n'}, {'id': '/mls-api/tasks/388', 'contents': 'Kick-off Regelungstechnik - Projekte; Cover; Sicherheitshinweise; Einfhrung und Ablauf; Versuchsaufbau; Messtechnik fr die Projekte\\n'}, {'id': '/mls-api/tasks/387', 'contents': 'Wechselstromtechnik Versuch 10: Elektromotor; Funktionsprinzip; Gleichstrom-Kommutatormotor; Untersuchung Gleichstrommotor; Grundlagen zum Drehstrommotor; Der Synchronmotor; Untersuchung Synchronmotor\\n'}, {'id': '/mls-api/tasks/386', 'contents': 'Wechselstromtechnik Versuch 9: Transformatoren; Aufgaben und Funktionsweise; Realer vs. idealer Transformator; Spannungs-, Strom-, Widerstandstransformation (bersetzungsverhltnis); Nachweis der Transformatorwirkung\\n'}, {'id': '/mls-api/tasks/385', 'contents': 'Wechselstromtechnik Versuch 8: RLC-Siebschaltungen (Filter); Filter und bertragungsverhalten; Hochpass mit RC-Glied; Tiefpass mit RL-Glied\\n'}, {'id': '/mls-api/tasks/384', 'contents': 'Wechselstromtechnik Versuch 7: Schwingkreise; Entstehung und Resonanz; Reihen- und Parallelschwingkreis; Reihenschwingkreis; Parallelschwingkreis\\n'}, {'id': '/mls-api/tasks/383', 'contents': 'Wechselstromtechnik Versuch 6: Zusammenschaltung von Blind- und Wirkwiderstnden; Arbeiten mit dem Zeigerdiagramm; RL-Reihenschaltung; RC-Reihenschaltung; RLC-Reihenschaltung\\n'}, {'id': '/mls-api/tasks/382', 'contents': 'Wechselstromtechnik Versuch 5.3: Schaltung mehrerer Spulen; Reihenschaltung von Spulen; Parallelschaltung von Spulen\\n'}, {'id': '/mls-api/tasks/381', 'contents': 'Wechselstromtechnik Versuch 5.2: Induktivitt an sinusfrmiger Wechselspannung; Phasenverschiebung; Induktiver Blindwiderstand; Wirk- und Blindleistung an der Spule\\n'}, {'id': '/mls-api/tasks/380', 'contents': 'Wechselstromtechnik Versuch 5.1: Elektromagnetismus und Spulen; Elektromagnetismus und Spulen; Versuch Spule und Elektromagnetismus; Kenngren von Spulen; Ein- und Ausschaltvorgang; Reaktion der Spule auf Rechteckspannungen\\n'}, {'id': '/mls-api/tasks/379', 'contents': 'Wechselstromtechnik Versuch 4.3: Schaltung mehrerer Kondensatoren; Reihenschaltung von Kondensatoren; Parallelschaltung von Kondensatoren\\n'}, {'id': '/mls-api/tasks/378', 'contents': 'Wechselstromtechnik Versuch 4.2: Der Kondensator an sinusfrmiger Wechselspannung; Phasenverschiebung; Der kapazitive Blindwiderstand XC; Wirk- und Blindleistung am Kondensator\\n'}, {'id': '/mls-api/tasks/377', 'contents': 'Wechselstromtechnik Versuch 4.1: Der Kondensator; Aufbau und Kenngren; Arten und Aufgaben; Lade- und Entladevorgnge; Auf- und Entladung; Reaktion des Kondensators auf Rechteckspannungen\\n'}, {'id': '/mls-api/tasks/376', 'contents': 'Wechselstromtechnik Versuch 3.2: Fehler an Drehstromschaltungen; Messungen an einer defekten Sternschaltung; Messungen an einer defekten Dreieckschaltung\\n'}, {'id': '/mls-api/tasks/375', 'contents': 'Wechselstromtechnik Versuch 3.1: Dreiphasenwechselstrom (Drehstrom); Entstehung und Wirkungsweise; Messungen an Drehstromsystemen; Sternschaltung; Messungen an der Sternschaltung; Dreieckschaltung; Messungen an der Dreieckschaltung\\n'}, {'id': '/mls-api/tasks/374', 'contents': 'Wechselstromtechnik Versuch 2: Wirkleistung von Wechselspannungen; Herleitung der Wechselstromleistung; Wirkleistung der Sinuswechselspannung\\n'}, {'id': '/mls-api/tasks/373', 'contents': 'Wechselstromtechnik Versuch 1: Stromarten und ihre Kenngren; Stromarten; Kenngren von Sinusspannungen; Kenngren der Sinusspannung; Kenngren von Rechteckwechselspannungen; Kenngren von Dreieckwechselspannungen\\n'}, {'id': '/mls-api/tasks/372', 'contents': 'Kick-off Wechselstromtechnik; Cover; Sicherheitshinweise; Einfhrung und Ablauf; Sichereres Experimentieren mit Strom und Spannung\\n'}, {'id': '/mls-api/tasks/371', 'contents': 'Gleichstromtechnik Versuch 9: Leistungs-, Spannungs- und Stromanpassung; Herleitung und Bedeutung der Belastungsflle; Praktische bung zu den Belastungsfllen\\n'}, {'id': '/mls-api/tasks/370', 'contents': 'Gleichstromtechnik Versuch 8: Wirkungsgrad der elektrischen Leistung; Definition und Bedeutung des Wirkungsgrades; Praktische bung zum Wirkungsgrad\\n'}, {'id': '/mls-api/tasks/369', 'contents': 'Gleichstromtechnik Versuch 7: Elektrische Leistung und Arbeit; Arbeit und Leistung im Stromkreis; Arbeit und Leistung im Stromkreis; Leistungshyperbel\\n'}, {'id': '/mls-api/tasks/368', 'contents': 'Gleichstromtechnik Versuch 6: Zusammenschaltung von Spannungsquellen; Darstellung von Spannungsquellen; Reihenschaltung von Spannungsquellen; Parallelschaltung von Spannungsquellen\\n'}, {'id': '/mls-api/tasks/367', 'contents': 'Gleichstromtechnik Versuch 5: Ersatzspannungsquelle; Ersatzspannungsquelle; Ersatzspannungsquellen\\n'}, {'id': '/mls-api/tasks/366', 'contents': 'Gleichstromtechnik Versuch 4: Spannungs- und Stromfehlerschaltung; Spannungs- und Stromfehlerschaltung; Anwendung von Spannungs- und Stromfehlerschaltung\\n'}, {'id': '/mls-api/tasks/365', 'contents': 'Gleichstromtechnik Versuch 3.6: Der Spannungsteiler; Der unbelastete Spannungsteiler; Unbelastete Spannungsteiler; Der belastete Spannungsteiler; Belastete Spannungsteiler\\n'}, {'id': '/mls-api/tasks/364', 'contents': 'Gleichstromtechnik Versuch 3.5: Kombinationen von Reihen- und Parallelschaltung; Kombinationen von Reihen und Parallelschaltung; Widerstandsnetzwek 1; Widerstandsnetzwerk 2\\n'}, {'id': '/mls-api/tasks/363', 'contents': 'Gleichstromtechnik Versuch 3.4: Parallelschaltung von Widerstnden; Parallelschaltung von Widerstnden; Untersuchung einer Parallelschaltung\\n'}, {'id': '/mls-api/tasks/362', 'contents': 'Gleichstromtechnik Versuch 3.3: Reihenschaltung von Widerstnden; Reihenschaltung von Widerstnden; Untersuchung einer Reihenschaltung\\n'}, {'id': '/mls-api/tasks/361', 'contents': 'Gleichstromtechnik Versuch 3.2: Elektrische Widerstnde Teil 2; Der PTC-Widerstand (Kaltleiter); Spannungsabhngige Widerstnde (VDR); Fotowiderstnde (LDR)\\n'}, {'id': '/mls-api/tasks/360', 'contents': 'Gleichstromtechnik Versuch 3.1: Elektrische Widerstnde Teil 1; Arten und Eigenschaften elektrischer Widerstnde; Lineare Widerstnde; Der NTC-Widerstand (Heileiter)\\n'}, {'id': '/mls-api/tasks/359', 'contents': \"Gleichstromtechnik Versuch 2: Das Ohm'sche Gesetz; Das Ohm'sche Gesetz; Abhngigkeit des Stroms von der Spannung; Abhngigkeit des Stroms vom Widerstand\\n\"}, {'id': '/mls-api/tasks/358', 'contents': 'Gleichstromtechnik Versuch 1: Der elektrische Stromkreis; Bestandteile und Funktion; Elektrische Grundgren; Der Stromkreis im praktischen Versuch; Messungen im Grundstromkreis\\n'}, {'id': '/mls-api/tasks/357', 'contents': 'Kick-off Gleichstromtechnik; Cover; Sicherheitshinweise; Einfhrung und Ablauf; Sichereres Experimentieren mit Strom und Spannung\\n'}, {'id': '/mls-api/tasks/356', 'contents': 'Ihr Feedback an uns; Willkommen; Feedbackbogen\\n'}, {'id': '/mls-api/tasks/355', 'contents': 'Halbleitertechnik Versuch 4: Operationsverstrker; Aufbau und Wirkungsweise ; Invertierender Verstrker; Nichtinvertierender Verstrker\\n'}, {'id': '/mls-api/tasks/354', 'contents': 'Halbleitertechnik Versuch 3: Die Thyristortriode; Aufbau und Wirkungsweise; Znd- und Lschvorgang; Verfahren zum Lschen\\n'}, {'id': '/mls-api/tasks/353', 'contents': 'Halbleitertechnik Versuch 2.2.: Verstrkerstufen; Verstrkerstufen; Arbeitspunkt einer Verstrkerstufe; Arbeitspunkt einer Verstrkerstufe\\n'}, {'id': '/mls-api/tasks/352', 'contents': 'Halbleitertechnik Versuch 2.1: Bipolare Transistoren; Aufbau und Funktionsweise; Diodenwirkung NPN-Transistor (1); Diodenwirkung NPN-Transistor (2); Wirkung von I_B auf I_C\\n'}, {'id': '/mls-api/tasks/351', 'contents': 'Halbleitertechnik Versuch 1.4: Leuchtdioden; Leuchtdioden; Lichtausbeute\\n'}, {'id': '/mls-api/tasks/350', 'contents': 'Halbleitertechnik Versuch 1.3: Die Zener-Diode; Kennlinie der Zener-Diode; Kennlinie im Sperrbetrieb; Gleichspannungsbegrenzungen mit der Z-Diode\\n'}, {'id': '/mls-api/tasks/349', 'contents': 'Halbleitertechnik Versuch 1.2: Gleichrichterschaltungen; Gleichrichterschaltung; Einpuls-Mittelpunkt-Schaltung (M1); Einpuls-Mittelpunkt-Schaltung M1 ohne und mit Glttungskondensator\\n'}, {'id': '/mls-api/tasks/348', 'contents': 'Halbleitertechnik Versuch 1.1: PN-bergang als Diode; Wirkungsweise eines PN-bergangs; PN-bergang als Diode; PN-bergang als Diode\\n'}, {'id': '/mls-api/tasks/347', 'contents': 'Montage- und Demontageautomat Versuch 5: Vollfunktion Montieren/Demontieren; Beschreibung; Erweiterungen des Aufbaus; Ablaufbeschreibung; Ablaufgraph; Programmerstellung in FUP\\n'}, {'id': '/mls-api/tasks/346', 'contents': 'Montage- und Demontageautomat Versuch 4: Einfahrt beidseitige Montage; Beschreibung; Erweiterungen des Aufbaus; Ablaufbeschreibung; Ablaufgraph; Programmerstellung in FUP\\n'}, {'id': '/mls-api/tasks/345', 'contents': 'Montage- und Demontageautomat Versuch 3: Demontagefunktion; Beschreibung; Einrichten; Aufbau; Ablaufbeschreibung; Ablaufgraph; Festlegung der Steuerung; Programmerstellung in FUP\\n'}, {'id': '/mls-api/tasks/344', 'contents': 'Montage- und Demontageautomat Versuch 2: Montagefunktion; Beschreibung; Einrichten; Aufbau; Ablaufbeschreibung; Ablaufgraph; Festlegung der Steuerung; Programmerstellung in FUP\\n'}, {'id': '/mls-api/tasks/343', 'contents': 'Kick-off Montage- und Demontageautomat; Cover; Sicherheitshinweise; Einfhrung und Ablauf; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/342', 'contents': 'LOGO! 8 PLC Board Versuch 4.2: Aufgabe Geschwindigkeitssteuerung; Versuchsablauf; Geschwindigkeitssteuerung; Stromlaufplan und Programm; Versuchsaufbau\\n'}, {'id': '/mls-api/tasks/341', 'contents': 'LOGO! 8 PLC Board Versuch 4.1: Aufgabe Bandsteuerung; Versuchsablauf; Aufgabe Bandsteuerung Tippbetrieb; Stromlaufplan und Programm; Versuchsaufbau; Aufgabe Erweiterung Tippbetrieb; Stromlaufplan und Programm; Versuchsaufbau\\n'}, {'id': '/mls-api/tasks/340', 'contents': 'LOGO! 8 PLC Board Versuch 3: Aufgabe Biegemaschine; Versuchsablauf; Aufgabe Biegemaschine; Stromlaufplan und Programm; Versuchsaufbau\\n'}, {'id': '/mls-api/tasks/339', 'contents': 'LOGO! 8 PLC Board Versuch 2: Aufgabe Kugellagerpresse; Versuchsablauf; Betriebsmittelkennzeichnung; Aufgabe Kugellagerpresse; Stromlaufplan und Programm; Versuchsaufbau; Aufgabe Kugellagerpresse Erweiterung; Stromlaufplan und Programm; Versuchsaufbau; Ermittlung der Endlage des Zylinders; Stromlaufplan und Programm\\n'}, {'id': '/mls-api/tasks/338', 'contents': 'LOGO! 8 PLC Board Versuch 1: Erste Programme; Versuchsablauf; Mensprache einstellen; UND-Schaltung; Programmierung der UND-Verknpfung am Display; ODER-Schaltung; Netzwerkeinstellungen; Schaltprogramm laden; Schaltprogramm anpassen und simulieren; Schaltprogramm in die LOGO! laden und testen\\n'}, {'id': '/mls-api/tasks/337', 'contents': 'Grundlagen der Steuerungstechnik: Arbeitsvorbereitung; Steuern vs. Regeln; EVA-Prinzip; Steuerungsarten; Einsatzgebiete VPS und SPS; Arbeitsweise einer SPS; Not-Halt- und Not-Aus- Funktionen; ffner und Schlieer; Logische Operationen; bersicht Logikgatter\\n'}, {'id': '/mls-api/tasks/336', 'contents': 'Kick-off LOGO! 8 PLC (Professional) Board 24V; Cover; Sicherheitshinweise; Einfhrung; Ablauf\\n'}, {'id': '/mls-api/tasks/335', 'contents': 'Regelungstechnik Versuch 4: Fllstandregelung mit stetigem Regler; Fllstandregelung; Funktionsweise der Fllstandstrecke; Regelkreis mit P-Regler; Reglereinstellugen fr den PI-Regler; Fllstandregelung mit PI-Regler\\n'}, {'id': '/mls-api/tasks/334', 'contents': 'Regelungstechnik Versuch 3: Regelkreis mit unstetigem Regler; Zweipunktregler; Dreipunktregler; Hysterese des Zweipunktreglers; Temperaturregelung mit Zweipunktregler\\n'}, {'id': '/mls-api/tasks/333', 'contents': 'Regelungstechnik Versuch 2: Regelkreis mit stetigem Regler; Einteilung von Regelungen; Regelkreis analysieren; Regelstreckenarten und Auswahl des Reglers; Der P-Regler; Einstellregeln nach Ziegler / Nichols; Der PI-Regler; Der PID-Regler\\n'}, {'id': '/mls-api/tasks/332', 'contents': 'Regelungstechnik Versuch 1: Beispiel einer Drehzahlstrecke; Einfhrung in die Regelungstechnik; Begriffserluterungen: Steuerstrecke; Drehzahlsteuerung; Begriffserluterungen: Regelstrecke; Drehzahlregelung\\n'}, {'id': '/mls-api/tasks/331', 'contents': 'Kick-off Regelungstechnik - Grundlagen; Cover; Sicherheitshinweise; Einfhrung und Ablauf; Versuchsaufbau\\n'}, {'id': '/mls-api/tasks/330', 'contents': 'Elektrotechnik 1 Versuch 13: Elektromotor; Funktionsprinzip; Gleichstrom-Kommutatormotor; Untersuchung Gleichstrommotor; Grundlagen zum Drehstrommotor; Der Synchronmotor; Untersuchung Synchronmotor\\n'}, {'id': '/mls-api/tasks/329', 'contents': 'Elektrotechnik 1 Versuch 12: Transformatoren; Aufgaben und Funktionsweise; Realer vs. idealer Transformator; Spannungs-, Strom-, Widerstandstransformation (bersetzungsverhltnis); Nachweis der Transformatorwirkung\\n'}, {'id': '/mls-api/tasks/328', 'contents': 'Elektrotechnik 1 Versuch 11: Elektromagnetismus und Spulen; Elektromagnetismus und Spulen; Kenngren von Spulen; Grundstzliches zum Ein- und Ausschaltvorgang an der Spule; Versuch Spule und Elektromagnetismus; Phasenverschiebung; Induktiver Blindwiderstand\\n'}, {'id': '/mls-api/tasks/327', 'contents': 'Elektrotechnik 1 Versuch 10: Der Kondensator; Aufbau und Kenngren; Arten und Aufgaben; Lade- und Entladevorgnge; Auf- und Entladung; Phasenverschiebung\\n'}, {'id': '/mls-api/tasks/326', 'contents': 'Elektrotechnik 1 Versuch 9: Dreiphasenwechselstrom (Drehstrom); Entstehung und Wirkungsweise; Sternschaltung; Dreieckschaltung; Messungen an Drehstromsystemen; Messungen an der Sternschaltung; Messungen an der Dreieckschaltung\\n'}, {'id': '/mls-api/tasks/325', 'contents': 'Elektrotechnik 1 Versuch 8: Wirkleistung von Wechselspannungen; Herleitung der Wechselstromleistung; Wirkleistung der Sinuswechselspannung\\n'}, {'id': '/mls-api/tasks/324', 'contents': 'Elektrotechnik 1 Versuch 7: Stromarten und ihre Kenngren; Stromarten; Herleitung der Kenngren; Kenngren der Sinusspannung\\n'}, {'id': '/mls-api/tasks/323', 'contents': 'Elektrotechnik 1 Versuch 6: Wirkungsgrad; Definition und Bedeutung des Wirkungsgrades; Versuch\\n'}, {'id': '/mls-api/tasks/322', 'contents': 'Elektrotechnik 1 Versuch 5: Elektrische Leistung und Arbeit; Arbeit und Leistung im Stromkreis; Versuch\\n'}, {'id': '/mls-api/tasks/321', 'contents': 'Elektrotechnik 1 Versuch 4: Zusammenschaltung von Spannungsquellen; Symbolische Darstellung; Reihenschaltung; Versuch\\n'}, {'id': '/mls-api/tasks/320', 'contents': 'Elektrotechnik 1 Versuch 3.2: Verschaltung elektrischer Widerstnde; Die Reihenschaltung von Widerstnden; Nachweis der Eigenschaften einer Reihenschaltung von Widerstnden; Die Parallelschaltung von Widerstnden; Nachweis der Eigenschaften parallel geschalteter Widerstnde; Unbelasteter Spannungsteiler; Belasteter Spannungsteiler; Festes Widerstandsverhltnis\\n'}, {'id': '/mls-api/tasks/319', 'contents': 'Elektrotechnik 1 Versuch 3.1: Eigenschaften elektrischer Widerstnde; Arten und Eigenschaften elektrischer Widerstnde; Lineare Kennlinie I=f(U); NTC-Kennlinien I = f (U) und R = f (U); Abhngigkeit des LDR von der Beleuchtungsstrke\\n'}, {'id': '/mls-api/tasks/318', 'contents': \"Elektrotechnik 1 Versuch 2: Ohm'sches Gesetz; Aussage und Bedeutung des Ohmschen Gesetzes; Das ohmsche Gesetz im Praxisversuch; Untersuchung der Abhngigkeit des Stroms von der Spannung; Messung der Stromstrke ber dem Widerstand\\n\"}, {'id': '/mls-api/tasks/317', 'contents': 'Elektrotechnik 1 Versuch 1: Der elektrische Stromkreis; Bestandteile und Funktion eines elektrischen Stromkreises; Beschreibung der elektrischen Grundgren; Der Stromkreis im praktischen Versuch; Messung von Spannung und Stromstrke\\n'}, {'id': '/mls-api/tasks/316', 'contents': 'Kick-off Grundlagen der Elektrotechnik Teil 1; Cover; Sicherheitshinweise; Einfhrung und Ablauf; Sicheres Experimentieren mit Strom und Spannung\\n'}, {'id': '/mls-api/tasks/315', 'contents': 'Grundlagen der Elektropneumatik: Aufgaben 6-10; Aufgabe 6: Spannvorrichtung (zeitabhngige Ablaufsteuerung); Aufgabe 7: Pneumatischer Vorschub (zeitabhngige Ablaufsteuerung); Aufgabe 8: Tauchbecken (Sicherheitsschaltung); Versuch 9: Positionierung / Erfassung; Aufgabe 10: Druckautomat\\n'}, {'id': '/mls-api/tasks/314', 'contents': 'Grundlagen der Elektropneumatik: Aufgaben 1-5; Versuchsaufbau; Aufgabe 1: Sicherheitstr; Aufgabe 2: Palettenlift; Aufgabe 3: Demontage; Aufgabe 4: Montage; Aufgabe 5: Werkstcklift (Parallelschaltung)\\n'}, {'id': '/mls-api/tasks/313', 'contents': 'Kick-off Grundlagen Elektropneumatik; Cover; Sicherheitshinweise; Projektvorstellung; Was ist Pneumatik?; Herstellen von Druckluft\\n'}, {'id': '/mls-api/tasks/312', 'contents': 'Grundlagen der Sensorik: RFID - Versuch 3: Beschreiben und Lesen des Transponders; Codierung (1); Codierung (2); Beschreiben des Transponders in der Anlage; Lesen des Transponders\\n'}, {'id': '/mls-api/tasks/311', 'contents': 'Grundlagen der Sensorik: RFID - Versuch 2: Materialeinflsse; Luftschnittstellenmaterial; Applikationsmaterial\\n'}, {'id': '/mls-api/tasks/310', 'contents': 'Grundlagen der Sensorik: RFID - Versuch 1: Lesebereich; Verwendete Materialien; Versuchsaufbau; Verbindung mit dem Reader (1); Verbindung mit dem Reader (2); Lesebereich ermitteln - 0-Orientierung; Lesebereich ermitteln - 90-Orientierung\\n'}, {'id': '/mls-api/tasks/309', 'contents': 'Grundlagen der Sensorik: RFID - Arbeitsvorbereitung Betrieblicher Auftrag; Vorberlegungen (1); Vorberlegungen (2); Vereinfachung in der Modellanlage\\n'}, {'id': '/mls-api/tasks/308', 'contents': 'Kick-off Grundlagen der Sensorik - RFID Identifikationsverfahren; Cover; Sicherheitshinweise; Einfhrung; Projektbeschreibung\\n'}, {'id': '/mls-api/tasks/307', 'contents': 'Grundlagen der Pneumatik: Aufgaben 6-10; Aufgabe 6 - Doppelschiebetr (zeitabhngige Ablaufsteuerung); Aufgabe 7 - Hubtisch (Ablaufsteuerung); Aufgabe 8 - Prgemaschine (Kaskadensteuerung); Aufgabe 9 - Montageautomat (Kaskadensteuerung); Aufgabe 10 - Umformmaschine (Ablaufsteuerung)\\n'}, {'id': '/mls-api/tasks/306', 'contents': 'Grundlagen der Pneumatik: Aufgaben 1-5; Versuchsaufbau; Aufgabe 1 - Dachfenster (Direktansteuerung); Aufgabe 2 - Presse 01 (Direktansteuerung); Aufgabe 3 - Presse 02 (UND-Verknpfung); Aufgabe 4 - Falllager (Ablaufsteuerung); Aufgabe 5 - Schiebetr (zeitabhngige Ablaufsteuerung)\\n'}, {'id': '/mls-api/tasks/305', 'contents': 'Grundlagen der Pneumatik: Arbeitsvorbereitung; Pneumatische Bauteile; Referenzkennzeichung; Steuerungstechnik; Komponenten von Steuerungen und Schaltplan; Ablaufsteuerung mit GRAFCET\\n'}, {'id': '/mls-api/tasks/304', 'contents': 'Kick-off Grundlagen der Pneumatik; Cover; Sicherheitshinweise; Projektvorstellung; Was ist Pneumatik?; Herstellen von Druckluft\\n'}, {'id': '/mls-api/tasks/303', 'contents': 'Grundlagen der Elektropneumatik mit tec2SKILL connect: Aufgaben 6-9; Aufgabe 6: Spannvorrichtung (zeitabhngige Ablaufsteuerung); Aufgabe 7: Pneumatischer Vorschub (zeitabhngige Ablaufsteuerung); Aufgabe 8: Tauchbecken (Sicherheitsschaltung); Aufgabe 9: Druckautomat\\n'}, {'id': '/mls-api/tasks/302', 'contents': 'Grundlagen der Elektropneumatik mit tec2SKILL connect: Aufgaben 1-5; Aufgabe 1: Sicherheitstr; Aufgabe 2: Palettenlift; Aufgabe 3: Demontage; Aufgabe 4: Montage; Aufgabe 5: Werkstcklift (Parallelschaltung)\\n'}, {'id': '/mls-api/tasks/301', 'contents': 'Grundlagen der Elektropneumatik: Arbeitsvorbereitung; Pneumatische Bauteile; Elektropneumatische Bauteile; Referenzkennzeichung; Steuerungstechnik; Komponenten von Steuerungen und Schaltplan; Ablaufsteuerung mit GRAFCET\\n'}, {'id': '/mls-api/tasks/300', 'contents': 'Kick-off Elektropneumatik mit tec2SKILL connect; Cover; Sicherheitshinweise; Projektvorstellung; Was ist Pneumatik?; Herstellen von Druckluft\\n'}, {'id': '/mls-api/tasks/299', 'contents': '43213SIOL Versuch 4: Sensoranordnung fr vorbeifahrende Kunststoffe; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Messaufbau und Funktionstest; Nachweis der Funktion; Nachweis des Reduktionsfaktors\\n'}, {'id': '/mls-api/tasks/298', 'contents': '43213SIOL Versuch 3: Fllstanderfassung eines Tanks planen und ausfhren; Auftrag; Simulation der Aufgabenstellung; Arbeitsplanung; Informationsbeschaffung und Sensorauswahl; Messaufbau und Funktionstest; Sensor programmieren; Analogausgang programmieren; Schaltausgang programmieren; Sensor ber IO-Link programmieren (1); Sensor ber IO-Link programmieren (2)\\n'}, {'id': '/mls-api/tasks/297', 'contents': '43213SIOL Versuch 2:  Fllstandserfassung eines Palettenlagers; Auftrag; Simulation der Aufgabenstellung; Arbeitsplanung; Informationsbeschaffung und Sensorauswahl; Messaufbau und Funktionstest; Sensor einstellen (Teach); Nachweis der Funktion; Nachweis der Hysterese; Detektionsverhalten bei Verkippung\\n'}, {'id': '/mls-api/tasks/296', 'contents': '43213SIOL Versuch 1: Sensoranordnung fr vorbeifahrende Metalle; Auftrag; Simulation der Aufgabenstellung; Arbeitsplanung; Informationsbeschaffung und Sensorauswahl; Messaufbau und Funktionstest; Nachweis der Funktion; Nachweis des Schaltabstands ; Nachweis des Reduktionsfaktors; Nachweis der Hyterese\\n'}, {'id': '/mls-api/tasks/295', 'contents': 'Analoge Sensorik Versuch 3:  Prfung des Behlterdeckels; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Messgert einstellen; Nachweis der Funktion; Nachweis des Schaltabstandes; Nachweis des Reduktionsfaktors\\n'}, {'id': '/mls-api/tasks/294', 'contents': 'Analoge Sensorik Versuch 2:  Fllstandserfassung eines Lagers fr Behlter; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Sensor einstellen (Teach); Nachweis der Funktion; Nachweis der Hysterese; Ermittlung der Schallkeule; Detektionsverhalten bei Verkippung\\n'}, {'id': '/mls-api/tasks/293', 'contents': 'Analoge Sensorik Versuch 1:  Fllstandserfassung eines Palettenlagers; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Sensor einstellen (Teach); Nachweis der Funktion; Nachweis der Hysterese; Nachweis der Reflektivitt; Detektionsverhalten bei Verkippung\\n'}, {'id': '/mls-api/tasks/292', 'contents': 'Arbeitsplanung Analoge Sensorik; Verfgbare Sensoren; Schritte der Arbeitsplanung\\n'}, {'id': '/mls-api/tasks/291', 'contents': 'ETS WebTECH4U ; Begrung; Digitale Lerninhalte; Highlights im berblick\\n'}, {'id': '/mls-api/tasks/290', 'contents': 'Grundlagen der Sensorik: Drehgeber - Versuch 3: Hochregallager CPS i40; Einfhrung; Versuchsaufbau Lngsachse; Versuchsdurchfhrung Lngsachse; Versuchsaufbau Palettenaufnehmer; Versuchsdurchfhrung Palettenaufnehmer\\n'}, {'id': '/mls-api/tasks/289', 'contents': 'Grundlagen der Sensorik: Drehgeber - Versuch 2: Seilzug-Encoder am Gabelstapler; Einfhrung; Versuchsbeschreibung und verwendete Materialien; Versuchsdurchfhrung\\n'}, {'id': '/mls-api/tasks/288', 'contents': 'Grundlagen der Sensorik: Drehgeber - Versuch 1: Messradsystem an einer Furnierschlmaschine; Einfhrung; Versuchsbeschreibung und verwendete Materialien; Versuchsdurchfhrung\\n'}, {'id': '/mls-api/tasks/287', 'contents': 'Grundlagen der Sensorik: Drehgeber - Erstinbetriebnahme des Messradaufbaus; Verkabelung; Sensor auslesen (1); Sensor auslesen (2); Messradaufsatz positionieren\\n'}, {'id': '/mls-api/tasks/286', 'contents': 'Grundlagen der Sensorik: Drehgeber - Arbeitsvorbereitung; Grundlagen und Verstndnisfragen; Datenblatt\\n'}, {'id': '/mls-api/tasks/285', 'contents': 'Kick-off Grundlagen der Sensorik - Drehgeber; Cover; Sicherheitshinweise; Einfhrung; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/284', 'contents': 'Grundlagen der Sensorik: Schwingungssensor - Betrieblicher Auftrag; Erluterung; Aufgabenstellung; Vereinfachungen/Simulationen; Aufbau und Messanordnung; Nachweis der Funktion\\n'}, {'id': '/mls-api/tasks/283', 'contents': 'Grundlagen der Sensorik: Schwingungssensor - Arbeitsplanung; Arbeitsvorbereitung; Eingesetzter Sensor; Datenblatt; Tastenprogrammierung und Grenzwerte festlegen\\n'}, {'id': '/mls-api/tasks/282', 'contents': 'Kick-off Grundlagen der Sensorik - Schwingungssensor; Cover; Sicherheitshinweise; Einfhrung; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/281', 'contents': 'Grundlagen der Sensorik: RFID - Versuch 2: Materialeinflsse und Beschreiben des Transponders; Luftschnittstellenmaterial; Applikationsmaterial; Beschreiben des Transponders in der Anlage\\n'}, {'id': '/mls-api/tasks/280', 'contents': 'Grundlagen der Sensorik: RFID - Versuch 1: Lesebereich; Verwendete Materialien; Versuchsaufbau; Verbindung mit dem Reader; Lesebereich ermitteln - 0-Orientierung; Lesebereich ermitteln - 90-Orientierung\\n'}, {'id': '/mls-api/tasks/279', 'contents': 'Grundlagen der Sensorik: RFID - Arbeitsvorbereitung Betrieblicher Auftrag; Vorberlegungen (1); Vorberlegungen (2); Vereinfachung in der Modellanlage; Codierung\\n'}, {'id': '/mls-api/tasks/278', 'contents': 'Kick-off Grundlagen der Sensorik - RFID Identifikationsverfahren; Cover; Sicherheitshinweise; Einfhrung; Projektbeschreibung\\n'}, {'id': '/mls-api/tasks/277', 'contents': 'Grundlagen der Sensorik: Pt100 - Versuch 2 Ermittlung der Widerstandskennlinie; Erluterung; Widerstandsmessung; Widerstandskennlinie\\n'}, {'id': '/mls-api/tasks/276', 'contents': 'Grundlagen der Sensorik : Pt100 - Versuch 1 Temperaturmessung eines Khlkreislaufes; Erluterung; Simulation der Aufgabenstellung; Arbeitsplanung; Aufbau der Messanordnung; Messgert einstellen; Nachweis der Funktion; Auswertung des Versuchs\\n'}, {'id': '/mls-api/tasks/275', 'contents': 'Grundlagen der Sensorik: Pt100 - Vorbereitung; Was ist Temperatur?; Temperatursensor Pt100; Temperatur-Stabsensor TT0281\\n'}, {'id': '/mls-api/tasks/274', 'contents': 'Kick-off Grundlagen der Sensorik - Platin Messwiderstand Pt100; Cover; Sicherheitshinweise; Einfhrung und Ablauf\\n'}, {'id': '/mls-api/tasks/273', 'contents': 'Grundlagen der Sensorik: Zylindersensoren - Versuch 2: Bohrtiefenmessung; Versuchsbeschreibung; Versuchsaufbau; Manuelle Parametrierung; Messung der Bohrtiefen; Parametrierung und Messung ber IO-Link\\n'}, {'id': '/mls-api/tasks/272', 'contents': 'Grundlagen der Sensorik: Zylindersensoren - Versuch 1: Pneumatische Deckelmontage; Versuchsbeschreibung; Versuchsaufbau; Anschlieen und Justieren des Sensors D-M9BL (SMC); Anschlieen und Justieren des Sensors MZC1 (Sick)\\n'}, {'id': '/mls-api/tasks/271', 'contents': 'Grundlagen der Sensorik: Zylindersensoren - Arbeitsvorbereitung; Magnetische Zylindersensoren; Allgemeiner Aufbau; Montage; Verwendete Sensoren\\n'}, {'id': '/mls-api/tasks/270', 'contents': 'Kick-off: Grundlagen der Sensorik - Zylindersensoren; Cover; Sicherheitshinweise; Einfhrung und Ablauf\\n'}, {'id': '/mls-api/tasks/269', 'contents': 'Prfung elektrischer Anlagen Versuch 3.3: Erstprfung im IT-Netz; Arbeitsauftrag; Arbeitsplanung; Versuchsaufbau; Ergnzung des IT-Systems mit RCD-Schutzschaltern\\n'}, {'id': '/mls-api/tasks/268', 'contents': 'Prfung elektrischer Anlagen Versuch 3.2: Erstprfung im TT-Netz; Arbeitsauftrag; Versuchsaufbau; Prfung der Erd- und Potentialausgleichsverbindung; Durchfhrung der Erstprfung; Messung der Fehlerspannung bzw. des Erdungswiderstands\\n'}, {'id': '/mls-api/tasks/267', 'contents': 'Prfung elektrischer Anlagen Versuch 3.1: Erstprfung im TN-Netz; Arbeitsauftrag; Versuchsaufbau; Messen des Erdungswiderstands\\n'}, {'id': '/mls-api/tasks/266', 'contents': 'Elektroenergieversorgung und Sicherheit von Betriebsmitteln Versuch 2.4: Prfungen und Messungen an RCD-Schutzeinrichtungen / Drehfeldrichtung; Prfungen und Messungen an RCD-Schutzeinrichtungen; Versuchsdurchfhrung; Drehfeldrichtung\\n'}, {'id': '/mls-api/tasks/265', 'contents': 'Elektroenergieversorgung und Sicherheit von Betriebsmitteln Versuch 2.3: Isolationswiderstand und Schleifenwiderstand; Isolationswiderstand; Messung Isolationswiderstand; Schleifenwiderstand; Messung Schleifenwiderstand im TN-S-Netz; Messung Schleifenwiderstand im TT-Netz\\n'}, {'id': '/mls-api/tasks/264', 'contents': 'Elektroenergieversorgung und Sicherheit von Betriebsmitteln Versuch 2.2: Hauptpotenzialausgleich; Hauptpotenzialausgleich; Messung\\n'}, {'id': '/mls-api/tasks/263', 'contents': 'Elektroenergieversorgung und Sicherheit von Betriebsmitteln Versuch 2.1: Hausanschluss, Leitungen, Zhlerplatz; Der Hausanschluss; Leitungen; Zhlerplatz\\n'}, {'id': '/mls-api/tasks/262', 'contents': 'Netzsysteme und Schutzmanahmen Versuch 1.5: Das IT-System; Das IT-System; Aufgabe\\n'}, {'id': '/mls-api/tasks/261', 'contents': 'Netzsysteme und Schutzmanahmen Versuch 1.4: Erdungswiderstand; Erdungswiderstand; Messung des Erdungswiderstands; Messung des Erdungswiderstands nach der Dreileitermethode; Messung des Erdungswiderstands mittels Fehlerschleifenimpedanz; Selektive Erdungswiderstandsmessung\\n'}, {'id': '/mls-api/tasks/260', 'contents': 'Netzsysteme und Schutzmanahmen Versuch 1.3: Automatische Abschaltung durch RCD-Schutzschalter; RCD-Schutzschalter; Typen und Auslseverhalten von Fehlerstromschutzschaltern; Prfung von RCD-Schutzschaltern; Messung im TN-S-Netz; Messung im TT-Netz\\n'}, {'id': '/mls-api/tasks/259', 'contents': 'Netzsysteme und Schutzmanahmen Versuch 1.2: Schutz gegen elektrischen Schlag; Schutz gegen elektrischen Schlag; Fehlerarten; Geforderte Abschaltzeit; Ermitteln des bentigten Abschaltstroms; Messbung zum TN-S-Netz; Messbung zum TT-Netz\\n'}, {'id': '/mls-api/tasks/258', 'contents': 'Netzsysteme und Schutzmanahmen Versuch 1.1: Netzsysteme; Kennzeichnung von Netzsystemen; Prinzipschaltbild eines Netzsystems; Messbung TN-C-Netz; Messbung TN-S-Netz; Messbung TT-Netz; Messbung IT-Netz\\n'}, {'id': '/mls-api/tasks/257', 'contents': 'Kick-off Netzsysteme und Schutzmanahmen; Cover; Sicherheitshinweise; Inhaltsverzeichnis; Bentigte Hardware\\n'}, {'id': '/mls-api/tasks/256', 'contents': 'Elektromotoren 1 - Versuch 3: Gleichstrom-Doppelschlussmaschine; Einfhrung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationren Betrieb; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/255', 'contents': 'Elektromotoren 1 - Versuch 2: Gleichstrom-Reihenschlussmaschine; Einfhrung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationren Betrieb; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/254', 'contents': 'Elektromotoren 1 - Versuch 1: Gleichstrom-Nebenschlussmaschine; Einfhrung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationren Betrieb; Auswertung der Ergebnisse; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/253', 'contents': 'Kick-off  Elektromotoren Teil 1: Gleichstrommotoren; Cover; Sicherheitshinweise; Einfhrung und Ablauf\\n'}, {'id': '/mls-api/tasks/252', 'contents': 'Digitaltechnik Versuch 13: Digital-Analog-Umsetzer; Digital-Analog-Umsetzer; Untersuchung eines Digital-Analog-Umsetzers\\n'}, {'id': '/mls-api/tasks/251', 'contents': 'Digitaltechnik Versuch 12: Analog-Digital-Umsetzer; Analog-Digital-Umsetzer; Untersuchung eines Analog-Digital-Umsetzers\\n'}, {'id': '/mls-api/tasks/250', 'contents': 'Digitaltechnik Versuch 11: Multiplexer / Demultiplexer; Multiplexer / Demultiplexer; Multiplexer-Demultiplexer-Strecke\\n'}, {'id': '/mls-api/tasks/249', 'contents': 'Digitaltechnik Versuch 10: Schieberegister; Schieberegister; Untersuchung eines Schieberegisters\\n'}, {'id': '/mls-api/tasks/248', 'contents': 'Digitaltechnik Versuch 9: Zhlerschaltungen; Asynchrone Zhler; Asynchroner Modulo-n-Zhler; Synchrone Zhler\\n'}, {'id': '/mls-api/tasks/247', 'contents': 'Digitaltechnik Versuch 8.2: Kippstufen Teil 2; Zweiflankengesteuerte Flifplops; Monostabile Kippstufen; Untersuchung eines Monoflops; Verzgerungsschaltungen; Astabile Kippschaltungen\\n'}, {'id': '/mls-api/tasks/246', 'contents': 'Digitaltechnik Versuch 8.1: Kippstufen Teil 1; Kippstufen; Bistabile Kippschaltungen; Untersuchung eines RS-Flipflops; Synchrone Flipflops; Untersuchung synchroner Flipflops\\n'}, {'id': '/mls-api/tasks/245', 'contents': 'Digitaltechnik Versuch 7.2: Rechenschaltungen Teil 2; Subtrahierer fr Dualzahlen; Subtraktionschaltung; Komparatoren\\n'}, {'id': '/mls-api/tasks/244', 'contents': 'Digitaltechnik Versuch 7.1: Rechenschaltungen Teil 1; Addierschaltungen; Aufbau der Addierschaltungen\\n'}, {'id': '/mls-api/tasks/243', 'contents': 'Digitaltechnik Versuch 6: Codes und Codeumsetzer; Was ist ein Code? ; Zahlencodes; Alphanumerische Codes; 7-Segment-Codeumsetzer; Wasserstandsanzeige\\n'}, {'id': '/mls-api/tasks/242', 'contents': 'Digitaltechnik Versuch 5.2: Schaltungssynthese Teil 2; Steuerung einer Treppenhausbeleuchtung; Auswahlverfahren fr eine Arbeitsstelle; Kontrolle eines Stromnetzes; \"Zwei-aus-drei\"-Schaltung\\n'}, {'id': '/mls-api/tasks/241', 'contents': 'Digitaltechnik Versuch 5.1: Schaltungssynthese Teil 1; Schaltungssynthese, DNF und KNF; Das KV-Diagramm; Schaltungsentwurf Normalformen; Beispiel: Discofahrt\\n'}, {'id': '/mls-api/tasks/240', 'contents': 'Digitaltechnik Versuch 4.2: Boolesche Schaltalgebra Teil 2; De Morgansche Gesetze; Untersuchung der De Morganschen Gesetze Teil 1/2; Untersuchung der De Morganschen Gesetze Teil 2/2\\n'}, {'id': '/mls-api/tasks/239', 'contents': 'Digitaltechnik Versuch 4.1: Boolesche Schaltalgebra Teil 1; Boolesche Schaltalgebra; Untersuchung der Gesetze der booleschen Schaltalgebra Teil 1/2; Untersuchung der Gesetzte der booleschen Algebra Teil 2/2\\n'}, {'id': '/mls-api/tasks/238', 'contents': 'Digitaltechnik Versuch 3: Logische Schaltkreise in der Praxis; Grundlagen; Elektrische Daten der TTL-Familie; Nicht benutzte EIngnge; Fan-Out und Fan-In; Ausgangsbeschaltung\\n'}, {'id': '/mls-api/tasks/237', 'contents': 'Digitaltechnik Versuch 2.2: Zusammengesetzte Grundbausteine Teil 2; Die Antivalenz-Funktion (XOR); Untersuchung der Antivalenz-Funktion; Alternative Schaltung fr die quivalenz-Funktion; Die quivalenz-Funktion (XNOR); Untersuchung der quivalenz-Funktion; Alternative Schaltung fr die quivalenz-Funktion\\n'}, {'id': '/mls-api/tasks/236', 'contents': 'Digitaltechnik Versuch 2.1: Zusammengesetzte Grundbausteine Teil 1; Die NAND-Funktion; Untersuchung der NAND-Funktion; Logische Funktionen berprfen; Die NOR-Funktion; Untersuchung der NOR-Funktion; Zusammengesetzte Funktion aus NOR-Gattern\\n'}, {'id': '/mls-api/tasks/235', 'contents': 'Digitaltechnik Versuch 1: Logische Grundschaltungen; Logische Aussagen, Schaltungen und Zustnde; Logik des Digital Trainer Boards; Die NICHT-Funktion; Untersuchung der NICHT-Funktion; Die UND-Funktion; Untersuchung der UND-Funktion; Die ODER-Funktion; Untersuchung der ODER-Funktion\\n'}, {'id': '/mls-api/tasks/234', 'contents': 'Kick-off Grundlagen der Digitaltechnik; Cover; Sicherheitshinweise; Einfhrung; Ablauf\\n'}, {'id': '/mls-api/tasks/233', 'contents': 'S7-1500 mit tec2SKILL connect Versuch 4: Montagestation; Aufbau; Ablaufbeschreibung; Variablentabelle; Aufbauplan; Ablaufgraph; SPS-Programm; Bausteinschnittstelle fbMontage; Ablaufgraph fbMontage; Programm fbMontage\\n'}, {'id': '/mls-api/tasks/232', 'contents': 'Testprogramm mit Programmvariablen; Programmiervariablen festlegen (1); Programmiervariablen festlegen (2)\\n'}, {'id': '/mls-api/tasks/231', 'contents': 'Erstellen eines Testprogramms; Erstellen eines einfachen Testprogramms; PLC-Variablentabelle; Programmbausteine einfgen; Programmablauf\\n'}, {'id': '/mls-api/tasks/230', 'contents': 'Kick-off Grundlagen S7-1500 mit tec2SKILL connect; Cover; Sicherheitshinweise; Allgemeines; Hardware, Software und Voraussetzungen\\n'}, {'id': '/mls-api/tasks/229', 'contents': 'IO-Link Versuch 3: Vermessung eines Werkstckes; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Sensor programmieren; Schaltausgang programmieren; Sensor ber IO-Link programmieren; Werkstckvermessung; Detektionsverhalten bei Verkippung\\n'}, {'id': '/mls-api/tasks/228', 'contents': 'IO-Link Versuch 2: Analoge berwachung einer Werkzeuglseeinheit; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Aufbau der Messanordnung; Sensor einstellen (Teach); Sensor ber IO-Link programmieren; Messgert einstellen; Nachweis der Funktion\\n'}, {'id': '/mls-api/tasks/227', 'contents': 'IO-Link Versuch 1: Fllstanderfassung eines Tanks planen und ausfhren; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan ; Messaufbau und Funktionstest; Sensor programmieren; Analogausgang programmieren; Schaltausgang programmieren; Sensor ber IO-Link programmieren (1); Sensor ber IO-Link programmieren (2)\\n'}, {'id': '/mls-api/tasks/226', 'contents': 'Kick-off IO-Link; Cover; Sicherheitshinweise; Einfhrung und Ablauf; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/225', 'contents': 'Stirnradgetriebe ETS6 Versuch 3: Ausgleich Axialspiel (optional); Arbeitsschritt 1-4; Arbeitsschritt 5-7\\n'}, {'id': '/mls-api/tasks/224', 'contents': 'Stirnradgetriebe ETS6 Versuch 2: Montageanleitung 3-stufig ; Einbau Lager; Baugruppe Ritzelwelle 5; Baugruppe Ritzelwelle 3; Baugruppe Antriebswelle (1); Baugruppe Antriebswelle (2); Montage Verschlusskappe; Baugruppe antriebsseitiger Deckel (1); Baugruppe antriebsseitiger Deckel (2); Montage Baugruppe antriebseitiger Deckel; Montage Verschluss- und Entlftungsschraube\\n'}, {'id': '/mls-api/tasks/223', 'contents': 'Stirnradgetriebe ETS6 Versuch 1: Montageanleitung 2-stufig ; Einbau Lager & Baugruppe Ritzelwelle; Baugruppe Ritzelwelle; Baugruppe Antriebswelle (1); Baugruppe Antriebswelle (2); Montage Verschlusskappe; Baugruppe antriebsseitiger Deckel (1); Baugruppe antriebsseitiger Deckel (2); Montage Baugruppe Antriebsdeckel; Montage Verschluss- und Entlftungsschraube; Montage der Abdeckung\\n'}, {'id': '/mls-api/tasks/222', 'contents': 'Kick-off Montageanleitung Stirnradgetriebe 2/3-stufig ETS6; Cover; Sicherheitshinweise; Einfhrung und Ablauf\\n'}, {'id': '/mls-api/tasks/221', 'contents': 'Stirnradgetriebe 2/3-stufig ETS6 Aufgabe 6: Wartung und Instandhaltung; Wartung und Instandhaltung\\n'}, {'id': '/mls-api/tasks/220', 'contents': 'Stirnradgetriebe 2/3-stufig ETS6 Aufgabe 5: Montage und Demontage; Montagetechnik; Montagestruktur; Montageplanung\\n'}, {'id': '/mls-api/tasks/219', 'contents': 'Stirnradgetriebe 2/3-stufig ETS6 Aufgabe 4: Antriebstechnik; Elektrische Drehstromantriebe mit festen Drehzahlen; Energiefluss; Kupplungen; Physik der Antriebstechnik; Antriebsauslegung\\n'}, {'id': '/mls-api/tasks/218', 'contents': 'Stirnradgetriebe 2/3-stufig ETS6 Aufgabe 3: Zahnradgetriebekonstruktion; Zahnradgetriebekonstruktion ; Lagerungen; Lagerlebensdauerbestimmung; Schmierung und Dichtung; Radialwellendichtringe\\n'}, {'id': '/mls-api/tasks/217', 'contents': 'Stirnradgetriebe 2/3-stufig ETS6 Aufgabe 2: Zahnradgeometrie; Der Modul; Schrgverzahnungen; Profilberdeckung; Stirnradgetriebemotor; Zahnradbauformen; Verzahnungen\\n'}, {'id': '/mls-api/tasks/216', 'contents': 'Stirnradgetriebe 2/3-stufig ETS6 Aufgabe 1: Zahnrder und Zahnradgetriebe; Getriebemotor und Getriebearten; Physikalische Grundlagen von Stirnradgetrieben; Drehmoment und Leistung; bersetzung des Drehmomentes; Wirkungsgrad\\n'}, {'id': '/mls-api/tasks/215', 'contents': 'Kick-off: Stirnradgetriebe 2/3-stufig ETS6; Cover; Sicherheitshinweise; Einfhrung; Demo-Getriebekoffer ETS6\\n'}, {'id': '/mls-api/tasks/214', 'contents': 'Additive Fertigung 3D-Druck - Aufgabe Zahnradkonfigurator; Getriebe ETS6; Zahnradkonfigurator/-generator (1); Zahnradkonfigurator/-generator (2); Ultimaker Cura (1); Ultimaker Cura (2); Montage\\n'}, {'id': '/mls-api/tasks/213', 'contents': 'Additive Fertigung 3D-Druck - Grundlagen; Additive Fertigungsverfahren; Vor- und Nachteile der Additiven Fertigung; Was ist Rapid Prototyping?; Was ist Rapid Tooling?; Was ist Rapid Manufacturing?\\n'}, {'id': '/mls-api/tasks/212', 'contents': 'Kick-off Additive Fertigung 3D-Druck ETS6; Cover; Sicherheitshinweise; Was ist Additive Fertigung?; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/211', 'contents': 'Versuch 4.2.: DC-Transfersystem mit tec2SKILL connect - LOGO! - Programm Ablauf Werkstcktransport; Ablaufbeschreibung ; Zuordnungsliste; Ablaufgraph; SPS-Programm (1); SPS-Programm (2); Test\\n'}, {'id': '/mls-api/tasks/210', 'contents': 'Versuch 4.1.: DC-Transfersystem mit tec2SKILL connect - LOGO! - Werkstcktransport; Aufgabe; Technologieschema; Aufbauplan; Stromlaufplan; Einfhrungsprogramm - Ablaufbeschreibung; Zuordnungsliste; Ablaufgraph; SPS-Programm; Test\\n'}, {'id': '/mls-api/tasks/209', 'contents': 'Versuch 3: DC-Transfersystem mit tec2SKILL connect - LOGO! - Geschwindigkeitssteuerung; Aufgabe; Technologieschema; Aufbauplan; Stromlaufplan; Zuordnungsliste; Ablaufgraph; SPS-Programm (1); SPS-Programm (2); Reset-Funktion\\n'}, {'id': '/mls-api/tasks/208', 'contents': 'Versuch 2: DC-Transfersystem mit tec2SKILL connect - LOGO! - Erweiterung Tippbetrieb; Aufgabe; Zuordnungsliste; SPS-Programm; Ablaufgraph; SPS-Programm mit Ablaufsteuerung; Test\\n'}, {'id': '/mls-api/tasks/207', 'contents': 'Versuch 1: DC-Transfersystem mit tec2SKILL connect - LOGO! - Tippbetrieb; Aufgabe; Technologieschema; Aufbauplan PLC Board 24 V; Aufbauplan PLC Professional Board; Stromlaufplan; Zuordnungsliste; SPS-Programm\\n'}, {'id': '/mls-api/tasks/206', 'contents': 'Arbeitsplanung DC-Transfersystem mit tec2SKILL connect - LOGO!; Inbetriebnahme; Betriebsmittelkennzeichnung; E/A-Belegung\\n'}, {'id': '/mls-api/tasks/205', 'contents': 'Kick-off: DC-Transfersystem mit tec2SKILL connect - LOGO!; Cover; Sicherheitshinweise; Projektvorstellung; Digitales Modell mit tec2SKILL connect\\n'}, {'id': '/mls-api/tasks/204', 'contents': 'IO-Link Versuch 3: Vermessung eines Werkstckes; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Sensor programmieren; Schaltausgang programmieren; Sensor ber IO-Link programmieren (1); Sensor ber IO-Link programmieren (2); Werkstckvermessung\\n'}, {'id': '/mls-api/tasks/203', 'contents': 'IO-Link Versuch 2: Analoge berwachung einer Werkzeuglseeinheit; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Aufbau der Messanordnung; Sensor einstellen (Teach); Sensor ber IO-Link programmieren (1); Sensor ber IO-Link programmieren (2); Messgert einstellen; Nachweis der Funktion\\n'}, {'id': '/mls-api/tasks/202', 'contents': 'IO-Link Versuch 1: Fllstanderfassung eines Tanks planen und ausfhren; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan ; Messaufbau und Funktionstest; Sensor programmieren; Analogausgang programmieren; Schaltausgang programmieren; Sensor ber IO-Link programmieren (1); Sensor ber IO-Link programmieren (2)\\n'}, {'id': '/mls-api/tasks/201', 'contents': 'Arbeitsplanung IO-Link; Verfgbare Sensoren; Schritte der Arbeitsplanung\\n'}, {'id': '/mls-api/tasks/200', 'contents': 'Kick-off IO-Link; Cover; Sicherheitshinweise; Einfhrung und Ablauf; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/199', 'contents': 'alt-Grundlagen der Halbleitertechnik Versuch 4: Operationsverstrker ; Versuch 4.0.: Invertierender Verstrker (1); Versuch 4.0.: Invertierender Verstrker (2); Versuch 4.1.: Operationsverstrker als nichtinvertierender Verstrker (1); Versuch 4.1.: Operationsverstrker als nichtinvertierender Verstrker (2)\\n'}, {'id': '/mls-api/tasks/198', 'contents': 'alt-Grundlagen der Halbleitertechnik Versuch 3: Die Thyristortriode ; Versuch 3.0.: Znd- und Lschvorgang an einer Thyristortriode TIC106; Versuch 3.1.: Verfahren zum Lschen einer Thyristortriode; Versuch 3.1.: Verfahren zum Lschen einer Thyristortriode (2)\\n'}, {'id': '/mls-api/tasks/197', 'contents': 'alt-Grundlagen der Halbleitertechnik Versuch 2: Bipolare Transistoren; Versuch 2.0.: Aufbau und Funktionsweise von bipolaren Transistoren (1);    Versuch 2.0.: Aufbau und Funktionsweise von bipolaren Transistoren (2); Versuch 2.1.: Wirkungen des Basisstroms auf den Kollektorstrom; Versuch 2.2.: Der Arbeitspunkt einer Verstrkerstufe\\n'}, {'id': '/mls-api/tasks/196', 'contents': 'alt-Grundlagen der Halbleitertechnik Versuch 1: Dioden und Gleichrichterschaltungen; Versuch 1.0: PN-bergang als Diode ; Versuch 1.1: Einpuls-Mittelpunkt-Schaltung M1 ohne und mit Glttungskondensator; Versuch 1.2: Die Kennlinien einer Z-Diode; Versuch 1.3: Gleichspannungsbegrenzungen mit der Z-Diode; Versuch 1.4: Leuchtdioden\\n'}, {'id': '/mls-api/tasks/195', 'contents': 'Kick-off Grundlagen der Elektrotechnik Teil 2: Grundlagen der Halbleitertechnik; Cover; Sicherheitshinweise; Sicheres Experimentieren mit Strom und Spannung (Allgemeines); Funktion der Strombegrenzung; Feste Gleichspannung einstellen; Strom in Halbleiterwerkstoffen; Versuche\\n'}, {'id': '/mls-api/tasks/194', 'contents': 'Digitale Sensorik Versuch 5: Sensoranordnung zur Aussortierung weier und sehr heller Kunststoffe; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Aufbau der Messanordnung; Nachweis der Funktion ; Einfluss der Objektfarbe auf den Tastbereich\\n'}, {'id': '/mls-api/tasks/193', 'contents': 'Digitale Sensorik Versuch 4: Sensoranordnung zur Grensortierung von Metallteilen; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Aufbau der Messanordnung; Nachweis der Funktion; Einfluss der Ausrichtung des Retrospiegels; Einfluss spiegelnder oder transparenter Objekte auf das Sensorverhalten\\n'}, {'id': '/mls-api/tasks/192', 'contents': 'Digitale Sensorik Versuch 3: Sensoranordnung zur Unterscheidung von Kunststoff und Metallteilen; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Nachweis der Funktion\\n'}, {'id': '/mls-api/tasks/191', 'contents': 'Digitale Sensorik Versuch 2: Sensoranordnung fr vorbeifahrende Kunststoffe; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Nachweis der Funktion; Nachweis des Reduktionsfaktors\\n'}, {'id': '/mls-api/tasks/190', 'contents': 'Digitale Sensorik Versuch 1: Sensoranordnung fr vorbeifahrende Metalle; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Nachweis der Funktion; Nachweis des Schaltabstands ; Nachweis des Reduktionsfaktors; Nachweis der Hyterese\\n'}, {'id': '/mls-api/tasks/189', 'contents': 'Arbeitsplanung Digitale Sensorik; Verfgbare Sensoren; Schritte der Arbeitsplanung\\n'}, {'id': '/mls-api/tasks/188', 'contents': 'Kick-off Digitale Sensorik; Cover; Sicherheitshinweise; Einfhrung und Ablauf; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/187', 'contents': 'Netzanalyse Versuch 6: Untersuchung von Gleichrichterschaltungen; Aufgabe; B6U-Brcken-Gleichrichtschaltung; M3U-Brcken-Gleichrichtschaltung\\n'}, {'id': '/mls-api/tasks/186', 'contents': 'Netzanalyse Versuch 5: Entstehung von Oberschwingungen - Messtechnische Untersuchung ; Aufgabe; Sternschaltung bei Belastung mit nichtlinearem Verbraucher; Sternschaltung bei Belastung mit mehreren nichtlinearen Verbrauchern; Ergebnisanalyse\\n'}, {'id': '/mls-api/tasks/185', 'contents': 'Neutralleiterbelastung Versuch 4: Ohmscher, induktiver bzw. kapazitiver (linearer) Verbraucher ; Aufgabe; Messungen\\n'}, {'id': '/mls-api/tasks/184', 'contents': 'Neutralleiterbelastung Versuch 3: Strungen an der Sternschaltung ; Aufgabe; Auenleiterausfall; Auenleiter- und Neutralleiterausfall; Unsymmetrische Last und Auenleiterausfall; Unsymmetrische Last, Auen- und Neutralleiterausfall\\n'}, {'id': '/mls-api/tasks/183', 'contents': 'Neutralleiterbelastung Versuch 2: Sternschaltung bei unsymmetrischer Belastung; Aufgabe; Hinweise; Messungen mit Neutralleiter; Messungen ohne Neutralleiter\\n'}, {'id': '/mls-api/tasks/182', 'contents': 'Neutralleiterbelastung Versuch 1: Sternschaltung bei symmetrischer Belastung; Aufgabe; Hinweise; Messungen mit Neutralleiter; Messungen ohne Neutralleiter\\n'}, {'id': '/mls-api/tasks/181', 'contents': 'Kick-off Neutralleiterbelastung - Netzanalyse; Cover; Sicherheitshinweise; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/180', 'contents': 'Elektrotechnik 1 Versuch 13: Elektromotor; Untersuchung eines permanenterregten Gleichstrommotors; Untersuchung eines Synchronmotors\\n'}, {'id': '/mls-api/tasks/179', 'contents': 'Elektrotechnik 1 Versuch 12: Transformatoren; Praktischer Nachweis der Transformatorwirkung\\n'}, {'id': '/mls-api/tasks/178', 'contents': 'Elektrotechnik 1 Versuch 11: Elektromagnetismus und Spulen; Elektromagnetismus; Phasenverschiebung zwischen Spannung und Strom; Der induktive Blindwiderstand XL\\n'}, {'id': '/mls-api/tasks/177', 'contents': 'Elektrotechnik 1 Versuch 10: Der Kondensator; Grundstzliches zu Lade- und Entladevorgngen; Phasenverschiebung zwischen Strom und Spannung\\n'}, {'id': '/mls-api/tasks/176', 'contents': 'Elektrotechnik 1 Versuch 9: Dreiphasenwechselstrom (Drehstrom); Messungen an Drehstromsystemen; Messungen an symmetrischer und unsymmetrischer Sternschaltung; Messungen an symmetrischer und unsymmetrischer Dreieckschaltung\\n'}, {'id': '/mls-api/tasks/175', 'contents': 'Elektrotechnik 1 Versuch 8: Wirkleistung von Wechselspannungen; Wirkleistung der Sinuswechselspannung in der praktischen bung\\n'}, {'id': '/mls-api/tasks/174', 'contents': 'Elektrotechnik 1 Versuch 7: Stromarten und ihre Kenngren; Kenngren der Sinusspannung in der praktischen bung\\n'}, {'id': '/mls-api/tasks/173', 'contents': 'Elektrotechnik 1 Versuch 6: Wirkungsgrad; Praktische Uebung zum Wirkungsgrad\\n'}, {'id': '/mls-api/tasks/172', 'contents': 'Elektrotechnik 1 Versuch 5: Elektrische Leistung und Arbeit; Praktische bungen zu Leistung und Arbeit im Stromkreis\\n'}, {'id': '/mls-api/tasks/171', 'contents': 'Elektrotechnik 1 Versuch 4: Zusammenschaltung von Spannungsquellen; Reihenschaltung von Spannungsquellen im Versuch\\n'}, {'id': '/mls-api/tasks/170', 'contents': 'Elektrotechnik 1 Versuch 3: Elektrische Widerstnde; Aufnahme der Kennlinie I=f(U); Aufnahme der NTC-Kennlinien I = f (U) und R = f (U); Untersuchung der Abhngigkeit des LDR von der Beleuchtungsstrke; Nachweis der Eigenschaften einer Reihenschaltung von Widerstnden; Nachweis der Eigenschaften parallel geschalteter Widerstnde; Der unbelastete Spannungsteiler; Eigenschaften belasteter Spannungsteiler\\n'}, {'id': '/mls-api/tasks/169', 'contents': 'Elektrotechnik 1 Versuch 2: Ohmsches Gesetz; Das ohmsche Gesetz im Praxisversuch; Untersuchung der Abhngigkeit des Stroms von der Spannung; Aufgaben / Fragen\\n'}, {'id': '/mls-api/tasks/168', 'contents': 'Elektrotechnik 1 Versuch 1: Der elektrische Stromkreis; Der Stromkreis im praktischen Versuch; Aufgaben / Fragen\\n'}, {'id': '/mls-api/tasks/167', 'contents': 'Elektromotoren 2 - Versuch 6: Drehstrom-Synchronreluktanzmaschine; Einfhrung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationren Betrieb; Messung der Anlauf-Kennlinien\\n'}, {'id': '/mls-api/tasks/166', 'contents': 'Elektromotoren 2 - Versuch 5: Lastsimulation mit Drehstrom-Asynchronmotoren; Einfhrung; Lastsimulation mit konstantem Drehmoment (1); Lastsimulation mit konstantem Drehmoment (2); Lastsimulation mit linearem Lastmoment (1); Lastsimulation mit linearem Lastmoment (2); Lastsimulation mit quadratischem Lastmoment; Lastsimulation mit quadratischem Lastmoment (2)\\n'}, {'id': '/mls-api/tasks/165', 'contents': 'Elektromotoren 2 - Versuch 4: Drehstrom-Schleifringlufer; Einfhrung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationren Betrieb; Messung von Kennlinien; Messung von Kennlinien in Sternschaltung\\n'}, {'id': '/mls-api/tasks/164', 'contents': 'Elektromotoren 2 - Versuch 3: IE4 Asynchronmaschine; Einfhrung 1; Einfhrung 2; Aufbau; Elektrischer Anschluss; Manueller Betrieb; Automatische Aufzeichnung einer Kennlinie; Sternschaltung (1); Sternschaltung (2)\\n'}, {'id': '/mls-api/tasks/163', 'contents': 'Elektromotoren 2 - Versuch 2: Drehstrom-Asynchronmaschine; Einfhrung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationren Betrieb; Messung von Kennlinien; Messung von Kennlinien in Sternschaltung\\n'}, {'id': '/mls-api/tasks/162', 'contents': 'Elektromotoren 2 - Versuch 1: Einphasen-Wechselstrommotor; Einfhrung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationren Betrieb; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/161', 'contents': 'Kick-off  Elektromotoren Teil 2: Wechsel- und Drehstrommotoren; Cover; Sicherheitshinweise; Einfhrung und Ablauf\\n'}, {'id': '/mls-api/tasks/160', 'contents': 'Kopiervorlage Versuche 56226 Elektromotoren; step; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt\\n'}, {'id': '/mls-api/tasks/159', 'contents': 'Elektromotoren 1 - Versuch 5: Schrittmotor; Einfhrung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationren Betrieb; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/158', 'contents': 'Elektromotoren 1 - Versuch 4: Brstenloser Gleichstrommotor (BLDC); Einfhrung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationren Betrieb; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/157', 'contents': 'Elektromotoren 1 - Versuch 3: Gleichstrom-Doppelschlussmaschine; Einfhrung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationren Betrieb; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/156', 'contents': 'Elektromotoren 1 - Versuch 2: Gleichstrom-Reihenschlussmaschine; Einfhrung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationren Betrieb; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/155', 'contents': 'Elektromotoren 1 - Versuch 1: Fremderregte Gleichstrom-Nebenschlussmaschine; Einfhrung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationren Betrieb; Auswertung der Ergebnisse; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/154', 'contents': 'Einfhrung und Grundlagen; Magnetisches Feld; Durchflutungsgesetz; Induktionsgesetz; Lorentzkraft; Aufbau einer rotierenden elektrischen Maschine; Verstndnisfragen\\n'}, {'id': '/mls-api/tasks/153', 'contents': 'Kick-off  Elektromotoren Teil 1: Gleichstrommotoren; Cover; Sicherheitshinweise; Einfhrung und Ablauf\\n'}, {'id': '/mls-api/tasks/152', 'contents': 'Analoge Sensorik Versuch 3:  Prfung des Behlterdeckels; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Messgert einstellen; Nachweis der Funktion; Nachweis des Schaltabstandes; Nachweis des Reduktionsfaktors\\n'}, {'id': '/mls-api/tasks/151', 'contents': 'Analoge Sensorik Versuch 2:  Fllstandserfassung eines Lagers fr Behlter; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Sensor einstellen (Teach); Nachweis der Funktion; Nachweis der Hysterese; Ermittlung der Schallkeule; Detektionsverhalten bei Verkippung\\n'}, {'id': '/mls-api/tasks/150', 'contents': 'Analoge Sensorik Versuch 1:  Fllstandserfassung eines Palettenlagers; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Sensor einstellen (Teach); Nachweis der Funktion; Nachweis der Hysterese; Nachweis der Reflektivitt; Detektionsverhalten bei Verkippung\\n'}, {'id': '/mls-api/tasks/149', 'contents': 'Arbeitsplanung Analoge Sensorik; Verfgbare Sensoren; Schritte der Arbeitsplanung\\n'}, {'id': '/mls-api/tasks/148', 'contents': 'Kick-off Analoge Sensorik; Cover; Sicherheitshinweise; Einfhrung und Ablauf; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/147', 'contents': 'Grundlagen: Laser-Abstandssensor; Funktionsprinzip; Einsatzarten von optischen Sensoren\\n'}, {'id': '/mls-api/tasks/146', 'contents': 'Analoge Sensorik Versuch 1:  Fllstandserfassung eines Palettenlagers; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Sensor einstellen (Teach); Nachweis der Funktion; Nachweis der Hysterese; Nachweis der Reflektivitt; Detektionsverhalten bei Verkippung\\n'}, {'id': '/mls-api/tasks/145', 'contents': 'Kick-off; Analyse\\n'}, {'id': '/mls-api/tasks/144', 'contents': 'Transfersystem mit Gleichstrom 4.0 Teil 7; 7. Aufgabe 4: Werkstcktransport  7.1 Aufgabenstellung; 7.2 Voraussetzung; 7.3 Technologieschema und Aufbauplan; 7.4 Aufbauplan; 7.5 Stromlaufplan; 7.6 Aufgabe 4.1: Einfhrunsprogramm; 7.7 Aufgabe 4.2: Programm Ablauf Werkstcktransport\\n'}, {'id': '/mls-api/tasks/143', 'contents': 'Transfersystem mit Gleichstrom 4.0 Teil 6; 6. Aufgabe 3: Geschwindigkeitssteuerung 6.1 Aufgabenstellung; 6.2 Voraussetzungen; 6.3 Technologieschema; 6.4 Aufbauplan; 6.5 Stromlaufplan; 6.6 Variablentabelle; 6.7 Ablaufgraph; 6.8 SPS-Programm\\n'}, {'id': '/mls-api/tasks/142', 'contents': 'Transfersystem mit Gleichstrom 4.0 Teil 5; 5. Aufgabe 2: Erweiterung Tippbetrieb; 5.1 Aufgabenstellung; 5.2 Variablentabelle; 5.3 Ablaufgraph; 5.4 SPS-Programm\\n'}, {'id': '/mls-api/tasks/141', 'contents': 'Transfersystem mit Gleichstrom 4.0 Teil 4; 4. Aufgabe 1: Tippbetrieb 4.1 Aufgabenstellung; 4.2 Voraussetzung ; 4.3 Technologieschema; 4.4 Aufbauplan; 4.5 Stromlaufplan; 4.6 Variablentabelle; 4.7 SPS-Programm \\n'}, {'id': '/mls-api/tasks/140', 'contents': 'Transfersystem mit Gleichstrom 4.0 Teil 3; 3. Hinweise zur Programmierung; 3.1 E/A- und Programmvariablen; 3.2 Benennung der Programmvariablen; 3.3 Beibehaltung positiver Logik\\n'}, {'id': '/mls-api/tasks/139', 'contents': 'Transfersystem mit Gleichsstromantrieb 4.0 Teil 1; Cover und Sicherheitshinweise; 1. Elektrische Inbetriebnahme 1.1 Fertigungslinie mit Frderband; 1.2 Inbetriebnahme; 1.3 Kontrolle\\n'}, {'id': '/mls-api/tasks/138', 'contents': 'Stirnradgetriebe ETS6 4.0 Teil 7; 6. Wartung und Instandhaltung 6.1 Allgemein; 6.2 Ziele der Instandhaltung; 6.3 Instandhaltung\\n'}, {'id': '/mls-api/tasks/137', 'contents': 'Stirnradgetriebe ETS6 4.0 Teil 6; 5. Montage und Demontage 5.1 Montagetechnik; 5.2 Montagestruktur; 5.3 Montageplanung; 5.4 3-stufiges Getriebe Montageplanung\\n'}, {'id': '/mls-api/tasks/136', 'contents': 'Stirnradgetriebe ETS6 4.0 Teil 5; 4. Antriebstechnik 4.1 Elektrische Drehstromantriebe mit festen Drehzahlen; 4.2 Energiefluss; 4.3 Kupplungen; 4.4 Physik der Antriebstechnik\\n'}, {'id': '/mls-api/tasks/135', 'contents': 'Stirnradgetriebe ETS6 4. Teil 4; 3. Zahnradgetriebekonstruktion; 3.1 Lagerung\\n'}, {'id': '/mls-api/tasks/134', 'contents': 'Stirnradgetriebe ETS6 4.0 Teil 3; 2. Zahnradgeometrie 2.1 Grundlagen- der Modul; 2.2 Schrgverzahnung; 2.3 Profilberdeckung; 2.4 Stirnradgetriebemotor; 2.5 Zahnradbauformen; 2.6 Verzahnung\\n'}, {'id': '/mls-api/tasks/133', 'contents': 'Stirnradgetriebe 2/3-stufig ETS6 4.0 Teil 2; 1. Zahnrder und Zahnradgetriebe 1.1 Getriebe; 1.2 Getriebemotor; 1.3 Getriebearten; 1.4 Physikalische Grundlagen von Stirnradgetrieben; 1.5 Drehmoment und Leistung; 1.6 bersetzung des Drehmomentes; 1.7 Wirkungsgrad\\n'}, {'id': '/mls-api/tasks/132', 'contents': 'Stirnradgetriebe 2/3-stufig ETS 6 4.0 Teil 1; Cover und Sicherheitshinweise; Vorwort und Unterrichtlicher Einsatz; Grundlegendes; Schnittdarstellungen\\n'}, {'id': '/mls-api/tasks/131', 'contents': 'Grundlagen der Sensorik Analog 4.1 Teil 11; 6. Dritter betrieblicher Auftrag: Sensoranordnung fr die Prfung des Behlterdeckels planen und ausfhren; 6.1 Aufgabenstellung; 6.2 Vereinfachungen/ Simulationen; 6.3 Arbeitsplanung; 6.4 Stromlaufplan; 6.5 Aufbau der Messanordnung; 6.5.1 Messgert einstellen; 6.6 Nachweis der Funktion; 6.6.1 Auswertung des Versuchs; 6.7 Aufgabenstellung\\n'}, {'id': '/mls-api/tasks/130', 'contents': 'Grundlagen der Sensorik Analog 4.1 Teil 10; 5. Zweiter betrieblicher Auftrag: Sensoranordnung fr die Fllstandserfassung eines Lagers fr Behlter planen und ausfhren; 5.1 Aufgabenstellung; 5.2 Vereinfachungen/ Simulationen; 5.3 Arbeitsplanung; 5.4 Stromlaufplan; 5.5  Aufbau der Messanordnung; 5.5.1 Sensor einstellen (Teach); 5.5.2 Messgert einstellen; 5.6 Nachweis der Funktion; 5.6.1 Auswertung des Versuchs\\n'}, {'id': '/mls-api/tasks/129', 'contents': 'Grundlagen der Sensorik Analog 4.1 Teil 8; 3.3 Laser-Abstandssensor; 3.3.1 Funktionsprinzip; 3.3.2 Einsatzarten von optischen Sensoren; 3.3.3 Kontrollfragen und Umgang mit dem Datenblatt\\n'}, {'id': '/mls-api/tasks/128', 'contents': 'Grundlagen der Sensorik Analog 4.1 Teil 7; 3.2 Ultraschallsensor; 3.2.1 Funktionsprinzip ; 3.2.2 Die Schallkeule eines Ultraschallsensors; 3.2.3 Auswertung der Messergebnisse ; 3.2.4 Einflussgren auf die Messgenauigkeit des Ultraschallsensors; 3.2.5 Kontrollfragen und Umgang mit dem Datenblatt\\n'}, {'id': '/mls-api/tasks/127', 'contents': 'Grundlagen der Sensorik 4.1 Teil 6; 3. Sensoren der betrieblichen Auftrge; 3.1 Induktiver Nherungssensor; 3.1.1 Funktionsprinzip; 3.1.2 Kontrollfragen und Umgang mit dem Datenblatt\\n'}, {'id': '/mls-api/tasks/126', 'contents': 'Grundlagen: Charakterisierung von Messeigenschaften; Messbereich und Genauigkeit der Messung; Linearittsfehler; Empfindlichkeit und Auflsung; Schaltabstnde und Reduktionsfaktor; Mess-/ Schaltfrequenz; Schalthysterese; Ansprechkurve\\n'}, {'id': '/mls-api/tasks/125', 'contents': 'Grundlagen der Sensorik 4.1 Teil 1; Sicherheitshinweise; 1. Einfhrung\\n'}, {'id': '/mls-api/tasks/124', 'contents': 'Prfung elektrischer Gerte 4.4 Teil 6; 4.3 Wiederholungsprfung einer Bohrmaschine; Part 2\\n'}, {'id': '/mls-api/tasks/123', 'contents': 'Prfung elektrischer Gerte Teil 13; 4.10 Prfung einer Waschmaschine; Part 2\\n'}, {'id': '/mls-api/tasks/122', 'contents': 'Prfung elektrischer Gerte Teil 14; 5. Fehlertabellen; 5.1 Bgeleisen; 5.2 Tauchsiedler; 5.3 Bohrmaschine; 5.4 PC; 5.5 Kabeltrommel; 5.6 Kaffeeautomat; 5.7 Herd; 5.8 Radio; 5.9 Netzgert\\n'}, {'id': '/mls-api/tasks/121', 'contents': 'Prfung elektrischer Gerte Teil 12; 4.9 Wiederholungsprfung eines Netzgertes; Part 2\\n'}, {'id': '/mls-api/tasks/120', 'contents': 'Prfung elektrischer Gerte Teil 11; 4.8 Wiederholungsprfung eines Radios ; Part 2\\n'}, {'id': '/mls-api/tasks/119', 'contents': 'Prfung elektrischer Gerte Teil 10; 4.7 Prfung eines Elektroherdes nach einer Reparatur; Part 2\\n'}, {'id': '/mls-api/tasks/118', 'contents': 'Prfung elektrischer Gerte 4.0 Teil 9; 4.6 Wiederholungsprfung eines Kaffeeautomaten; Part 2\\n'}, {'id': '/mls-api/tasks/117', 'contents': 'Prfung elektrischer Gerte Teil 8; 4.5 Wiederholungsprfung einer Kabeltrommel; Part 2\\n'}, {'id': '/mls-api/tasks/116', 'contents': 'Prfung elektrischer Gerte Teil 7; 4.4 Wiederholungsprfung eines PCs; Part 2; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt\\n'}, {'id': '/mls-api/tasks/115', 'contents': 'Prfung elektrischer Gerte 4.4 Teil 5; 4.2 Prfung eines Tauchsieders; Part 2\\n'}, {'id': '/mls-api/tasks/114', 'contents': 'Prfung elektrischer Gerte 4.4 Teil 4 (kopiert); 4. Aufgaben; 4.1 Wiederholungsprfung eines Bgeleisens; Part 2\\n'}, {'id': '/mls-api/tasks/113', 'contents': 'Prfung elektrischer Gerte Version 4.4 Teil 3; 3. Definitionen / 3.1 Ortsfeste Betriebsmittel; 3.2 Ortsvernderliche Verbraucher; 3.3 Aktive und passive Messung; 3.4 Definitionen der Schutzklassen\\n'}, {'id': '/mls-api/tasks/112', 'contents': 'Prfung elektrischer Gerte Version 4.4 Teil 1; Deckblatt/ Sicherheitshinweise; 1. Einleitung; 1.1 Anforderungen an den Prfer; 1.2 - 1.4 ; 1.5 Prffristen nach DGUV Vorschrift 3\\n'}, {'id': '/mls-api/tasks/46', 'contents': 'Vorstellung Projekt Presse futurelearning (Demo) [0]; Start; informieren Pressenfu / BG1; informieren Verbindungsteil_innen; Funktionsbeschreibung Verbindungsteil_innen; Funktionsbeschreibung Lsungsvorschlag; technische Darstellung Verbindungsteil_innen; informieren Krnen; planen Verbindungsteil_innen; Arbeitsschrittkarten Verbindungsteil_innen; entscheiden Verbindungsteil_innen\\n'}, {'id': '/mls-api/tasks/45', 'contents': 'Verbindungsplatte [2_3]; Start; informieren technische Darstellungen; informieren Verfahrenshinweise; planen Verbindungsplatte; entscheiden Verbindungsplatte; Arbeitsplan Verbindungsplatte; durchfhren Verbindungsplatte; kontrollieren Verbindungsplatte; Erfolgskonrolle Verbindungsplatte; Lernprozess bewerten\\n'}, {'id': '/mls-api/tasks/44', 'contents': 'Pressensule / BG2 Montage [2_8]; Start; informieren technische Darstellungen; informieren Montage Pressensule (BG2); planen Montage Pressensule (BG2); entscheiden Montage Pressensule (BG2); Montageanleitung Pressensule (BG2); durchfhren Montage Pressensule (GB2); kontrollieren Montage Pressensule (BG2); Erfolgskongrolle Montage Pressensule (BG2); Lernprozess bewerten\\n'}, {'id': '/mls-api/tasks/43', 'contents': 'Gewindespindel [2_7]; Start; informieren Funktion Gewindespindel; informieren technische Darstellungen; informieren Verfahrenshinweise; planen Gewindespindel; entscheiden Gewindespindel; Arbeitsplan Gewindespindel; durchfhren Gewindespindel; kontrollieren Gewindespindel; Erfolgskontrolle Gewindespindel\\n'}, {'id': '/mls-api/tasks/42', 'contents': 'Sule [2_6]; Start; informieren Funktion Sule; informieren technische Darstellungen; informieren Verfahrenshinweise; informieren Messen III; planen Sule; entscheiden Sule; Arbeitsplan Sule; durchfhren Sule; kontrollieren Sule\\n'}, {'id': '/mls-api/tasks/41', 'contents': 'Halterung [2_5]; Start; Funktionsbeschreibung (Lsungsvorschlag); informieren technische Darstellungen; informieren Verfahrenshinweise; informieren Drehen I; informieren Drehen II; informieren Arbeitssicherheit Drehen; informieren Auengewinde schneiden; planen Halterung; Arbeitsschrittkarten Halterung\\n'}, {'id': '/mls-api/tasks/40', 'contents': 'Deckplatte [2_4]; Start; informieren technische Darstellungen; informieren Verfahrenshinweise; planen Deckplatte; entscheiden Deckplatte; Arbeitsplan Deckplatte; durchfhren Deckplatte; kontrollieren Deckplatte; Erfolgskontrolle Deckplatte; Lernprozess bewerten\\n'}, {'id': '/mls-api/tasks/39', 'contents': 'Seitenplatten [2_2]; Start; Funktionsbeschreibung (Lsungsvorschlag); informieren technische Darstellungen; informieren Verfahrenshinweise; informieren Frsen I; informieren Frsen II; informieren Kantentaster; informieren Arbeitssicherheit Frsen I; planen Seitenplatten; Arbeitsschrittkarten Seitenplatten\\n'}, {'id': '/mls-api/tasks/38', 'contents': 'Pressensule / BG2 [2_1] - informieren; informieren\\n'}, {'id': '/mls-api/tasks/37', 'contents': 'Gesamtmontage Presse [6_1]; Arbeitsschritt Montage Gessamtprojekt Presse; planen Montage Gessamtprojekt Presse; Montageplan Gessamtprojekt Presse; durchfhren Montage Gessamtprojekt Presse; Erfolgskontrolle Gessamtprojekt Presse; \"Ich kann ...\"-Liste berfachliche Kompetenzen; \"Ich kann ...\"-Liste fachliche Kompetenzen\\n'}, {'id': '/mls-api/tasks/36', 'contents': 'Tischplatte / BG5 [5_1]; informieren Tischplatte; planen Tischplatte; Arbeitsplan Tischplatte; durchfhren Tischplatte; Erfolgskontrolle Tischplatte; \"Ich kann ...\"-Liste berfachliche Kompetenzen; \"Ich kann ...\"-Liste fachliche Kompetenzen\\n'}, {'id': '/mls-api/tasks/35', 'contents': 'elektrotechnische Erweiterung [4_2]; informieren elektrotechnische Erweiterung\\n'}, {'id': '/mls-api/tasks/34', 'contents': 'Pressenkopf / BG4 [4_1] ; informieren Pressenkopf (BG4); planen Bauteile Pressenkopf (BG4); Arbeitsplan leer; durchfhren Bauteile Pressenkopf (BG4); Erfolgskontrolle leer; planen Montage Pressenkopf (BG4); Montageplan Pressenkopf  (BG4); durchfhren Montage Pressenkopf (BG4); Erfolgskontrolle Montage Pressenkopf  (BG4); \"Ich kann ...\"-Liste berfachliche Kompetenzen\\n'}, {'id': '/mls-api/tasks/33', 'contents': 'Verbindungsteil_auen [1_9] - bewerten; Lernprozess bewerten; \"Ich kann ...\"-Liste berfachliche Kompetenzen; \"Ich kann ...\"-Liste fachliche Kompetenzen\\n'}, {'id': '/mls-api/tasks/32', 'contents': 'Verbindungsteil_auen [1_8] - durchfhren und kontrollieren; durchfhren Verbindungsteil_auen ; kontrollieren Verbindungsteil_auen; Ergebniskontrolle Verbindungsteil_auen; Bohrplatte Verbindungsteil_auen\\n'}, {'id': '/mls-api/tasks/31', 'contents': 'Verbindungsteil_auen [1_7] - planen und entscheiden; planen Verbindungsteil_auen; entscheiden Verbindungsteil_auen; Arbeitsplan Verbindungsteil_auen\\n'}, {'id': '/mls-api/tasks/30', 'contents': 'Verbindungsteil_auen [1_6] - informieren; Start; informieren Funktion Verbindungsteil_auen; informieren technische Darstellung; informieren Verfahrenshinweise; informieren Sgen\\n'}, {'id': '/mls-api/tasks/29', 'contents': 'Pressenfu / BG1 Montage  [1_15]; Start; informieren Funktion Pressenfu; informieren Montage Pressenfu; Lsung Montageanforderungen; informieren technische Darstellungen; informieren Reiben; informieren Lehren; informieren Fgen; planen Montage Pressenfu (BG1); entscheiden Montage Pressenfu (BG1)\\n'}, {'id': '/mls-api/tasks/28', 'contents': 'Trgerplatte [1_14]; Start; informieren Funktion Trgerplatte; informieren technische Darstellungen; informieren Verfahrenshinweise; planen Trgerplatte; entscheiden Trgerplatte; Arbeitsplan Trgerplatte; durchfhren Trgerplatte; kontrollieren Trgerplatte; Erfolgskontrolle Trgerplatte\\n'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks-test/json/tasks2.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/peng_luh/.pyenv/versions/3.9.5/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/peng_luh/.pyenv/versions/3.9.5/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/encode/__main__.py\", line 118, in <module>\n",
      "    encoder = init_encoder(args.encoder.encoder, args.encoder.encoder_class, device=args.encoder.device)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/encode/__main__.py\", line 60, in init_encoder\n",
      "    return encoder_class(**kwargs)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/encode/_auto.py\", line 28, in __init__\n",
      "    self.model.to(self.device)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py\", line 1811, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1145, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 820, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1143, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py\", line 247, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/peng_luh/.pyenv/versions/3.9.5/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/peng_luh/.pyenv/versions/3.9.5/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/encode/__main__.py\", line 118, in <module>\n",
      "    encoder = init_encoder(args.encoder.encoder, args.encoder.encoder_class, device=args.encoder.device)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/encode/__main__.py\", line 60, in init_encoder\n",
      "    return encoder_class(**kwargs)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/encode/_auto.py\", line 28, in __init__\n",
      "    self.model.to(self.device)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py\", line 1811, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1145, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 820, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1143, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py\", line 247, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import transformers\n",
    "\n",
    "cmd = \"\"\"\n",
    "    python -m pyserini.encode \\\n",
    "        input   --corpus /home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks-test/jsonl/data.jsonl \\\n",
    "                --fields text \\\n",
    "                --delimiter \";\" \\\n",
    "                --shard-id 0 \\\n",
    "                --shard-num 1 \\\n",
    "        output  --embeddings /home/peng_luh/__git/search_l3s/search_l3s_search_srv/encodes/dense/xlm_roberta_base/mls-tasks-test \\\n",
    "                --to-faiss \\\n",
    "        encoder --encoder xlm-roberta-large \\\n",
    "                --fields text \\\n",
    "                --batch 32 \\\n",
    "                --fp16\n",
    "\"\"\"\n",
    "\n",
    "subprocess.call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at dbmdz/bert-base-german-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_german_uncased\n",
      "/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks/jsonl/data.jsonl\n",
      "/home/peng_luh/__git/search_l3s/search_l3s_search_srv/encodes/dense/bert_german_uncased/mls-tasks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from search_l3s_search.api.encoder.logic import BertGermanUncasedDenseEncoder\n",
    "\n",
    "enc = BertGermanUncasedDenseEncoder()\n",
    "\n",
    "enc.print_model_name()\n",
    "\n",
    "enc.dataset_encoder(dataset_name=\"mls-tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-german-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks/jsonl/data.jsonl\n",
      "/home/peng_luh/__git/search_l3s/search_l3s_search_srv/encodes/dense/bert_german_uncased/mls-tasks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from search_l3s_search.api.encoder.logic import BertGermanUncasedDenseEncoder\n",
    "\n",
    "enc = BertGermanUncasedDenseEncoder()\n",
    "\n",
    "print(len(enc.query_encoder(\"Beispiel\")))\n",
    "\n",
    "enc.dataset_encoder(dataset_name=\"mls-tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "def hnsw_indexer(encode_cat, model_name, dataset_name):\n",
    "        dataset_encode_path = os.path.join(os.getcwd(),\n",
    "                                            f\"encodes/{encode_cat}/{model_name}/{dataset_name}\"\n",
    "                                        )\n",
    "        if not os.path.exists(dataset_encode_path):\n",
    "            raise FileNotFoundError\n",
    "        \n",
    "        output_path = os.path.join(os.getcwd(), f\"indexes/{encode_cat}/{model_name}/hnsw/{dataset_name}\")\n",
    "        # print(output_path)\n",
    "        \n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        \n",
    "        hnsw_cmd = f\"\"\"\n",
    "            python -m pyserini.index.faiss \\\n",
    "                --input {dataset_encode_path} \\\n",
    "                --output {output_path} \\\n",
    "                --hnsw\n",
    "        \"\"\"\n",
    "        \n",
    "        subprocess.call(hnsw_cmd, shell=True)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326, 768)\n",
      "hnsw_add_vertices: adding 326 elements on top of 0 (preset_levels=0)\n",
      "  max_level = 0\n",
      "Adding 326 elements at level 0\n",
      "Done in 40.108 ms\n",
      "326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hnsw_indexer(encode_cat=\"dense\", model_name=\"bert_german_uncased\", dataset_name=\"mls-tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search.faiss import FaissSearcher\n",
    "import json\n",
    "\n",
    "def dense_retrieval(query):\n",
    "        model_name = \"bert_german_uncased\"\n",
    "        dataset_name = \"mls-tasks\"\n",
    "        index_method = \"hnsw\"\n",
    "        \n",
    "        dataset_file_path = os.path.join(os.getcwd(), f\"datasets/{dataset_name}/jsonl/data.jsonl\")\n",
    "        \n",
    "        prebuilt_index_path = os.path.join(os.getcwd(), f\"indexes/dense/{model_name}/{index_method}/{dataset_name}\")\n",
    "\n",
    "        search_engine = FaissSearcher(\n",
    "            prebuilt_index_path,\n",
    "            \"dbmdz/bert-base-german-uncased\"\n",
    "        )\n",
    "                \n",
    "        hits = search_engine.search(query)\n",
    "        results=[]\n",
    "        \n",
    "        # if hits:\n",
    "        #     for i in range(0, len(hits)):\n",
    "        #         temp = ast.literal_eval(hits[i].raw)\n",
    "        #         temp['score'] = f'{hits[i].score:.4f}'\n",
    "        #         results.append(temp)\n",
    "        \n",
    "        for i in range(0, 10):\n",
    "            docid = hits[i].docid\n",
    "            with open(dataset_file_path, \"r\") as dataset:\n",
    "                for line in dataset:\n",
    "                    json_obj = json.loads(line)\n",
    "                    if int(docid) == json_obj[\"id\"]:\n",
    "                        temp = dict()\n",
    "                        temp[\"@id\"] = json_obj[\"@id\"]\n",
    "                        temp[\"contents\"] = json_obj[\"contents\"]\n",
    "                        temp[\"score\"] = f\"{hits[i].score:.5f}\"\n",
    "                        results.append(temp)\n",
    "            \n",
    "            # print(f'{i+1:2} {hits[i].docid:7} {hits[i].score:.5f}')\n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_331 = [0.22154638171195984, -0.03536605462431908, -0.2912493050098419, 0.5319214463233948, -0.36612260341644287, 0.03568511828780174, 0.27370965480804443, 0.00978295411914587, -0.045464105904102325, -0.267067551612854, 0.6439609527587891, -0.1166854053735733, -0.7110666632652283, 0.9173524379730225, 0.4479750990867615, 0.22522468864917755, -0.5504530668258667, -0.3796117305755615, -0.41885364055633545, -0.5035166144371033, 0.18854443728923798, 0.23881149291992188, 1.1101657152175903, -0.9617190361022949, -0.006559269968420267, 0.2220858633518219, -0.22361570596694946, -0.18334241211414337, -0.03386091813445091, 0.6254233717918396, 0.40355944633483887, -0.6828979253768921, 0.5137401819229126, 0.5067671537399292, -0.3722723424434662, 0.2831169664859772, -0.24351198971271515, 0.3541296720504761, 0.5935749411582947, -0.11793436110019684, 0.2677404582500458, -0.2652527391910553, 0.5108146071434021, -0.5921666622161865, -0.17076407372951508, -0.4888835847377777, -0.048121627420186996, -1.0304791927337646, -0.02815260738134384, -0.24148282408714294, -0.6323826313018799, 0.08970674127340317, 0.46729499101638794, -0.27126574516296387, -0.16023801267147064, 0.2958875894546509, 0.2974606454372406, 0.6791817545890808, -0.027798665687441826, 0.8141459822654724, 0.7901440858840942, -0.19421859085559845, -0.06948456913232803, -0.021152153611183167, 0.36398953199386597, -0.4986671507358551, -0.3841012120246887, -1.1012091636657715, -0.18721577525138855, 0.05288136005401611, -0.16339851915836334, 0.2620474696159363, 0.4209460914134979, -3.2898201942443848, 0.13884419202804565, 0.49751394987106323, 1.4624335765838623, 0.4739340543746948, 0.32848060131073, -0.6530799865722656, 0.07329990714788437, 0.031008083373308182, -0.8977426886558533, 0.06638327240943909, 0.011134698055684566, 0.6172598600387573, -1.379198670387268, 0.2541881799697876, 0.2216394692659378, -0.4148119390010834, 0.2917603552341461, -0.3300979435443878, -0.03924437239766121, -0.9383015036582947, -0.020288363099098206, -0.07907771319150925, 0.09857144951820374, -0.3385886549949646, -0.4194817841053009, 0.32148635387420654, -0.07520481944084167, -0.2854905426502228, -0.20120887458324432, -0.3893740475177765, 0.23189781606197357, 0.20734094083309174, 0.22193670272827148, 0.46635064482688904, 0.9917510747909546, -0.3811907470226288, -0.08535239845514297, -0.13135433197021484, 0.3366360664367676, 0.8447031378746033, 0.5194770097732544, 0.4730754792690277, -0.10181786119937897, 0.4108662009239197, 0.563346803188324, -0.004596702288836241, 0.10382963716983795, 0.1976446956396103, -0.4171176552772522, -0.01944463886320591, -0.6670040488243103, -0.20813995599746704, 0.25109803676605225, 0.29040631651878357, 0.19775390625, -0.806316077709198, -1.5847177505493164, 0.287110298871994, 0.6104015111923218, 0.06437893956899643, -0.37466368079185486, 0.3771003782749176, 0.137516051530838, 0.3757713735103607, 1.0917292833328247, -0.17437972128391266, 0.26122725009918213, -0.004995782393962145, -0.5880810618400574, 0.6752739548683167, 0.1093020811676979, 0.2423037886619568, -0.3378508687019348, -0.10573738068342209, -0.3565458357334137, -14.043425559997559, 0.47333618998527527, 0.9879235625267029, -0.5170160531997681, -1.191133975982666, 0.4889661371707916, 0.25763139128685, -0.03934541717171669, -0.4841372072696686, -0.06555373221635818, 0.05024592950940132, -0.8585819602012634, -0.1499122679233551, -0.47456884384155273, -0.8169113993644714, 0.4768712818622589, -0.09233439713716507, -0.06613187491893768, 0.37947332859039307, -0.5797991156578064, 0.2505777180194855, 0.47341272234916687, 0.35033443570137024, -1.1364407539367676, 0.2004738301038742, -0.08153394609689713, -0.34715622663497925, -0.33537548780441284, 0.47172775864601135, 0.05629431828856468, -0.7562210559844971, 0.2860223650932312, 0.33384695649147034, 0.7083267569541931, -0.13190196454524994, 1.2097312211990356, -0.28878292441368103, -0.10386764258146286, -0.5908347964286804, 0.47809305787086487, 0.2522825598716736, 0.03384004160761833, 0.1476939618587494, 0.16521002352237701, -0.037338756024837494, 0.4095965027809143, -0.3498218357563019, 0.03930428624153137, -0.04635385423898697, 0.9078057408332825, 0.2618737518787384, 0.5488669872283936, 0.015335286036133766, -0.29952970147132874, -0.506941556930542, -0.010026415809988976, -0.06746960431337357, 0.15556350350379944, 0.2657564580440521, -1.2192751169204712, 0.18280719220638275, -0.06940429657697678, -0.2720226049423218, -0.5463625192642212, 0.43049514293670654, -0.3362327814102173, 0.08873749524354935, 0.24111127853393555, 0.13457022607326508, 1.2211908102035522, 0.4936220943927765, 0.2184792459011078, 0.36253029108047485, 0.45400264859199524, 0.2977726459503174, -0.10401637107133865, 0.18768416345119476, 0.21402980387210846, 0.22453179955482483, 0.03527450934052467, -0.09471135586500168, -0.191964790225029, -0.40598565340042114, -0.009422004222869873, 0.235077366232872, -0.913417398929596, 0.2609175741672516, 0.4095500111579895, 0.2356719821691513, -0.1571531444787979, 0.8467679023742676, 0.038500506430864334, -0.271562397480011, 0.318322092294693, -0.3009224534034729, 0.0237403754144907, 0.45458608865737915, -0.06051953136920929, -0.25164952874183655, 0.33925238251686096, 0.2361641526222229, -0.39735147356987, 0.08137153089046478, -0.19485220313072205, -0.3810477554798126, 0.009734799154102802, -0.25898462533950806, 0.7409868836402893, -0.07437841594219208, 0.0029077017679810524, 0.47381719946861267, 0.2935835123062134, 0.11488308012485504, 0.2173895388841629, -0.5445263981819153, -0.261358380317688, -0.09375723451375961, -0.2329961657524109, -0.3792358636856079, 0.8232138752937317, -0.15006932616233826, 0.020131032913923264, 0.01216090191155672, -0.6171147227287292, 0.1832321286201477, 0.5187524557113647, 0.011182336136698723, -0.009324604645371437, 0.27990487217903137, 0.20388612151145935, 0.5358164310455322, 0.07206989079713821, 0.9242681264877319, -0.263177752494812, 0.6874938607215881, 0.3132344186306, 0.1495007425546646, 0.01707719825208187, 0.3223930895328522, -0.650538980960846, -0.14148642122745514, -0.4693257212638855, 0.09812896698713303, 0.0019449596293270588, 0.05856376886367798, -0.8004976511001587, -0.468003511428833, 0.42769551277160645, -0.3013893663883209, -0.0921923890709877, 0.14745904505252838, 0.6136793494224548, 0.6398677825927734, -0.12428512424230576, -0.12186910957098007, -0.6339580416679382, -0.3424898386001587, -0.2910423278808594, 0.32909417152404785, -0.08585228025913239, 0.13842763006687164, 0.411792516708374, 0.534913957118988, 0.42631080746650696, -0.22637243568897247, -0.08645687997341156, 0.13470439612865448, -0.8058285713195801, 0.2505238950252533, -0.0877099558711052, 0.2665371298789978, -0.3572221100330353, 0.37013161182403564, -0.7641989588737488, 0.8427732586860657, -0.36719581484794617, 0.017611632123589516, -0.28877130150794983, 1.0331522226333618, -0.7090998888015747, -0.08541853725910187, -0.14591820538043976, -0.16174393892288208, 0.8785203099250793, -0.6647529006004333, -1.1045868396759033, 0.010873427614569664, 0.01748516783118248, -0.38860464096069336, -0.4298636019229889, -0.500834584236145, 0.7375121116638184, -0.07536491006612778, 0.6416773796081543, -0.386107474565506, -0.19342394173145294, -0.46380215883255005, -0.04931049421429634, 0.43778252601623535, 0.32846617698669434, -0.04507628455758095, 0.9580941200256348, 1.0597399473190308, 0.0874054878950119, -0.41313958168029785, 0.5303297638893127, 0.11317025125026703, -0.3927030563354492, -0.5442252159118652, 0.7966984510421753, -0.1298971176147461, -0.20649994909763336, -0.946942150592804, 0.021568890661001205, 1.1890907287597656, -1.2584587335586548, -0.33032625913619995, -0.5287941098213196, 0.1044955775141716, 0.6208651065826416, 0.3320682644844055, 0.3645220100879669, 0.31699275970458984, -0.254189670085907, -0.5772091150283813, 0.09218815714120865, -0.20067502558231354, -0.1096423864364624, -0.4546753466129303, -0.22713476419448853, -0.07566504925489426, -0.12437400221824646, 0.597306489944458, -0.27569589018821716, -0.33553454279899597, 0.6672300100326538, -0.37848639488220215, 0.1949804127216339, -0.18572303652763367, -0.10126736015081406, -0.1346205174922943, -0.13155597448349, -1.0336236953735352, 0.10716253519058228, -0.5330153107643127, 0.7319086194038391, 0.5263681411743164, -0.23031586408615112, -0.5921040773391724, 0.0830376073718071, -0.050373226404190063, -0.21228475868701935, -0.7342960834503174, -0.39397627115249634, 0.06279758363962173, -0.04762892797589302, -0.17493334412574768, -0.5439286828041077, 0.3184834122657776, -0.5473164916038513, 0.15268610417842865, 0.18267792463302612, 0.21561913192272186, 0.5564021468162537, 0.05969442427158356, -0.3835783302783966, -1.075946569442749, -0.23557469248771667, 0.19136376678943634, -0.289767324924469, -0.08182723820209503, -0.3794582486152649, 0.06350813806056976, 0.6975003480911255, -0.15292294323444366, 0.343221515417099, 0.22280757129192352, -0.513473629951477, -0.30218952894210815, -0.42250365018844604, 0.1660229116678238, -0.30724847316741943, 0.21209849417209625, -0.8669721484184265, 0.9081754684448242, 0.45162251591682434, 1.4697083234786987, 0.3743985593318939, 0.1878405511379242, -0.16802945733070374, 0.44648921489715576, 1.2136332988739014, 0.09858949482440948, 0.31655964255332947, 0.07666774094104767, 0.19530776143074036, 0.10853416472673416, -0.09794075787067413, 0.1263394057750702, 0.004142037592828274, -0.6776214838027954, -0.3137854039669037, 0.1892148107290268, 0.06586449593305588, 0.03050629049539566, 0.2779353857040405, -0.26581695675849915, -0.12435257434844971, -0.11469384282827377, 0.19596610963344574, 0.4760918617248535, 0.16739672422409058, 0.36044934391975403, 0.20693767070770264, 0.600701630115509, 0.05300360918045044, -0.6535438299179077, 0.29670313000679016, -0.2649935483932495, 0.3100591003894806, -0.16534222662448883, 0.603947103023529, -0.1965954452753067, 0.22026464343070984, 0.5556516051292419, 0.3796635568141937, -1.0347172021865845, -0.6868613362312317, -0.5368090867996216, -0.1719871312379837, 0.12198743224143982, -0.5445279479026794, -0.16824106872081757, 0.0002375345939071849, -0.18796195089817047, -0.45415955781936646, -0.42497947812080383, -0.4615939259529114, -0.20420196652412415, 0.3073006570339203, 0.030007638037204742, -0.7294412851333618, -0.3453335165977478, -0.5656929016113281, -0.5996313095092773, -0.30348968505859375, -0.20380379259586334, 0.007559905294328928, -0.45595479011535645, -0.07570259273052216, 0.03928603231906891, -0.1769038885831833, -0.13529008626937866, 1.1439050436019897, -0.33488404750823975, -0.41670677065849304, 0.3602760434150696, -0.0847148448228836, -0.25955817103385925, -0.2038497030735016, -0.2561943531036377, 1.0978432893753052, 0.20240794122219086, 0.461073637008667, 0.1298782080411911, -0.3727109432220459, 0.7304834127426147, 0.5297349691390991, -0.551512598991394, 0.7137865424156189, 0.10095083713531494, -0.013575551100075245, -0.20321029424667358, -0.4811446964740753, -0.2997974455356598, -0.37714141607284546, -1.0301226377487183, 0.022593699395656586, 0.6810116171836853, -0.05781028792262077, 0.24921448528766632, 0.5631072521209717, 0.5052714943885803, -0.5453206896781921, 0.1162337139248848, 0.2852400839328766, -0.1939760446548462, 0.4778609573841095, 0.17707528173923492, 0.20232945680618286, 0.6441445350646973, -0.32558736205101013, -0.3608724772930145, -0.3715103566646576, 0.11373715102672577, 0.04518590122461319, 0.7240031361579895, -0.08473435789346695, 0.9469995498657227, 0.2008855640888214, -0.01693122088909149, 0.30899757146835327, 0.5058563947677612, 0.5853034853935242, -0.7788946032524109, -0.32663822174072266, 0.720164954662323, -0.05127892270684242, 0.09994880855083466, 0.20955879986286163, 0.28164759278297424, 1.2397141456604004, 0.22406895458698273, -0.16704663634300232, 0.23139506578445435, 0.16772791743278503, 0.12261948734521866, 0.4314460754394531, -0.45407983660697937, -0.44550782442092896, 0.15390868484973907, 0.0610174685716629, 0.41923561692237854, -0.49442362785339355, 0.48522162437438965, -0.7421517372131348, 0.03433595970273018, 0.0006315102800726891, -0.41982829570770264, -0.1552351415157318, 0.13251811265945435, -0.6308271288871765, -1.5918852090835571, -0.48867014050483704, 0.8102247714996338, -0.68392413854599, 0.13340236246585846, -0.40186306834220886, 0.7239654064178467, 0.45854106545448303, -0.34783491492271423, 0.6744083166122437, 0.004725173115730286, -0.13768263161182404, 0.11462234705686569, 0.6968070864677429, 0.754035234451294, 0.2863507568836212, 1.0739479064941406, -0.04527704790234566, 0.42607423663139343, -0.16836144030094147, 0.8456312417984009, 0.2766447067260742, -0.5625872611999512, 0.539954423904419, 0.11684135347604752, 0.5189899802207947, -0.43748271465301514, 0.20900914072990417, 1.0194834470748901, 0.22133643925189972, 0.2640106678009033, -0.41443586349487305, 0.5090633630752563, -0.37466493248939514, -0.06732446700334549, 0.8816194534301758, 0.19706715643405914, 0.33617717027664185, -0.3937286138534546, 0.26783373951911926, -0.6894789934158325, 0.843172013759613, 0.2604798674583435, 0.6511631608009338, 0.5821529626846313, 0.3069513142108917, 0.17376618087291718, 0.18571771681308746, 0.32309484481811523, 0.47388768196105957, -0.3340679407119751, -0.10960562527179718, 0.34419724345207214, -0.1232864260673523, -0.443847119808197, 0.7879575490951538, 0.3149968683719635, 0.1349290907382965, -0.5409595966339111, 0.151164710521698, -0.14085401594638824, 0.276419460773468, 0.3630043566226959, -0.449211061000824, -0.6947718262672424, 0.5284052491188049, -0.39295142889022827, 0.4084552824497223, 0.5665998458862305, 0.7901442050933838, -0.25017213821411133, 0.22328875958919525, -0.11152839660644531, 0.6064267158508301, 0.3957063853740692, -0.03258167579770088, -0.03688677400350571, -0.7916764616966248, 0.18453571200370789, -0.10405879467725754, -0.2748679518699646, -0.02709329128265381, -0.6729950308799744, 1.5267003774642944, 0.5404310822486877, 0.6259427070617676, 0.07243498414754868, 0.03122643753886223, 0.832466185092926, 0.05452905222773552, -0.28396075963974, 0.22088930010795593, -0.16975024342536926, -0.35301029682159424, -0.07598623633384705, 0.07032258808612823, -0.8090739846229553, -0.14253629744052887, 0.76167231798172, -0.04696652293205261, -1.210944652557373, 0.4921262860298157, 0.16249603033065796, -0.12937864661216736, 0.8671388030052185, -0.40338319540023804, 0.3843778073787689, -0.7210575938224792, -0.3896016776561737, -0.012906895019114017, -0.26147031784057617, 0.10315210372209549, -0.6329640746116638, -0.5726400017738342, 1.100956678390503, -0.3385281562805176, 0.1337314248085022, -0.4345676898956299, 0.6876882910728455, 0.04344357177615166, -0.17304807901382446, 0.25321730971336365, -0.8290703296661377, 1.0179016590118408, 0.26629671454429626, 0.31281203031539917, -0.030012033879756927, 0.654255747795105, -1.029093861579895, 0.5767906904220581, -0.47162967920303345, -0.026003235951066017, 0.29319819808006287, -0.6430271863937378, -0.09829962253570557, -0.6163454055786133, 0.2679811716079712, 0.12214057892560959, 0.4514056146144867, 0.244789257645607, 0.33376190066337585, -0.13890382647514343, 0.15278877317905426, 0.29844173789024353, -0.147852823138237, -0.3871980309486389, -0.5550984144210815, -0.38286474347114563, -0.255177766084671, -0.1669131964445114, -0.59510737657547, -0.09419433772563934, -0.09870947152376175, 0.5180899500846863, 0.027720343321561813, 0.06511766463518143, -0.1658174693584442, 0.4609411656856537, -1.0799025297164917, -0.5820200443267822, -0.12321826815605164, -1.3496798276901245, -0.5268656611442566, 0.3543970286846161, -0.10355700552463531, 0.13736726343631744, -0.2346586436033249, -0.01607373170554638, 1.2557207345962524, -0.18556655943393707, 0.19090339541435242, 0.6681014895439148, 0.2220887839794159, -0.16175973415374756, -0.0326644666492939, -0.5007616877555847, -0.38724035024642944, 0.3141181170940399, -0.1938156634569168, 0.17886663973331451, 0.19278892874717712, -0.38518935441970825, -0.7564964294433594, 0.39979851245880127, 0.2148739993572235, 0.533394992351532, -1.0600650310516357]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102, 17756, 232, 15008, 7591, 11634, 232, 12298, 3464, 18666, 3464, 4367, 1176, 875, 3464, 5091, 136, 11137, 3464, 21074, 21094, 103]\n",
      "[0.22154638171195984, -0.03536605462431908, -0.2912493050098419, 0.5319214463233948, -0.36612260341644287, 0.03568511828780174, 0.27370965480804443, 0.00978295411914587, -0.045464105904102325, -0.267067551612854, 0.6439609527587891, -0.1166854053735733, -0.7110666632652283, 0.9173524379730225, 0.4479750990867615, 0.22522468864917755, -0.5504530668258667, -0.3796117305755615, -0.41885364055633545, -0.5035166144371033, 0.18854443728923798, 0.23881149291992188, 1.1101657152175903, -0.9617190361022949, -0.006559269968420267, 0.2220858633518219, -0.22361570596694946, -0.18334241211414337, -0.03386091813445091, 0.6254233717918396, 0.40355944633483887, -0.6828979253768921, 0.5137401819229126, 0.5067671537399292, -0.3722723424434662, 0.2831169664859772, -0.24351198971271515, 0.3541296720504761, 0.5935749411582947, -0.11793436110019684, 0.2677404582500458, -0.2652527391910553, 0.5108146071434021, -0.5921666622161865, -0.17076407372951508, -0.4888835847377777, -0.048121627420186996, -1.0304791927337646, -0.02815260738134384, -0.24148282408714294, -0.6323826313018799, 0.08970674127340317, 0.46729499101638794, -0.27126574516296387, -0.16023801267147064, 0.2958875894546509, 0.2974606454372406, 0.6791817545890808, -0.027798665687441826, 0.8141459822654724, 0.7901440858840942, -0.19421859085559845, -0.06948456913232803, -0.021152153611183167, 0.36398953199386597, -0.4986671507358551, -0.3841012120246887, -1.1012091636657715, -0.18721577525138855, 0.05288136005401611, -0.16339851915836334, 0.2620474696159363, 0.4209460914134979, -3.2898201942443848, 0.13884419202804565, 0.49751394987106323, 1.4624335765838623, 0.4739340543746948, 0.32848060131073, -0.6530799865722656, 0.07329990714788437, 0.031008083373308182, -0.8977426886558533, 0.06638327240943909, 0.011134698055684566, 0.6172598600387573, -1.379198670387268, 0.2541881799697876, 0.2216394692659378, -0.4148119390010834, 0.2917603552341461, -0.3300979435443878, -0.03924437239766121, -0.9383015036582947, -0.020288363099098206, -0.07907771319150925, 0.09857144951820374, -0.3385886549949646, -0.4194817841053009, 0.32148635387420654, -0.07520481944084167, -0.2854905426502228, -0.20120887458324432, -0.3893740475177765, 0.23189781606197357, 0.20734094083309174, 0.22193670272827148, 0.46635064482688904, 0.9917510747909546, -0.3811907470226288, -0.08535239845514297, -0.13135433197021484, 0.3366360664367676, 0.8447031378746033, 0.5194770097732544, 0.4730754792690277, -0.10181786119937897, 0.4108662009239197, 0.563346803188324, -0.004596702288836241, 0.10382963716983795, 0.1976446956396103, -0.4171176552772522, -0.01944463886320591, -0.6670040488243103, -0.20813995599746704, 0.25109803676605225, 0.29040631651878357, 0.19775390625, -0.806316077709198, -1.5847177505493164, 0.287110298871994, 0.6104015111923218, 0.06437893956899643, -0.37466368079185486, 0.3771003782749176, 0.137516051530838, 0.3757713735103607, 1.0917292833328247, -0.17437972128391266, 0.26122725009918213, -0.004995782393962145, -0.5880810618400574, 0.6752739548683167, 0.1093020811676979, 0.2423037886619568, -0.3378508687019348, -0.10573738068342209, -0.3565458357334137, -14.043425559997559, 0.47333618998527527, 0.9879235625267029, -0.5170160531997681, -1.191133975982666, 0.4889661371707916, 0.25763139128685, -0.03934541717171669, -0.4841372072696686, -0.06555373221635818, 0.05024592950940132, -0.8585819602012634, -0.1499122679233551, -0.47456884384155273, -0.8169113993644714, 0.4768712818622589, -0.09233439713716507, -0.06613187491893768, 0.37947332859039307, -0.5797991156578064, 0.2505777180194855, 0.47341272234916687, 0.35033443570137024, -1.1364407539367676, 0.2004738301038742, -0.08153394609689713, -0.34715622663497925, -0.33537548780441284, 0.47172775864601135, 0.05629431828856468, -0.7562210559844971, 0.2860223650932312, 0.33384695649147034, 0.7083267569541931, -0.13190196454524994, 1.2097312211990356, -0.28878292441368103, -0.10386764258146286, -0.5908347964286804, 0.47809305787086487, 0.2522825598716736, 0.03384004160761833, 0.1476939618587494, 0.16521002352237701, -0.037338756024837494, 0.4095965027809143, -0.3498218357563019, 0.03930428624153137, -0.04635385423898697, 0.9078057408332825, 0.2618737518787384, 0.5488669872283936, 0.015335286036133766, -0.29952970147132874, -0.506941556930542, -0.010026415809988976, -0.06746960431337357, 0.15556350350379944, 0.2657564580440521, -1.2192751169204712, 0.18280719220638275, -0.06940429657697678, -0.2720226049423218, -0.5463625192642212, 0.43049514293670654, -0.3362327814102173, 0.08873749524354935, 0.24111127853393555, 0.13457022607326508, 1.2211908102035522, 0.4936220943927765, 0.2184792459011078, 0.36253029108047485, 0.45400264859199524, 0.2977726459503174, -0.10401637107133865, 0.18768416345119476, 0.21402980387210846, 0.22453179955482483, 0.03527450934052467, -0.09471135586500168, -0.191964790225029, -0.40598565340042114, -0.009422004222869873, 0.235077366232872, -0.913417398929596, 0.2609175741672516, 0.4095500111579895, 0.2356719821691513, -0.1571531444787979, 0.8467679023742676, 0.038500506430864334, -0.271562397480011, 0.318322092294693, -0.3009224534034729, 0.0237403754144907, 0.45458608865737915, -0.06051953136920929, -0.25164952874183655, 0.33925238251686096, 0.2361641526222229, -0.39735147356987, 0.08137153089046478, -0.19485220313072205, -0.3810477554798126, 0.009734799154102802, -0.25898462533950806, 0.7409868836402893, -0.07437841594219208, 0.0029077017679810524, 0.47381719946861267, 0.2935835123062134, 0.11488308012485504, 0.2173895388841629, -0.5445263981819153, -0.261358380317688, -0.09375723451375961, -0.2329961657524109, -0.3792358636856079, 0.8232138752937317, -0.15006932616233826, 0.020131032913923264, 0.01216090191155672, -0.6171147227287292, 0.1832321286201477, 0.5187524557113647, 0.011182336136698723, -0.009324604645371437, 0.27990487217903137, 0.20388612151145935, 0.5358164310455322, 0.07206989079713821, 0.9242681264877319, -0.263177752494812, 0.6874938607215881, 0.3132344186306, 0.1495007425546646, 0.01707719825208187, 0.3223930895328522, -0.650538980960846, -0.14148642122745514, -0.4693257212638855, 0.09812896698713303, 0.0019449596293270588, 0.05856376886367798, -0.8004976511001587, -0.468003511428833, 0.42769551277160645, -0.3013893663883209, -0.0921923890709877, 0.14745904505252838, 0.6136793494224548, 0.6398677825927734, -0.12428512424230576, -0.12186910957098007, -0.6339580416679382, -0.3424898386001587, -0.2910423278808594, 0.32909417152404785, -0.08585228025913239, 0.13842763006687164, 0.411792516708374, 0.534913957118988, 0.42631080746650696, -0.22637243568897247, -0.08645687997341156, 0.13470439612865448, -0.8058285713195801, 0.2505238950252533, -0.0877099558711052, 0.2665371298789978, -0.3572221100330353, 0.37013161182403564, -0.7641989588737488, 0.8427732586860657, -0.36719581484794617, 0.017611632123589516, -0.28877130150794983, 1.0331522226333618, -0.7090998888015747, -0.08541853725910187, -0.14591820538043976, -0.16174393892288208, 0.8785203099250793, -0.6647529006004333, -1.1045868396759033, 0.010873427614569664, 0.01748516783118248, -0.38860464096069336, -0.4298636019229889, -0.500834584236145, 0.7375121116638184, -0.07536491006612778, 0.6416773796081543, -0.386107474565506, -0.19342394173145294, -0.46380215883255005, -0.04931049421429634, 0.43778252601623535, 0.32846617698669434, -0.04507628455758095, 0.9580941200256348, 1.0597399473190308, 0.0874054878950119, -0.41313958168029785, 0.5303297638893127, 0.11317025125026703, -0.3927030563354492, -0.5442252159118652, 0.7966984510421753, -0.1298971176147461, -0.20649994909763336, -0.946942150592804, 0.021568890661001205, 1.1890907287597656, -1.2584587335586548, -0.33032625913619995, -0.5287941098213196, 0.1044955775141716, 0.6208651065826416, 0.3320682644844055, 0.3645220100879669, 0.31699275970458984, -0.254189670085907, -0.5772091150283813, 0.09218815714120865, -0.20067502558231354, -0.1096423864364624, -0.4546753466129303, -0.22713476419448853, -0.07566504925489426, -0.12437400221824646, 0.597306489944458, -0.27569589018821716, -0.33553454279899597, 0.6672300100326538, -0.37848639488220215, 0.1949804127216339, -0.18572303652763367, -0.10126736015081406, -0.1346205174922943, -0.13155597448349, -1.0336236953735352, 0.10716253519058228, -0.5330153107643127, 0.7319086194038391, 0.5263681411743164, -0.23031586408615112, -0.5921040773391724, 0.0830376073718071, -0.050373226404190063, -0.21228475868701935, -0.7342960834503174, -0.39397627115249634, 0.06279758363962173, -0.04762892797589302, -0.17493334412574768, -0.5439286828041077, 0.3184834122657776, -0.5473164916038513, 0.15268610417842865, 0.18267792463302612, 0.21561913192272186, 0.5564021468162537, 0.05969442427158356, -0.3835783302783966, -1.075946569442749, -0.23557469248771667, 0.19136376678943634, -0.289767324924469, -0.08182723820209503, -0.3794582486152649, 0.06350813806056976, 0.6975003480911255, -0.15292294323444366, 0.343221515417099, 0.22280757129192352, -0.513473629951477, -0.30218952894210815, -0.42250365018844604, 0.1660229116678238, -0.30724847316741943, 0.21209849417209625, -0.8669721484184265, 0.9081754684448242, 0.45162251591682434, 1.4697083234786987, 0.3743985593318939, 0.1878405511379242, -0.16802945733070374, 0.44648921489715576, 1.2136332988739014, 0.09858949482440948, 0.31655964255332947, 0.07666774094104767, 0.19530776143074036, 0.10853416472673416, -0.09794075787067413, 0.1263394057750702, 0.004142037592828274, -0.6776214838027954, -0.3137854039669037, 0.1892148107290268, 0.06586449593305588, 0.03050629049539566, 0.2779353857040405, -0.26581695675849915, -0.12435257434844971, -0.11469384282827377, 0.19596610963344574, 0.4760918617248535, 0.16739672422409058, 0.36044934391975403, 0.20693767070770264, 0.600701630115509, 0.05300360918045044, -0.6535438299179077, 0.29670313000679016, -0.2649935483932495, 0.3100591003894806, -0.16534222662448883, 0.603947103023529, -0.1965954452753067, 0.22026464343070984, 0.5556516051292419, 0.3796635568141937, -1.0347172021865845, -0.6868613362312317, -0.5368090867996216, -0.1719871312379837, 0.12198743224143982, -0.5445279479026794, -0.16824106872081757, 0.0002375345939071849, -0.18796195089817047, -0.45415955781936646, -0.42497947812080383, -0.4615939259529114, -0.20420196652412415, 0.3073006570339203, 0.030007638037204742, -0.7294412851333618, -0.3453335165977478, -0.5656929016113281, -0.5996313095092773, -0.30348968505859375, -0.20380379259586334, 0.007559905294328928, -0.45595479011535645, -0.07570259273052216, 0.03928603231906891, -0.1769038885831833, -0.13529008626937866, 1.1439050436019897, -0.33488404750823975, -0.41670677065849304, 0.3602760434150696, -0.0847148448228836, -0.25955817103385925, -0.2038497030735016, -0.2561943531036377, 1.0978432893753052, 0.20240794122219086, 0.461073637008667, 0.1298782080411911, -0.3727109432220459, 0.7304834127426147, 0.5297349691390991, -0.551512598991394, 0.7137865424156189, 0.10095083713531494, -0.013575551100075245, -0.20321029424667358, -0.4811446964740753, -0.2997974455356598, -0.37714141607284546, -1.0301226377487183, 0.022593699395656586, 0.6810116171836853, -0.05781028792262077, 0.24921448528766632, 0.5631072521209717, 0.5052714943885803, -0.5453206896781921, 0.1162337139248848, 0.2852400839328766, -0.1939760446548462, 0.4778609573841095, 0.17707528173923492, 0.20232945680618286, 0.6441445350646973, -0.32558736205101013, -0.3608724772930145, -0.3715103566646576, 0.11373715102672577, 0.04518590122461319, 0.7240031361579895, -0.08473435789346695, 0.9469995498657227, 0.2008855640888214, -0.01693122088909149, 0.30899757146835327, 0.5058563947677612, 0.5853034853935242, -0.7788946032524109, -0.32663822174072266, 0.720164954662323, -0.05127892270684242, 0.09994880855083466, 0.20955879986286163, 0.28164759278297424, 1.2397141456604004, 0.22406895458698273, -0.16704663634300232, 0.23139506578445435, 0.16772791743278503, 0.12261948734521866, 0.4314460754394531, -0.45407983660697937, -0.44550782442092896, 0.15390868484973907, 0.0610174685716629, 0.41923561692237854, -0.49442362785339355, 0.48522162437438965, -0.7421517372131348, 0.03433595970273018, 0.0006315102800726891, -0.41982829570770264, -0.1552351415157318, 0.13251811265945435, -0.6308271288871765, -1.5918852090835571, -0.48867014050483704, 0.8102247714996338, -0.68392413854599, 0.13340236246585846, -0.40186306834220886, 0.7239654064178467, 0.45854106545448303, -0.34783491492271423, 0.6744083166122437, 0.004725173115730286, -0.13768263161182404, 0.11462234705686569, 0.6968070864677429, 0.754035234451294, 0.2863507568836212, 1.0739479064941406, -0.04527704790234566, 0.42607423663139343, -0.16836144030094147, 0.8456312417984009, 0.2766447067260742, -0.5625872611999512, 0.539954423904419, 0.11684135347604752, 0.5189899802207947, -0.43748271465301514, 0.20900914072990417, 1.0194834470748901, 0.22133643925189972, 0.2640106678009033, -0.41443586349487305, 0.5090633630752563, -0.37466493248939514, -0.06732446700334549, 0.8816194534301758, 0.19706715643405914, 0.33617717027664185, -0.3937286138534546, 0.26783373951911926, -0.6894789934158325, 0.843172013759613, 0.2604798674583435, 0.6511631608009338, 0.5821529626846313, 0.3069513142108917, 0.17376618087291718, 0.18571771681308746, 0.32309484481811523, 0.47388768196105957, -0.3340679407119751, -0.10960562527179718, 0.34419724345207214, -0.1232864260673523, -0.443847119808197, 0.7879575490951538, 0.3149968683719635, 0.1349290907382965, -0.5409595966339111, 0.151164710521698, -0.14085401594638824, 0.276419460773468, 0.3630043566226959, -0.449211061000824, -0.6947718262672424, 0.5284052491188049, -0.39295142889022827, 0.4084552824497223, 0.5665998458862305, 0.7901442050933838, -0.25017213821411133, 0.22328875958919525, -0.11152839660644531, 0.6064267158508301, 0.3957063853740692, -0.03258167579770088, -0.03688677400350571, -0.7916764616966248, 0.18453571200370789, -0.10405879467725754, -0.2748679518699646, -0.02709329128265381, -0.6729950308799744, 1.5267003774642944, 0.5404310822486877, 0.6259427070617676, 0.07243498414754868, 0.03122643753886223, 0.832466185092926, 0.05452905222773552, -0.28396075963974, 0.22088930010795593, -0.16975024342536926, -0.35301029682159424, -0.07598623633384705, 0.07032258808612823, -0.8090739846229553, -0.14253629744052887, 0.76167231798172, -0.04696652293205261, -1.210944652557373, 0.4921262860298157, 0.16249603033065796, -0.12937864661216736, 0.8671388030052185, -0.40338319540023804, 0.3843778073787689, -0.7210575938224792, -0.3896016776561737, -0.012906895019114017, -0.26147031784057617, 0.10315210372209549, -0.6329640746116638, -0.5726400017738342, 1.100956678390503, -0.3385281562805176, 0.1337314248085022, -0.4345676898956299, 0.6876882910728455, 0.04344357177615166, -0.17304807901382446, 0.25321730971336365, -0.8290703296661377, 1.0179016590118408, 0.26629671454429626, 0.31281203031539917, -0.030012033879756927, 0.654255747795105, -1.029093861579895, 0.5767906904220581, -0.47162967920303345, -0.026003235951066017, 0.29319819808006287, -0.6430271863937378, -0.09829962253570557, -0.6163454055786133, 0.2679811716079712, 0.12214057892560959, 0.4514056146144867, 0.244789257645607, 0.33376190066337585, -0.13890382647514343, 0.15278877317905426, 0.29844173789024353, -0.147852823138237, -0.3871980309486389, -0.5550984144210815, -0.38286474347114563, -0.255177766084671, -0.1669131964445114, -0.59510737657547, -0.09419433772563934, -0.09870947152376175, 0.5180899500846863, 0.027720343321561813, 0.06511766463518143, -0.1658174693584442, 0.4609411656856537, -1.0799025297164917, -0.5820200443267822, -0.12321826815605164, -1.3496798276901245, -0.5268656611442566, 0.3543970286846161, -0.10355700552463531, 0.13736726343631744, -0.2346586436033249, -0.01607373170554638, 1.2557207345962524, -0.18556655943393707, 0.19090339541435242, 0.6681014895439148, 0.2220887839794159, -0.16175973415374756, -0.0326644666492939, -0.5007616877555847, -0.38724035024642944, 0.3141181170940399, -0.1938156634569168, 0.17886663973331451, 0.19278892874717712, -0.38518935441970825, -0.7564964294433594, 0.39979851245880127, 0.2148739993572235, 0.533394992351532, -1.0600650310516357]\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-german-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m results \u001b[39m=\u001b[39m dense_retrieval(query)\n\u001b[1;32m     15\u001b[0m pprint(results)\n",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m, in \u001b[0;36mdense_retrieval\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     11\u001b[0m prebuilt_index_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mgetcwd(), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindexes/dense/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mindex_method\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mdataset_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m enc \u001b[39m=\u001b[39m BertGermanUncasedDenseEncoder()\n\u001b[0;32m---> 14\u001b[0m search_engine \u001b[39m=\u001b[39m FaissSearcher(\n\u001b[1;32m     15\u001b[0m     prebuilt_index_path,\n\u001b[1;32m     16\u001b[0m     enc\u001b[39m.\u001b[39;49mquery_encoder \u001b[39m# \"dbmdz/bert-base-german-uncased\"\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m hits \u001b[39m=\u001b[39m search_engine\u001b[39m.\u001b[39msearch(query)\n\u001b[1;32m     20\u001b[0m results\u001b[39m=\u001b[39m[]\n",
      "File \u001b[0;32m~/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/search/faiss/_searcher.py:360\u001b[0m, in \u001b[0;36mFaissSearcher.__init__\u001b[0;34m(self, index_dir, query_encoder, prebuilt_index_name)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery_encoder \u001b[39m=\u001b[39m query_encoder\n\u001b[1;32m    359\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 360\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery_encoder \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_encoder_from_str(query_encoder)\n\u001b[1;32m    361\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_index(index_dir)\n\u001b[1;32m    362\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdimension \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39md\n",
      "File \u001b[0;32m~/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/search/faiss/_searcher.py:512\u001b[0m, in \u001b[0;36mFaissSearcher._init_encoder_from_str\u001b[0;34m(encoder)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    511\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_init_encoder_from_str\u001b[39m(encoder):\n\u001b[0;32m--> 512\u001b[0m     encoder_lower \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39;49mlower()\n\u001b[1;32m    513\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mdpr\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m encoder_lower:\n\u001b[1;32m    514\u001b[0m         \u001b[39mreturn\u001b[39;00m DprQueryEncoder(encoder_dir\u001b[39m=\u001b[39mencoder)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# 331\n",
    "query = \"Kick-off Regelungstechnik - Grundlagen; Cover; Sicherheitshinweise; Einf\\u00fchrung und Ablauf; Versuchsaufbau\"\n",
    "embdding_query = enc.query_encoder(query)\n",
    "print(embdding_query)\n",
    "\n",
    "if embedding_331 == embdding_query:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)\n",
    "    \n",
    "    \n",
    "results = dense_retrieval(query)\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "(326, 768)\n"
     ]
    }
   ],
   "source": [
    "# fetch the embedding as list\n",
    "import json, numpy\n",
    "\n",
    "sentence_embedding = []\n",
    "\n",
    "with open(\"./encodes/dense/bert_german_uncased/mls-tasks/data_encoded.jsonl\") as data:\n",
    "    for line in data:\n",
    "        json_obj = json.loads(line)\n",
    "        sentence_embedding.append(json_obj[\"vector\"])\n",
    "\n",
    "print(type(sentence_embedding))\n",
    "\n",
    "print(numpy.array(sentence_embedding).shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "sentence_embedding = numpy.array(sentence_embedding)\n",
    "index = faiss.IndexFlatL2(768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(numpy.float32(sentence_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 71  72  73  74 185  78 143 123 266 137]]\n",
      "[[ 0.        7.625406  8.257185 10.935714 46.676605 49.768665 55.11333\n",
      "  55.84443  55.84443  56.041443]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = 10\n",
    "\n",
    "xq = numpy.float32(numpy.array([enc.query_encoder(\"Montage- und Demontageautomat Versuch 5: Vollfunktion Montieren/Demontieren; Beschreibung; Erweiterungen des Aufbaus; Ablaufbeschreibung; Ablaufgraph; Programmerstellung in FUP\")]))\n",
    "\n",
    "# Distance, Labels\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mls-api/tasks/347\n"
     ]
    }
   ],
   "source": [
    "embd = sentence_embedding[71].tolist()\n",
    "\n",
    "with open(\"./encodes/dense/bert_german_uncased/mls-tasks/data_encoded.jsonl\") as data:\n",
    "    for line in data:\n",
    "        json_obj = json.loads(line)\n",
    "        if json_obj[\"vector\"] == embd:\n",
    "            print(json_obj[\"@id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "{'id': '/mls-api/tasks/356', 'contents': 'Ihr Feedback an uns; Willkommen; Feedbackbogen'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "f = open(\"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks/json/data.json\")\n",
    "\n",
    "data = json.load(f)\n",
    "\n",
    "print(type(data))\n",
    "\n",
    "lst = [62, 114, 206, 105, 118, 218, 192, 270, 230, 133]\n",
    "\n",
    "print(data[62])\n",
    "\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[418, 417, 416, 415, 414, 413, 412, 411, 410, 409, 408, 407, 406, 405, 404, 403, 402, 401, 400, 399, 398, 397, 396, 395, 394, 393, 392, 391, 390, 389, 388, 387, 386, 385, 384, 383, 382, 381, 380, 379, 378, 377, 376, 375, 374, 373, 372, 371, 370, 369, 368, 367, 366, 365, 364, 363, 362, 361, 360, 359, 358, 357, 356, 355, 354, 353, 352, 351, 350, 349, 348, 347, 346, 345, 344, 343, 342, 341, 340, 339, 338, 337, 336, 335, 334, 333, 332, 331, 330, 329, 328, 327, 326, 325, 324, 323, 322, 321, 320, 319, 318, 317, 316, 315, 314, 313, 312, 311, 310, 309, 308, 307, 306, 305, 304, 303, 302, 301, 300, 299, 298, 297, 296, 295, 294, 293, 292, 291, 290, 289, 288, 287, 286, 285, 284, 283, 282, 281, 280, 279, 278, 277, 276, 275, 274, 273, 272, 271, 270, 269, 268, 267, 266, 265, 264, 263, 262, 261, 260, 259, 258, 257, 256, 255, 254, 253, 252, 251, 250, 249, 248, 247, 246, 245, 244, 243, 242, 241, 240, 239, 238, 237, 236, 235, 234, 233, 232, 231, 230, 229, 228, 227, 226, 225, 224, 223, 222, 221, 220, 219, 218, 217, 216, 215, 214, 213, 212, 211, 210, 209, 208, 207, 206, 205, 204, 203, 202, 201, 200, 199, 198, 197, 196, 195, 194, 193, 192, 191, 190, 189, 188, 187, 186, 185, 184, 183, 182, 181, 180, 179, 178, 177, 176, 175, 174, 173, 172, 171, 170, 169, 168, 167, 166, 165, 164, 163, 162, 161, 160, 159, 158, 157, 156, 155, 154, 153, 152, 151, 150, 149, 148, 147, 146, 145, 144, 143, 142, 141, 140, 139, 138, 137, 136, 135, 134, 133, 132, 131, 130, 129, 128, 127, 126, 125, 124, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28]\n"
     ]
    }
   ],
   "source": [
    "o = open(\"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/indexes/dense/bert_german_uncased/flat/mls-tasks/docid\")\n",
    "\n",
    "docid = o.read()\n",
    "\n",
    "print(docid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<faiss.swigfaiss.IndexHNSWFlat; proxy of <Swig Object of type 'faiss::IndexHNSWFlat *' at 0x7f33ec3a6900> >\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "d = 128  # vector size\n",
    "M = 32   # number of neighbours add to each vertex on insertion\n",
    "\n",
    "\n",
    "index = faiss.IndexHNSWFlat(d, M)\n",
    "print(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.hnsw.max_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels = faiss.vector_to_array(index.hnsw.levels)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.bincount(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598 410 812\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "x = 4000\n",
    "\n",
    "f1 = int((x*0.083 + 175)*1.18)\n",
    "f2 = int((x*0.057 + 120)*1.18)\n",
    "\n",
    "f3 = int((x*0.109 + 230)*(1.22))\n",
    "\n",
    "print(f1, f2, f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m x \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m j \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/json/__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(s, (\u001b[39mbytes\u001b[39m, \u001b[39mbytearray\u001b[39m)):\n\u001b[0;32m--> 339\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    340\u001b[0m                         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnot \u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not list"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "x = [\"key\", \"key\", \"key\"]\n",
    "\n",
    "j = json.loads(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>task_title</th>\n",
       "      <th>tasksteps_ids</th>\n",
       "      <th>task_text</th>\n",
       "      <th>taskSet_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>418</td>\n",
       "      <td>Kick-off Grundlagen der Sensorik - Schwingungs...</td>\n",
       "      <td>[2092, 2093, 2094, 2095]</td>\n",
       "      <td>1. Cover:  Willkommen zum Projekt Grundlagen...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>417</td>\n",
       "      <td>Grundlagen der Sensorik: Schwingungssensor - B...</td>\n",
       "      <td>[2087, 2088, 2089, 2090, 2091]</td>\n",
       "      <td>1. Erluterung:  Sensoranordnung fur die Be...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>416</td>\n",
       "      <td>Grundlagen der Sensorik: Schwingungssensor - A...</td>\n",
       "      <td>[2083, 2084, 2085, 2086]</td>\n",
       "      <td>1. Arbeitsvorbereitung:  Arbeitsvorbereitung...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>415</td>\n",
       "      <td>Halbleiterbauelemente der Elektronik Versuch 2...</td>\n",
       "      <td>[2078, 2079, 2080, 2081, 2082]</td>\n",
       "      <td>1. Impedanzwandler:  Operationsverstarker a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>414</td>\n",
       "      <td>Halbleiterbauelemente der Elektronik Versuch 2...</td>\n",
       "      <td>[2071, 2072, 2073, 2074, 2075, 2076, 2077]</td>\n",
       "      <td>1. Operationsverstrker:  Operationsverstar...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id                                         task_title   \n",
       "0      418  Kick-off Grundlagen der Sensorik - Schwingungs...  \\\n",
       "1      417  Grundlagen der Sensorik: Schwingungssensor - B...   \n",
       "2      416  Grundlagen der Sensorik: Schwingungssensor - A...   \n",
       "3      415  Halbleiterbauelemente der Elektronik Versuch 2...   \n",
       "4      414  Halbleiterbauelemente der Elektronik Versuch 2...   \n",
       "\n",
       "                                tasksteps_ids   \n",
       "0                    [2092, 2093, 2094, 2095]  \\\n",
       "1              [2087, 2088, 2089, 2090, 2091]   \n",
       "2                    [2083, 2084, 2085, 2086]   \n",
       "3              [2078, 2079, 2080, 2081, 2082]   \n",
       "4  [2071, 2072, 2073, 2074, 2075, 2076, 2077]   \n",
       "\n",
       "                                           task_text  taskSet_ids  \n",
       "0    1. Cover:  Willkommen zum Projekt Grundlagen...            5  \n",
       "1    1. Erluterung:  Sensoranordnung fur die Be...            5  \n",
       "2    1. Arbeitsvorbereitung:  Arbeitsvorbereitung...            5  \n",
       "3    1. Impedanzwandler:  Operationsverstarker a...            5  \n",
       "4    1. Operationsverstrker:  Operationsverstar...            5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls_dataset.csv\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# len(dataset.iloc[0][\"task_text\"].translate(str.maketrans('', '', string.punctuation)).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kickoff', 'Analyse']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"Elektrotechnik 1 Versuch 8: Wirkleistung von Wechselspannungen; Herleitung der Wechselstromleistung; Wirkleistung der Sinuswechselspannung\"\n",
    "y = \"Kick-off LOGO! 8 PLC (Professional) Board 24V; Cover; Sicherheitshinweise; Einfhrung; Ablauf\"\n",
    "z = \"Kick-off; Analyse\"\n",
    "\n",
    "\n",
    "z.translate(str.maketrans('', '', string.punctuation)).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kick-off analyse'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex as re    \n",
    "re.sub(r\"\\p{P}(?<!-)\", \"\", z).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kick-off'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Kick-off\"\n",
    "query.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "replace() argument 1 must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m punctuation_marks \u001b[39m=\u001b[39m string\u001b[39m.\u001b[39;49mpunctuation\u001b[39m.\u001b[39;49mreplace([\u001b[39m\"\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m], [\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      2\u001b[0m punctuation_marks\n",
      "\u001b[0;31mTypeError\u001b[0m: replace() argument 1 must be str, not list"
     ]
    }
   ],
   "source": [
    "punctuation_marks = string.punctuation.replace([\"-\", \"+\"], [\"\",\"\"])\n",
    "punctuation_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "input_path = \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks-full/json/data.json\"\n",
    "\n",
    "with open(input_path) as file:\n",
    "    data_json = json.load(file)\n",
    "    print(len(data_json))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2178/1768385597.py:4: RuntimeWarning: divide by zero encountered in log2\n",
      "  np.log2(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "np.log2(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 418,\n",
       " 'contents': 'Kick-off Grundlagen der Sensorik - Schwingungssensor; Cover; Sicherheitshinweise; Einfhrung; Projektvorstellung.   1. Cover:  Willkommen zum Projekt Grundlagen der Sensorik - Schwingungssensor Lesen Sie bitte die nachfolgenden Sicherheitshinweise sowie die einleitenden Hinweise zum Projektablauf aufmerksam durch, bevor Sie mit der Bearbeitung der Betrieblichen Auftrage in den Versuchen starten. 2. Sicherheitshinweise:  Sicherheitshinweise Achtung! Beachten Sie beim Aufbau und bei der Erprobung der Gerate alle erforderlichen Sicherheitsbestimmungen, die Laborordnung und die erforderlichen Schutzmanahmen! Verdrahten Sie den Laborversuch grundsatzlich im stromlosen Zustand! Bei Anschluss der Versorgungsspannungen auf richtige Polaritat und Spannungshohe prufen!  Copyright: ETS DIDACTIC GMBH Im Huttental 11 | 85125 Kinding  | Germany Alle Rechte vorbehalten. Das Werk und seine Teile sind urheberrechtlich geschutzt. Jede Nutzung in anderen als den gesetzlich zugelassenen Fallen bedarf der vorherigen schriftlichen Einwilligung des Herausgebers. Hinweis zu  60a/b UrhG: Weder das Werk noch seine Teile durfen ohne eine solche Einwilligung in ein Netzwerk eingestellt werden. Dies gilt auch fur Intranets von Schulen und sonstigen Institutionen. Ausdrucklich hiervon ausgenommen sind die Arbeitsblatter fur Schuler. Diese durfen innerhalb der Institution, die dieses Handbuch erworben hat, zur Unterrichtsgestaltung in unveranderter Form beliebig vervielfaltigt werden. Falls Anderungen durch eine nicht von der ETS DIDACTIC GMBH autorisierte Stelle vorgenommen werden, erloschen hierdurch die Produzentenhaftung und ein etwaiger Garantieanspruch. 3. Einfhrung:  Einfuhrung Sensoren bilden zusammen mit Aktoren eine wichtige Grundlage fur die Automatisierung von technischen Anwendungen. Die nachfolgende Abbildung  zeigt eine hierarchische Darstellung der verschiedenen Ebenen der automatisierten Produktion. Sensoren und Aktoren befinden sich hier auf der Feldebene, also der untersten Ebene des Automatisierungssystems. Im Feld messen Sensoren physikalische Prozessgroen und -zustande und wandeln diese in elektrische Groen um. Die Daten der Feldebene werden an die Steuerungsebene (z. B. SPS) gesendet, welche uber die Aktoren den Prozess fuhren kann. Automatisierungspyramide In vielen Anwendungen und Prozessen ist es wichtig, Schwingungen zu Uberwachen und Storungen zu erkennen oder zum Zweck der Prozessfuhrung zu messen. Allen Storungen ist gemeinsam, dass ihre Ursache Schwingungen und Stoe sind. Dies fuhrt zu Rissentstehung und Materialversagen. Werden diese kontinuierlich oder in festen Abstanden gemessen, werden Fehlfunktion, Abnutzung und Schaden erkannt und konnen behoben werden. Ein gangiges Beispiel hierfur ist die fruhzeitige Erfassung von Storungen in Abluft und Beluftungsanlagen. Die Instandhaltung und Instandsetzung bei Maschinen und Anlagen kann durch das fruhzeitige Erkennen von Storungen erheblich verbessert werden. Eine standige Maschinen und Anlagenverfugbarkeit zeigt das hohe Marktpotential fur die Schwingungssensorik. Je nach Anwendungsbeispiel liegen allerdings sehr unterschiedliche Anforderungen an Bandbreite, Empfindlichkeit, Dynamikbereich, Frequenzbereich, NullgSpannung, Spannungsrauschdichte oder der verfugbaren Schnittstellen vor. Dementsprechend sind am Markt eine Reihe von Sensoren und Messgeraten verfugbar, die in ihrer Funktionsweise recht unterschiedlich sind. Dieses Handbuch betrachtet die Schwingungsmessung mit mikromechanischem Beschleunigungssensor und einem kapazitiven Messprinzip. 4. Projektvorstellung:  Sensoranordnung fur die Beschleunigungserfassung eines Luftermotors In einem groen Unternehmen werden MagnesiumDruckgussteile mit MagnesiumDruckgussmaschinen hergestellt. Diese Maschinen befinden sich in groen Hallen. In den Hallen befinden sich groe Abluft und Beluftungsanlagen, die den in der Luft befindlichen Magnesiumstaub abtransportieren und Frischluft zufuhren. Es ist unbedingt erforderlich, dass die Abluftanlagen vorhanden und zu jeder Zeit betriebsbereit sind. Aus den Hallen muss immer ausreichend Magnesiumstaub abtransportiert und in gleichem Mae Frischluft zugefuhrt werden. Trotz der Beluftung lagert sich der Magnesiumstaub aus der Luft an Maschinen und Anlagen ab. Von der Ablagerung ist auch die Abluft und Beluftungsanlage betroffen. Der Magnesiumstaub kann sich in kleinen Schlitzen und Offnungen ablagern. Gelangt der Staub in die Lagerung des Lufterrades, hat das zur Folge, dass der Luftermotor Unwucht bekommt und sich mit der Zeit selbst beschadigt und ausfallt. Aus Grunden des Maschinen und Arbeitsschutzes, sowie zur Erhaltung und Bereitschaft der Anlagen, muss eine hohe Ausfallsicherheit der Abluft und Beluftungsanlage gewahrleistet werden. Beluftungsanlage Der Inhaber des Unternehmens mochte seine Maschinen mit Uberwachungssensorik ausstatten. Er mochte mit dieser Umbaumanahme am Beluftungssystem beginnen und aufgrund der oben genannten Grunde einen Schwingungssensor einbauen lassen. Dieser Schwingungssensor uberwacht die Schwingungen des Luftermotors und hilft dabei Schaden fruhzeitig zu erkennen und diese dann zu beheben. Um mehr uber die Funktion und die Eigenschaften des Sensors zu erfahren, erarbeiten Sie in der Arbeitsplanung die Grundlagen und die wichtigsten Fakten aus dem Datenblatt, bevor Sie mit der Umsetzung des betrieblichen Auftrags starten. Hinweis zur Bearbeitung der Versuche: Vertiefende theoretische Grundlagen und Datenblatter finden Sie in jedem Arbeitsschritt im Menubereich \"Aufgabendokumente\". Nutzen Sie diese, um sich das notige Wissen fur die Losung der Aufgabenstellung und zur Beantwortung der Fragen in den Formularen anzueignen. Sie konnen nun mit der Bearbeitung der Versuchsreihe starten.',\n",
       " '@id': '/mls-api/tasks/418',\n",
       " 'vector': [-0.23397259414196014,\n",
       "  0.001961972564458847,\n",
       "  -0.2923840284347534,\n",
       "  0.0534830205142498,\n",
       "  0.39756500720977783,\n",
       "  -0.33446967601776123,\n",
       "  -0.08210780471563339,\n",
       "  -0.3477711081504822,\n",
       "  -0.32556578516960144,\n",
       "  0.4367249011993408,\n",
       "  0.02068767324090004,\n",
       "  -0.08982595801353455,\n",
       "  -0.5004345774650574,\n",
       "  -0.05643752962350845,\n",
       "  0.15576183795928955,\n",
       "  -0.29474562406539917,\n",
       "  -0.22783485054969788,\n",
       "  0.16589096188545227,\n",
       "  -0.167149156332016,\n",
       "  0.4394269585609436,\n",
       "  -0.1095946729183197,\n",
       "  0.2904982566833496,\n",
       "  0.20733784139156342,\n",
       "  0.08173305541276932,\n",
       "  -0.2305852770805359,\n",
       "  -0.6876134872436523,\n",
       "  0.005882482975721359,\n",
       "  0.024752076715230942,\n",
       "  -0.1117842048406601,\n",
       "  0.1674138605594635,\n",
       "  -0.16023418307304382,\n",
       "  -0.22512993216514587,\n",
       "  -0.12321048974990845,\n",
       "  -0.07023351639509201,\n",
       "  -0.1305537223815918,\n",
       "  0.23852881789207458,\n",
       "  -0.18474802374839783,\n",
       "  -0.17363613843917847,\n",
       "  0.1004435271024704,\n",
       "  0.40952378511428833,\n",
       "  0.17966648936271667,\n",
       "  -0.14482209086418152,\n",
       "  -0.39692193269729614,\n",
       "  0.06586640328168869,\n",
       "  -0.05528634041547775,\n",
       "  -0.11461374163627625,\n",
       "  -0.26342418789863586,\n",
       "  0.26095128059387207,\n",
       "  0.25012364983558655,\n",
       "  -0.14315280318260193,\n",
       "  -0.09079969674348831,\n",
       "  0.17666122317314148,\n",
       "  0.059969186782836914,\n",
       "  -0.41984453797340393,\n",
       "  -0.41061660647392273,\n",
       "  -0.5272654891014099,\n",
       "  0.24278762936592102,\n",
       "  0.13818413019180298,\n",
       "  0.5549348592758179,\n",
       "  0.050782058387994766,\n",
       "  -0.011110091581940651,\n",
       "  0.10407377034425735,\n",
       "  0.21823793649673462,\n",
       "  0.001048397272825241,\n",
       "  -0.20731544494628906,\n",
       "  -0.1093936562538147,\n",
       "  -0.07832364737987518,\n",
       "  -0.023584062233567238,\n",
       "  -0.09301923960447311,\n",
       "  0.022349655628204346,\n",
       "  -0.1652240753173828,\n",
       "  0.1017749160528183,\n",
       "  0.029259493574500084,\n",
       "  1.583893060684204,\n",
       "  0.06368415057659149,\n",
       "  0.09809239208698273,\n",
       "  0.17870764434337616,\n",
       "  0.0579647421836853,\n",
       "  0.0638885349035263,\n",
       "  -0.08959425985813141,\n",
       "  0.13828830420970917,\n",
       "  0.5913723707199097,\n",
       "  -0.4779823422431946,\n",
       "  0.1839367151260376,\n",
       "  -0.19579002261161804,\n",
       "  -0.04341045394539833,\n",
       "  -0.042339712381362915,\n",
       "  0.09586165100336075,\n",
       "  0.02407248318195343,\n",
       "  0.12468114495277405,\n",
       "  0.5505087971687317,\n",
       "  0.2748557925224304,\n",
       "  0.07234157621860504,\n",
       "  -0.1493176966905594,\n",
       "  -0.16424353420734406,\n",
       "  0.03474477678537369,\n",
       "  0.1590965837240219,\n",
       "  0.19320985674858093,\n",
       "  -0.29997289180755615,\n",
       "  0.17628315091133118,\n",
       "  -0.008341025561094284,\n",
       "  0.29207757115364075,\n",
       "  -0.14000429213047028,\n",
       "  0.08899363875389099,\n",
       "  0.3293606638908386,\n",
       "  0.01680077239871025,\n",
       "  -0.033098720014095306,\n",
       "  0.05634232237935066,\n",
       "  0.5792769193649292,\n",
       "  0.08179229497909546,\n",
       "  0.20332936942577362,\n",
       "  -0.07008957862854004,\n",
       "  0.36660486459732056,\n",
       "  0.11142581701278687,\n",
       "  -0.05612131208181381,\n",
       "  -0.18285131454467773,\n",
       "  0.273044228553772,\n",
       "  0.013185529969632626,\n",
       "  -0.253260999917984,\n",
       "  0.33173251152038574,\n",
       "  0.14423726499080658,\n",
       "  -0.1542455554008484,\n",
       "  -0.4071362614631653,\n",
       "  -0.23550376296043396,\n",
       "  0.19598335027694702,\n",
       "  -0.2783644199371338,\n",
       "  -0.02708980068564415,\n",
       "  -0.03278901055455208,\n",
       "  -0.07104521989822388,\n",
       "  -0.054457131773233414,\n",
       "  -1.6219217777252197,\n",
       "  0.016486750915646553,\n",
       "  -0.5269484519958496,\n",
       "  -0.04681304842233658,\n",
       "  0.3392181694507599,\n",
       "  -0.22523552179336548,\n",
       "  -0.11376477777957916,\n",
       "  0.06005805358290672,\n",
       "  -0.011225903406739235,\n",
       "  -0.09763652086257935,\n",
       "  0.22293956577777863,\n",
       "  -0.30538108944892883,\n",
       "  0.06857191771268845,\n",
       "  0.41467857360839844,\n",
       "  0.051725953817367554,\n",
       "  -0.019689345732331276,\n",
       "  -0.011746153235435486,\n",
       "  0.15867482125759125,\n",
       "  -2.3350119590759277e-05,\n",
       "  -9.86550521850586,\n",
       "  0.19401061534881592,\n",
       "  0.12042303383350372,\n",
       "  -0.1763516664505005,\n",
       "  0.08747698366641998,\n",
       "  0.24896100163459778,\n",
       "  -0.4951018691062927,\n",
       "  -0.12948216497898102,\n",
       "  -0.013422787189483643,\n",
       "  0.0755142867565155,\n",
       "  -0.1104414090514183,\n",
       "  0.3247520923614502,\n",
       "  -0.7601195573806763,\n",
       "  0.22301100194454193,\n",
       "  -0.2578120827674866,\n",
       "  0.05118823051452637,\n",
       "  -0.25727158784866333,\n",
       "  0.3050767183303833,\n",
       "  -0.3731132447719574,\n",
       "  0.054243553429841995,\n",
       "  0.1276644617319107,\n",
       "  -0.1367059051990509,\n",
       "  -0.16033601760864258,\n",
       "  -0.0007144436240196228,\n",
       "  0.21188168227672577,\n",
       "  -0.2849499583244324,\n",
       "  -0.2943952679634094,\n",
       "  0.320565402507782,\n",
       "  0.024103857576847076,\n",
       "  -0.10451889783143997,\n",
       "  -0.13015395402908325,\n",
       "  -0.12872761487960815,\n",
       "  0.02584252692759037,\n",
       "  -0.02955501526594162,\n",
       "  0.1621234118938446,\n",
       "  0.27323389053344727,\n",
       "  0.01783139631152153,\n",
       "  0.03373289480805397,\n",
       "  -0.2373603731393814,\n",
       "  -0.25147581100463867,\n",
       "  0.2816198468208313,\n",
       "  -0.2082151472568512,\n",
       "  0.06488154828548431,\n",
       "  -0.006280761212110519,\n",
       "  0.0907595157623291,\n",
       "  0.29319578409194946,\n",
       "  -0.2815212607383728,\n",
       "  -0.5479307770729065,\n",
       "  -0.03044319711625576,\n",
       "  0.05901702120900154,\n",
       "  -0.030091479420661926,\n",
       "  -0.12262396514415741,\n",
       "  0.23984897136688232,\n",
       "  -0.04710277169942856,\n",
       "  0.18279066681861877,\n",
       "  0.07377471774816513,\n",
       "  -0.2823213040828705,\n",
       "  0.44852811098098755,\n",
       "  0.5545382499694824,\n",
       "  0.4912019670009613,\n",
       "  0.0647280290722847,\n",
       "  -0.08675886690616608,\n",
       "  0.07703939080238342,\n",
       "  -0.08113657683134079,\n",
       "  0.004480436444282532,\n",
       "  -0.09239211678504944,\n",
       "  -0.4501953423023224,\n",
       "  0.11377568542957306,\n",
       "  0.19021303951740265,\n",
       "  0.36091935634613037,\n",
       "  0.25335991382598877,\n",
       "  -0.12440961599349976,\n",
       "  0.046364184468984604,\n",
       "  0.11856638640165329,\n",
       "  0.6388301253318787,\n",
       "  0.6604452133178711,\n",
       "  -0.06745859980583191,\n",
       "  0.538331151008606,\n",
       "  0.10415817052125931,\n",
       "  -0.19268450140953064,\n",
       "  0.3254756033420563,\n",
       "  -0.14891576766967773,\n",
       "  -0.2445884793996811,\n",
       "  -0.11477042734622955,\n",
       "  0.05147390067577362,\n",
       "  -0.04948093742132187,\n",
       "  -0.028265882283449173,\n",
       "  -0.031568244099617004,\n",
       "  0.08060689270496368,\n",
       "  0.19966058433055878,\n",
       "  -0.16579630970954895,\n",
       "  0.2472236454486847,\n",
       "  0.0680239200592041,\n",
       "  0.2920002341270447,\n",
       "  0.07894881069660187,\n",
       "  0.4805757701396942,\n",
       "  0.4201979637145996,\n",
       "  -0.15145108103752136,\n",
       "  0.18227210640907288,\n",
       "  -0.31104105710983276,\n",
       "  0.5815688371658325,\n",
       "  -0.15714916586875916,\n",
       "  -0.2809906303882599,\n",
       "  0.5168477296829224,\n",
       "  -0.1252167820930481,\n",
       "  0.028518298640847206,\n",
       "  0.08539886772632599,\n",
       "  -0.2883344888687134,\n",
       "  0.10407023876905441,\n",
       "  0.15575580298900604,\n",
       "  0.10991127789020538,\n",
       "  -0.24298730492591858,\n",
       "  -0.2082456797361374,\n",
       "  -0.0012180472258478403,\n",
       "  -0.14546474814414978,\n",
       "  0.250183641910553,\n",
       "  -0.0015375912189483643,\n",
       "  -0.19628870487213135,\n",
       "  -0.1362454891204834,\n",
       "  -0.16696539521217346,\n",
       "  0.08710464835166931,\n",
       "  0.29821091890335083,\n",
       "  -0.1569683849811554,\n",
       "  0.2955257296562195,\n",
       "  0.11022411286830902,\n",
       "  0.3572767674922943,\n",
       "  0.2489359974861145,\n",
       "  0.17937669157981873,\n",
       "  -0.3223208785057068,\n",
       "  0.19366750121116638,\n",
       "  0.18815070390701294,\n",
       "  -0.36160582304000854,\n",
       "  -0.5800444483757019,\n",
       "  -0.04642592743039131,\n",
       "  0.05377881973981857,\n",
       "  -0.022926602512598038,\n",
       "  -0.22837883234024048,\n",
       "  0.25430870056152344,\n",
       "  -0.06950847804546356,\n",
       "  0.05334281921386719,\n",
       "  0.1940269023180008,\n",
       "  -0.010763265192508698,\n",
       "  0.12981382012367249,\n",
       "  0.1997237205505371,\n",
       "  0.2957714796066284,\n",
       "  -0.19555097818374634,\n",
       "  0.008737428113818169,\n",
       "  0.1102977842092514,\n",
       "  0.0431896448135376,\n",
       "  -0.010691750794649124,\n",
       "  0.1334613859653473,\n",
       "  0.13193468749523163,\n",
       "  0.07570376992225647,\n",
       "  -0.09639755636453629,\n",
       "  0.13405467569828033,\n",
       "  -0.09165631234645844,\n",
       "  -0.325654000043869,\n",
       "  -0.10331371426582336,\n",
       "  -0.25085240602493286,\n",
       "  0.03906633332371712,\n",
       "  -0.43706995248794556,\n",
       "  0.33588606119155884,\n",
       "  0.11286412179470062,\n",
       "  -0.018782198429107666,\n",
       "  0.02391253411769867,\n",
       "  -0.021028239279985428,\n",
       "  0.24805086851119995,\n",
       "  -0.33879613876342773,\n",
       "  0.040610089898109436,\n",
       "  0.3949131965637207,\n",
       "  0.18946748971939087,\n",
       "  0.3839702606201172,\n",
       "  0.193303644657135,\n",
       "  -0.07606644928455353,\n",
       "  0.4233071804046631,\n",
       "  -0.3046295940876007,\n",
       "  0.15998591482639313,\n",
       "  0.008910410106182098,\n",
       "  0.21029147505760193,\n",
       "  -0.47668957710266113,\n",
       "  0.18947437405586243,\n",
       "  -0.2701929211616516,\n",
       "  -0.049119655042886734,\n",
       "  -0.13984157145023346,\n",
       "  0.10367724299430847,\n",
       "  -0.1639977991580963,\n",
       "  0.23999229073524475,\n",
       "  0.13758288323879242,\n",
       "  0.1058364063501358,\n",
       "  0.4675375819206238,\n",
       "  -0.2693970799446106,\n",
       "  -0.04131605103611946,\n",
       "  0.0945783257484436,\n",
       "  -0.10054606944322586,\n",
       "  0.6822524070739746,\n",
       "  -0.05054362863302231,\n",
       "  0.06336858868598938,\n",
       "  -0.06488688290119171,\n",
       "  -0.23686859011650085,\n",
       "  -0.12870091199874878,\n",
       "  0.44405224919319153,\n",
       "  0.041575487703084946,\n",
       "  -0.017690686509013176,\n",
       "  1.0821415185928345,\n",
       "  -0.08656942844390869,\n",
       "  -0.07710424810647964,\n",
       "  0.13082516193389893,\n",
       "  0.05542978644371033,\n",
       "  -0.20484982430934906,\n",
       "  0.27363547682762146,\n",
       "  -0.17144615948200226,\n",
       "  0.07247880101203918,\n",
       "  -0.014464028179645538,\n",
       "  0.1773921549320221,\n",
       "  0.1724327802658081,\n",
       "  -0.18967604637145996,\n",
       "  -0.12627935409545898,\n",
       "  -0.08155182749032974,\n",
       "  0.6595968008041382,\n",
       "  0.1862863302230835,\n",
       "  0.540442943572998,\n",
       "  0.17501938343048096,\n",
       "  0.20045723021030426,\n",
       "  0.19276517629623413,\n",
       "  0.09559512138366699,\n",
       "  -0.13161928951740265,\n",
       "  0.08056812733411789,\n",
       "  -0.2670394778251648,\n",
       "  -0.4530145525932312,\n",
       "  -0.07057980448007584,\n",
       "  0.360873281955719,\n",
       "  0.07291948795318604,\n",
       "  0.0408560186624527,\n",
       "  -0.10668091475963593,\n",
       "  -0.2313006967306137,\n",
       "  0.36994004249572754,\n",
       "  -0.051975637674331665,\n",
       "  0.11448092758655548,\n",
       "  -0.11864086985588074,\n",
       "  -0.07530109584331512,\n",
       "  -0.10943777114152908,\n",
       "  0.13242363929748535,\n",
       "  -0.06208087131381035,\n",
       "  -0.45482730865478516,\n",
       "  0.20724919438362122,\n",
       "  -0.10354135185480118,\n",
       "  -0.19780196249485016,\n",
       "  0.03709154576063156,\n",
       "  -0.3817937970161438,\n",
       "  -0.11861926317214966,\n",
       "  -0.07860788702964783,\n",
       "  0.08973635733127594,\n",
       "  -0.09655513614416122,\n",
       "  0.0838179960846901,\n",
       "  -0.4645019471645355,\n",
       "  -0.29694414138793945,\n",
       "  -0.6823688745498657,\n",
       "  -0.13002356886863708,\n",
       "  -0.12651576101779938,\n",
       "  0.3495938777923584,\n",
       "  0.07707411050796509,\n",
       "  0.20074854791164398,\n",
       "  -0.3328016400337219,\n",
       "  -0.055105652660131454,\n",
       "  0.010075528174638748,\n",
       "  -0.12740829586982727,\n",
       "  -1.1147511005401611,\n",
       "  0.36853399872779846,\n",
       "  -0.25549089908599854,\n",
       "  0.11005155742168427,\n",
       "  -0.3598264455795288,\n",
       "  0.055501993745565414,\n",
       "  -0.09724512696266174,\n",
       "  -0.2512027323246002,\n",
       "  -0.5894033908843994,\n",
       "  -0.1626494824886322,\n",
       "  -0.061683110892772675,\n",
       "  0.12458532303571701,\n",
       "  -0.16046063601970673,\n",
       "  -0.05556325986981392,\n",
       "  0.27781999111175537,\n",
       "  -0.26305609941482544,\n",
       "  -0.22082039713859558,\n",
       "  -0.19183191657066345,\n",
       "  -0.11195547878742218,\n",
       "  0.44662871956825256,\n",
       "  0.7276146411895752,\n",
       "  0.12343153357505798,\n",
       "  0.024479122832417488,\n",
       "  0.41906237602233887,\n",
       "  0.0615069754421711,\n",
       "  0.1000194251537323,\n",
       "  -0.3095342814922333,\n",
       "  0.46760761737823486,\n",
       "  0.15951451659202576,\n",
       "  0.013850957155227661,\n",
       "  -0.01708805188536644,\n",
       "  0.07514828443527222,\n",
       "  0.11611093580722809,\n",
       "  0.0904102474451065,\n",
       "  -0.3556387424468994,\n",
       "  -0.27091333270072937,\n",
       "  -0.029167089611291885,\n",
       "  -0.32146066427230835,\n",
       "  -0.15296921133995056,\n",
       "  -0.027973804622888565,\n",
       "  0.2579583525657654,\n",
       "  -0.10843327641487122,\n",
       "  0.09507468342781067,\n",
       "  -0.0017867833375930786,\n",
       "  0.3472125232219696,\n",
       "  0.32289353013038635,\n",
       "  0.3127884864807129,\n",
       "  0.4953122138977051,\n",
       "  -0.18701741099357605,\n",
       "  0.26130586862564087,\n",
       "  0.28278404474258423,\n",
       "  -0.1691308170557022,\n",
       "  -0.06733802706003189,\n",
       "  0.12142132222652435,\n",
       "  -0.3857285976409912,\n",
       "  -0.21814566850662231,\n",
       "  -0.16533538699150085,\n",
       "  0.08715379983186722,\n",
       "  -0.1750299632549286,\n",
       "  0.1492917239665985,\n",
       "  -0.27600014209747314,\n",
       "  -0.29946255683898926,\n",
       "  -0.32362210750579834,\n",
       "  -0.24111051857471466,\n",
       "  -0.12874123454093933,\n",
       "  -0.46300244331359863,\n",
       "  0.14855776727199554,\n",
       "  0.2707788944244385,\n",
       "  -0.05995751917362213,\n",
       "  0.007007911801338196,\n",
       "  -0.031064270064234734,\n",
       "  0.22067975997924805,\n",
       "  0.03821023553609848,\n",
       "  -0.16824811697006226,\n",
       "  -0.050340019166469574,\n",
       "  -0.462230384349823,\n",
       "  0.22176238894462585,\n",
       "  0.3089487552642822,\n",
       "  0.0375995859503746,\n",
       "  0.06179189309477806,\n",
       "  -0.3204769194126129,\n",
       "  0.04647821933031082,\n",
       "  0.33049774169921875,\n",
       "  0.011469706892967224,\n",
       "  0.3649965226650238,\n",
       "  0.14955750107765198,\n",
       "  -0.14867308735847473,\n",
       "  0.44041740894317627,\n",
       "  0.3832675516605377,\n",
       "  -0.0003601163625717163,\n",
       "  -0.0520346537232399,\n",
       "  -0.032674163579940796,\n",
       "  0.20643779635429382,\n",
       "  -0.08178162574768066,\n",
       "  -0.054178934544324875,\n",
       "  -0.10455542802810669,\n",
       "  0.11448433995246887,\n",
       "  -0.1547037661075592,\n",
       "  0.15660633146762848,\n",
       "  0.1661348044872284,\n",
       "  0.18796414136886597,\n",
       "  0.49886131286621094,\n",
       "  0.027665765956044197,\n",
       "  0.14015404880046844,\n",
       "  0.20612752437591553,\n",
       "  0.029639028012752533,\n",
       "  0.17737862467765808,\n",
       "  0.05848325043916702,\n",
       "  -0.173565074801445,\n",
       "  -0.00018484145402908325,\n",
       "  -0.3329562246799469,\n",
       "  0.33847904205322266,\n",
       "  -0.21160756051540375,\n",
       "  -0.11197952926158905,\n",
       "  0.0705932229757309,\n",
       "  -0.062047816812992096,\n",
       "  -0.2141319066286087,\n",
       "  -0.3457079827785492,\n",
       "  0.3986383080482483,\n",
       "  0.09312543272972107,\n",
       "  -0.3591322898864746,\n",
       "  0.06899004429578781,\n",
       "  0.0845077633857727,\n",
       "  0.14862793684005737,\n",
       "  0.14183753728866577,\n",
       "  -1.124879002571106,\n",
       "  0.001299375668168068,\n",
       "  0.20149873197078705,\n",
       "  0.027347996830940247,\n",
       "  0.16208328306674957,\n",
       "  0.25314319133758545,\n",
       "  0.04073964059352875,\n",
       "  0.15914812684059143,\n",
       "  -0.11074405908584595,\n",
       "  0.034820012748241425,\n",
       "  0.3462222218513489,\n",
       "  -0.11308414489030838,\n",
       "  -0.07181894779205322,\n",
       "  -0.03198408707976341,\n",
       "  0.19547201693058014,\n",
       "  -0.03135927766561508,\n",
       "  -0.015266941860318184,\n",
       "  -0.16693870723247528,\n",
       "  0.26807689666748047,\n",
       "  0.09360232949256897,\n",
       "  -0.23995187878608704,\n",
       "  -0.007265560328960419,\n",
       "  -0.1672515571117401,\n",
       "  -0.013950835913419724,\n",
       "  -0.29782021045684814,\n",
       "  0.456473708152771,\n",
       "  0.08344005048274994,\n",
       "  0.25781768560409546,\n",
       "  -0.10178449749946594,\n",
       "  0.15292277932167053,\n",
       "  -0.26736271381378174,\n",
       "  0.021156545728445053,\n",
       "  -0.05649162456393242,\n",
       "  -0.13310958445072174,\n",
       "  0.16299286484718323,\n",
       "  0.0902075320482254,\n",
       "  -0.018088234588503838,\n",
       "  0.0926085114479065,\n",
       "  0.00797741487622261,\n",
       "  0.3941720128059387,\n",
       "  0.3445020914077759,\n",
       "  -0.06420513987541199,\n",
       "  -0.06340649724006653,\n",
       "  0.3935243487358093,\n",
       "  -0.028813838958740234,\n",
       "  0.021365061402320862,\n",
       "  -0.2832292318344116,\n",
       "  -0.24730552732944489,\n",
       "  0.11942075192928314,\n",
       "  -0.23595985770225525,\n",
       "  -0.09092018008232117,\n",
       "  -0.0905189961194992,\n",
       "  -0.08063292503356934,\n",
       "  0.03176262229681015,\n",
       "  -0.12419968098402023,\n",
       "  0.022403262555599213,\n",
       "  0.11716118454933167,\n",
       "  0.21527798473834991,\n",
       "  -0.1704138219356537,\n",
       "  -0.04214831441640854,\n",
       "  -0.16138948500156403,\n",
       "  0.19292697310447693,\n",
       "  -0.014471776783466339,\n",
       "  -0.308505654335022,\n",
       "  0.17566117644309998,\n",
       "  0.02114851027727127,\n",
       "  0.09130197763442993,\n",
       "  0.03136906027793884,\n",
       "  -0.00102265365421772,\n",
       "  0.23341171443462372,\n",
       "  -0.3022589087486267,\n",
       "  0.010949751362204552,\n",
       "  0.09810008853673935,\n",
       "  1.4550468921661377,\n",
       "  0.22146832942962646,\n",
       "  0.06994572281837463,\n",
       "  0.053823575377464294,\n",
       "  0.1439700722694397,\n",
       "  0.07807566225528717,\n",
       "  0.10961215198040009,\n",
       "  -0.1754859983921051,\n",
       "  -0.23186033964157104,\n",
       "  -0.09301391243934631,\n",
       "  -0.39436075091362,\n",
       "  -0.19504332542419434,\n",
       "  0.03207885101437569,\n",
       "  -0.10045132040977478,\n",
       "  -0.10887113213539124,\n",
       "  0.08827297389507294,\n",
       "  0.42492765188217163,\n",
       "  -0.06557944416999817,\n",
       "  -0.3885299563407898,\n",
       "  -0.6469904184341431,\n",
       "  -0.2848351001739502,\n",
       "  -0.2713741064071655,\n",
       "  -0.3995663523674011,\n",
       "  0.152473583817482,\n",
       "  -0.13862848281860352,\n",
       "  0.8304586410522461,\n",
       "  -0.1987704485654831,\n",
       "  -0.2037767618894577,\n",
       "  -0.17729809880256653,\n",
       "  0.047917336225509644,\n",
       "  0.16820800304412842,\n",
       "  0.08383335173130035,\n",
       "  -0.10253508388996124,\n",
       "  -0.1600703001022339,\n",
       "  -0.11171700060367584,\n",
       "  0.4025431275367737,\n",
       "  -0.11895520240068436,\n",
       "  -0.024416271597146988,\n",
       "  -0.685060441493988,\n",
       "  0.0888679176568985,\n",
       "  0.06291866302490234,\n",
       "  0.2818947434425354,\n",
       "  -0.21484819054603577,\n",
       "  -0.14658376574516296,\n",
       "  -0.2220352739095688,\n",
       "  -0.0005122087895870209,\n",
       "  0.01994331181049347,\n",
       "  0.08300943672657013,\n",
       "  -0.08660340309143066,\n",
       "  0.15015794336795807,\n",
       "  0.305905818939209,\n",
       "  0.521682858467102,\n",
       "  0.41986626386642456,\n",
       "  -0.16207900643348694,\n",
       "  -0.2907133102416992,\n",
       "  0.0236450657248497,\n",
       "  0.35931700468063354,\n",
       "  0.7976833581924438,\n",
       "  -0.03358756750822067,\n",
       "  0.21189719438552856,\n",
       "  0.2135714590549469,\n",
       "  0.08427703380584717,\n",
       "  0.32364875078201294,\n",
       "  0.18831469118595123,\n",
       "  -0.013618148863315582,\n",
       "  -0.13334032893180847,\n",
       "  0.0537017285823822,\n",
       "  -0.06600081920623779,\n",
       "  0.01705087162554264,\n",
       "  0.0030617471784353256,\n",
       "  -0.4913731515407562,\n",
       "  -0.2814473807811737,\n",
       "  0.21592432260513306,\n",
       "  -0.11833769828081131,\n",
       "  0.09021563827991486,\n",
       "  -0.1232619434595108,\n",
       "  -0.22473391890525818,\n",
       "  -0.021080242469906807,\n",
       "  -0.17848722636699677,\n",
       "  0.1042303591966629,\n",
       "  -0.19742965698242188,\n",
       "  -0.3409152626991272,\n",
       "  -0.1316390484571457,\n",
       "  -0.2644228935241699,\n",
       "  0.0011196751147508621,\n",
       "  0.03214166313409805,\n",
       "  0.4724060297012329,\n",
       "  0.13371258974075317,\n",
       "  0.2204650193452835,\n",
       "  -0.01306075043976307,\n",
       "  0.08610144257545471,\n",
       "  0.46602338552474976,\n",
       "  -0.22371673583984375,\n",
       "  -0.211192786693573,\n",
       "  -0.1500362753868103,\n",
       "  -0.012413952499628067,\n",
       "  -0.011724654585123062,\n",
       "  0.16830536723136902,\n",
       "  0.1673279106616974,\n",
       "  -0.08815383911132812,\n",
       "  -0.020585039630532265,\n",
       "  -0.5135365724563599,\n",
       "  0.24202880263328552,\n",
       "  -0.024637483060359955,\n",
       "  -0.04640660434961319,\n",
       "  0.36015039682388306,\n",
       "  0.1663832664489746,\n",
       "  0.0007873028516769409,\n",
       "  -0.3459649085998535,\n",
       "  0.6558085680007935,\n",
       "  -0.03366789594292641,\n",
       "  0.030950777232646942,\n",
       "  -0.03802688047289848,\n",
       "  0.27694064378738403,\n",
       "  -0.03006269782781601,\n",
       "  0.10637607425451279,\n",
       "  0.2818686366081238,\n",
       "  -0.16324232518672943,\n",
       "  0.2009197473526001,\n",
       "  0.28008121252059937,\n",
       "  -0.04436352103948593,\n",
       "  0.2682880759239197,\n",
       "  0.1601073294878006,\n",
       "  0.2688365578651428,\n",
       "  -0.12914028763771057,\n",
       "  0.10621452331542969,\n",
       "  -1.473179817199707,\n",
       "  -0.10588079690933228,\n",
       "  -0.06695060431957245,\n",
       "  -0.5605920553207397,\n",
       "  -0.20685765147209167,\n",
       "  -0.24437373876571655,\n",
       "  0.24926047027111053,\n",
       "  0.17819996178150177,\n",
       "  0.1845102459192276,\n",
       "  0.0310687068849802,\n",
       "  0.5268228054046631,\n",
       "  -0.15077483654022217,\n",
       "  -0.051549509167671204,\n",
       "  0.18790081143379211,\n",
       "  -0.13560663163661957,\n",
       "  0.10213970392942429,\n",
       "  0.019233688712120056,\n",
       "  -0.11866386234760284,\n",
       "  -0.21842575073242188,\n",
       "  -0.15636397898197174,\n",
       "  -0.15318313241004944,\n",
       "  -0.35542595386505127,\n",
       "  -0.17256850004196167,\n",
       "  0.2136182188987732,\n",
       "  -0.3473866879940033,\n",
       "  0.3506321907043457,\n",
       "  0.17905259132385254,\n",
       "  -0.3207918405532837,\n",
       "  -0.05124085769057274]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodes_file_path = \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/encodes/dense/bert-base-german-cased/mls-tasks-full/data_encoded.json\"\n",
    "with open(encodes_file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = 1\n",
    "resistence = 0.5\n",
    "effect_hit = 1/(base*(1 - resistence)) - 1\n",
    "\n",
    "effect_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks-full/json/data.json\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 418,\n",
       " 'contents': 'Kick-off Grundlagen der Sensorik - Schwingungssensor; Cover; Sicherheitshinweise; Einfhrung; Projektvorstellung.   1. Cover:  Willkommen zum Projekt Grundlagen der Sensorik - Schwingungssensor Lesen Sie bitte die nachfolgenden Sicherheitshinweise sowie die einleitenden Hinweise zum Projektablauf aufmerksam durch, bevor Sie mit der Bearbeitung der Betrieblichen Auftrage in den Versuchen starten. 2. Sicherheitshinweise:  Sicherheitshinweise Achtung! Beachten Sie beim Aufbau und bei der Erprobung der Gerate alle erforderlichen Sicherheitsbestimmungen, die Laborordnung und die erforderlichen Schutzmanahmen! Verdrahten Sie den Laborversuch grundsatzlich im stromlosen Zustand! Bei Anschluss der Versorgungsspannungen auf richtige Polaritat und Spannungshohe prufen!  Copyright: ETS DIDACTIC GMBH Im Huttental 11 | 85125 Kinding  | Germany Alle Rechte vorbehalten. Das Werk und seine Teile sind urheberrechtlich geschutzt. Jede Nutzung in anderen als den gesetzlich zugelassenen Fallen bedarf der vorherigen schriftlichen Einwilligung des Herausgebers. Hinweis zu  60a/b UrhG: Weder das Werk noch seine Teile durfen ohne eine solche Einwilligung in ein Netzwerk eingestellt werden. Dies gilt auch fur Intranets von Schulen und sonstigen Institutionen. Ausdrucklich hiervon ausgenommen sind die Arbeitsblatter fur Schuler. Diese durfen innerhalb der Institution, die dieses Handbuch erworben hat, zur Unterrichtsgestaltung in unveranderter Form beliebig vervielfaltigt werden. Falls Anderungen durch eine nicht von der ETS DIDACTIC GMBH autorisierte Stelle vorgenommen werden, erloschen hierdurch die Produzentenhaftung und ein etwaiger Garantieanspruch. 3. Einfhrung:  Einfuhrung Sensoren bilden zusammen mit Aktoren eine wichtige Grundlage fur die Automatisierung von technischen Anwendungen. Die nachfolgende Abbildung  zeigt eine hierarchische Darstellung der verschiedenen Ebenen der automatisierten Produktion. Sensoren und Aktoren befinden sich hier auf der Feldebene, also der untersten Ebene des Automatisierungssystems. Im Feld messen Sensoren physikalische Prozessgroen und -zustande und wandeln diese in elektrische Groen um. Die Daten der Feldebene werden an die Steuerungsebene (z. B. SPS) gesendet, welche uber die Aktoren den Prozess fuhren kann. Automatisierungspyramide In vielen Anwendungen und Prozessen ist es wichtig, Schwingungen zu Uberwachen und Storungen zu erkennen oder zum Zweck der Prozessfuhrung zu messen. Allen Storungen ist gemeinsam, dass ihre Ursache Schwingungen und Stoe sind. Dies fuhrt zu Rissentstehung und Materialversagen. Werden diese kontinuierlich oder in festen Abstanden gemessen, werden Fehlfunktion, Abnutzung und Schaden erkannt und konnen behoben werden. Ein gangiges Beispiel hierfur ist die fruhzeitige Erfassung von Storungen in Abluft und Beluftungsanlagen. Die Instandhaltung und Instandsetzung bei Maschinen und Anlagen kann durch das fruhzeitige Erkennen von Storungen erheblich verbessert werden. Eine standige Maschinen und Anlagenverfugbarkeit zeigt das hohe Marktpotential fur die Schwingungssensorik. Je nach Anwendungsbeispiel liegen allerdings sehr unterschiedliche Anforderungen an Bandbreite, Empfindlichkeit, Dynamikbereich, Frequenzbereich, NullgSpannung, Spannungsrauschdichte oder der verfugbaren Schnittstellen vor. Dementsprechend sind am Markt eine Reihe von Sensoren und Messgeraten verfugbar, die in ihrer Funktionsweise recht unterschiedlich sind. Dieses Handbuch betrachtet die Schwingungsmessung mit mikromechanischem Beschleunigungssensor und einem kapazitiven Messprinzip. 4. Projektvorstellung:  Sensoranordnung fur die Beschleunigungserfassung eines Luftermotors In einem groen Unternehmen werden MagnesiumDruckgussteile mit MagnesiumDruckgussmaschinen hergestellt. Diese Maschinen befinden sich in groen Hallen. In den Hallen befinden sich groe Abluft und Beluftungsanlagen, die den in der Luft befindlichen Magnesiumstaub abtransportieren und Frischluft zufuhren. Es ist unbedingt erforderlich, dass die Abluftanlagen vorhanden und zu jeder Zeit betriebsbereit sind. Aus den Hallen muss immer ausreichend Magnesiumstaub abtransportiert und in gleichem Mae Frischluft zugefuhrt werden. Trotz der Beluftung lagert sich der Magnesiumstaub aus der Luft an Maschinen und Anlagen ab. Von der Ablagerung ist auch die Abluft und Beluftungsanlage betroffen. Der Magnesiumstaub kann sich in kleinen Schlitzen und Offnungen ablagern. Gelangt der Staub in die Lagerung des Lufterrades, hat das zur Folge, dass der Luftermotor Unwucht bekommt und sich mit der Zeit selbst beschadigt und ausfallt. Aus Grunden des Maschinen und Arbeitsschutzes, sowie zur Erhaltung und Bereitschaft der Anlagen, muss eine hohe Ausfallsicherheit der Abluft und Beluftungsanlage gewahrleistet werden. Beluftungsanlage Der Inhaber des Unternehmens mochte seine Maschinen mit Uberwachungssensorik ausstatten. Er mochte mit dieser Umbaumanahme am Beluftungssystem beginnen und aufgrund der oben genannten Grunde einen Schwingungssensor einbauen lassen. Dieser Schwingungssensor uberwacht die Schwingungen des Luftermotors und hilft dabei Schaden fruhzeitig zu erkennen und diese dann zu beheben. Um mehr uber die Funktion und die Eigenschaften des Sensors zu erfahren, erarbeiten Sie in der Arbeitsplanung die Grundlagen und die wichtigsten Fakten aus dem Datenblatt, bevor Sie mit der Umsetzung des betrieblichen Auftrags starten. Hinweis zur Bearbeitung der Versuche: Vertiefende theoretische Grundlagen und Datenblatter finden Sie in jedem Arbeitsschritt im Menubereich \"Aufgabendokumente\". Nutzen Sie diese, um sich das notige Wissen fur die Losung der Aufgabenstellung und zur Beantwortung der Fragen in den Formularen anzueignen. Sie konnen nun mit der Bearbeitung der Versuchsreihe starten.',\n",
       " '@id': '/mls-api/tasks/418'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].get(\"content\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
